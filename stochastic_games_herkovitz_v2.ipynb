{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stochastic_games_herkovitz_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarod13/Stochastic_Games/blob/master/stochastic_games_herkovitz_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5T17o-vEAdt"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import linprog\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.parameter import Parameter\n",
        "import copy\n",
        "\n",
        "device = 'cpu'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SMCGNsteY1a"
      },
      "source": [
        "# import inspect\n",
        "# inspect.getsource(game.feasible_gradient_descent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsaLjXwX-aKX"
      },
      "source": [
        "# Game Class Definition\n",
        "\n",
        "First, we will define a general class for stochastic games that requires the tuple $\\langle N,S,A,R,T,\\beta \\rangle$ to define each game."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diVFarepD_cX"
      },
      "source": [
        "class multi_player_game(nn.Module):\n",
        "  def __init__(self, N, S, A, R, T, beta, device, dtype=torch.float64, name='StochasticGame-v0'):\n",
        "    super().__init__()\n",
        "\n",
        "    # Store game defining parameters\n",
        "    self.N = N\n",
        "    self.S_no_string = S.copy()\n",
        "    self.S = [str(s) for s in S]\n",
        "    self.A = A.copy()\n",
        "    self.R = {}\n",
        "    for player in self.players():\n",
        "      self.R[player] = {}\n",
        "      for s_key, val in R[player].items():\n",
        "        self.R[player][s_key] = val.clone().to(device)\n",
        "    self.transition_map = T[0]\n",
        "    self.transition_type = T[1]\n",
        "    self.beta = beta\n",
        "    self.device = device\n",
        "    self.name = name\n",
        "    self.dtype = dtype\n",
        "\n",
        "    # Define useful constants\n",
        "    self.N_S = len(S)    \n",
        "    self.N_A_S_vector = {'1':[], '2':[]}\n",
        "    self.N_A_S_reduced_vector = {'1':[], '2':[]}\n",
        "    for player in self.players():\n",
        "      for s in self.S:\n",
        "        n_actions_player_in_s = A[player][s]      \n",
        "        self.N_A_S_vector[player].append(n_actions_player_in_s)\n",
        "        if self.more_than_one_action(player, s):\n",
        "          self.N_A_S_reduced_vector[player].append(n_actions_player_in_s)\n",
        "    \n",
        "    self.N_A_total = {}\n",
        "    self.N_A_reduced = {}\n",
        "    self.N_S_reduced = {}\n",
        "    for player in self.players():\n",
        "      if dtype == torch.float64:\n",
        "        self.N_A_S_vector[player] = torch.DoubleTensor(self.N_A_S_vector[player]).to(device).view(-1,1)\n",
        "        self.N_A_S_reduced_vector[player] = torch.DoubleTensor(self.N_A_S_reduced_vector[player]).to(device).view(-1,1)\n",
        "      else:\n",
        "        self.N_A_S_vector[player] = torch.FloatTensor(self.N_A_S_vector[player]).to(device).view(-1,1)\n",
        "        self.N_A_S_reduced_vector[player] = torch.FloatTensor(self.N_A_S_reduced_vector[player]).to(device).view(-1,1)\n",
        "      self.N_A_total[player] = int(self.N_A_S_vector[player].sum().item())\n",
        "      self.N_A_reduced[player] = int(self.N_A_S_reduced_vector[player].sum().item())\n",
        "      self.N_S_reduced[player] = self.N_A_S_reduced_vector[player].view(-1).shape[0]\n",
        "\n",
        "    self.n_restrictions = 0\n",
        "    for player in self.players():\n",
        "      self.n_restrictions += self.N_A_total[player] + self.N_A_reduced[player] + self.N_S_reduced[player]\n",
        "    self.n_vars = 2*self.N_S + self.N_A_reduced['1'] + self.N_A_reduced['2']\n",
        "\n",
        "    # Define useful variables\n",
        "    self.n_save = 0\n",
        "\n",
        "    # Define policy and value parameter tensors\n",
        "    for player in self.players():\n",
        "      setattr(self, 'pi'+player, nn.ParameterDict())\n",
        "    \n",
        "    self.pi = {}\n",
        "    for player in self.players():\n",
        "      self.pi[player] = getattr(self, 'pi'+player)\n",
        "      for s in self.S: \n",
        "        n_actions_player_in_s = A[player][s]\n",
        "        if dtype == torch.float64:\n",
        "          self.pi[player][s] = Parameter(torch.Tensor(n_actions_player_in_s,1).double().to(device))\n",
        "        else:\n",
        "          self.pi[player][s] = Parameter(torch.Tensor(n_actions_player_in_s,1).to(device))\n",
        "        if n_actions_player_in_s >= 2:\n",
        "          nn.init.constant_(self.pi[player][s], 2.0/(3.0*n_actions_player_in_s))\n",
        "        else:\n",
        "          nn.init.constant_(self.pi[player][s], 1.0)\n",
        "    \n",
        "    if dtype == torch.float64:\n",
        "      self.v = Parameter(torch.Tensor(self.N_S,2).double().to(device))\n",
        "    else:\n",
        "      self.v = Parameter(torch.Tensor(self.N_S,2).to(device))\n",
        "    self.set_feasible_value(alpha=1.0e-2)\n",
        "\n",
        "  def forward(self):\n",
        "    return self.pi, self.v\n",
        "  \n",
        "  #-----------------------------------------------------------------------------\n",
        "  # Useful methods\n",
        "  def get_state_index(self, state):\n",
        "    if state in self.S:\n",
        "      return self.S.index(state)\n",
        "    elif state in self.S_no_string:\n",
        "      return self.S_no_string.index(state)\n",
        "    else:\n",
        "      assert 0 == 1, 'Invalid state'\n",
        "\n",
        "  # TODO: consider more than 2 players (is this method really necessary?)\n",
        "  @staticmethod \n",
        "  def player_dim(i):\n",
        "    if i in [0, '1']:\n",
        "      return 'i'\n",
        "    elif i in [1, '2']:\n",
        "      return 'j'\n",
        "    else:\n",
        "      assert 0 == 1, 'Invalid player id'\n",
        "\n",
        "  def get_player_id(self, player):\n",
        "    player_id = int(player)-1\n",
        "    if player_id >= 0 and player_id < self.N:\n",
        "      return player_id\n",
        "    else:\n",
        "      assert 0 == 1, 'Invalid player'\n",
        "  \n",
        "  # TODO: consider more than 2 players (is this method really necessary?)\n",
        "  @staticmethod\n",
        "  def other_player(i):\n",
        "    if i == 0:\n",
        "      return 1\n",
        "    elif i == 1:\n",
        "      return 0\n",
        "    elif i == '1':\n",
        "      return '2'\n",
        "    elif i == '2':\n",
        "      return '1'\n",
        "    else:\n",
        "      assert 0 == 1, 'Invalid player id'\n",
        "\n",
        "  def players_id(self):\n",
        "    return range(0, self.N)\n",
        "\n",
        "  def players(self):\n",
        "    return iter([str(player_id+1) for player_id in self.players_id()]) \n",
        "\n",
        "  def state_player_id_pairs(self):\n",
        "    return itertools.product(self.S, self.players_id())\n",
        "\n",
        "  def state_player_pairs(self):\n",
        "    return itertools.product(self.S, self.players())\n",
        "\n",
        "  def player_consistent_reward_matrices(self):\n",
        "    consistent_R = {'1':{}, '2':{}}\n",
        "    for s in self.S:\n",
        "      consistent_R['1'][s] = self.R['1'][s].clone()\n",
        "      consistent_R['2'][s] = torch.t(self.R['2'][s].clone())  \n",
        "    return consistent_R \n",
        "\n",
        "  def more_than_one_action(self, player, s):\n",
        "    if self.A[player][s] > 1:\n",
        "      return True\n",
        "    else:\n",
        "      return False\n",
        "  \n",
        "  def pi2vec(self):\n",
        "    pi_vector = {}\n",
        "    for player in self.players():\n",
        "      pi_list = []\n",
        "      for s in self.S:\n",
        "        if self.more_than_one_action(player, s):\n",
        "          pi_list.append(self.pi[player][s])\n",
        "      pi_vector[player] = torch.cat(pi_list, dim=0)\n",
        "    return pi_vector\n",
        "  \n",
        "  def pi_sum(self):\n",
        "    sum_vector = {}\n",
        "    for player in self.players():\n",
        "      sum_list = []\n",
        "      for s in self.S:\n",
        "        if self.more_than_one_action(player, s):\n",
        "          sum_list.append(self.pi[player][s].sum(0, keepdim=True))        \n",
        "      sum_vector[player] = torch.cat(sum_list, dim=0)\n",
        "    return sum_vector\n",
        "\n",
        "  def perturb_pi(self, hard_constraints, alpha=1e-2):\n",
        "    for player in self.players():\n",
        "      for s in self.S:\n",
        "        if self.more_than_one_action(player, s):\n",
        "          sum_pi = self.pi[player][s].sum()\n",
        "          pi = self.pi[player][s].clamp(1e-3,1.0-1e-3)\n",
        "          pi = pi / pi.sum() * sum_pi\n",
        "          self.pi[player][s].data.copy_(pi.clone())\n",
        "    g_vector = self.calculate_restriction_vector(hard_constraints)\n",
        "    if not torch.all(g_vector <= 0.0):\n",
        "      self.set_feasible_value(alpha=alpha)\n",
        "\n",
        "  def pi_negentropy(self):\n",
        "    H_vector = {}\n",
        "    for player in self.players():\n",
        "      H_list = []\n",
        "      for s in self.S:\n",
        "        if self.more_than_one_action(player, s):\n",
        "          p = self.pi[player][s]\n",
        "          H = (-p * torch.log(p)).sum(0, keepdim=True)\n",
        "          Hmax = np.log(self.A[player][s])\n",
        "          coef = (1+1e-3)*Hmax - H\n",
        "          H_list.append(coef*torch.ones_like(p))        \n",
        "      H_vector[player] = torch.cat(H_list, dim=0)\n",
        "    return H_vector\n",
        "  \n",
        "  def mask_inequality_restrictions(self, vec):\n",
        "    masked_vector = vec.clone()\n",
        "    masked_vector[-self.N_S_reduced['1']-self.N_S_reduced['2']:,:] = 0.0\n",
        "    return masked_vector\n",
        "\n",
        "  def mask_equality_restrictions(self, vec):\n",
        "    masked_vector = vec.clone()\n",
        "    masked_vector[:-self.N_S_reduced['1']-self.N_S_reduced['2'],:] = 0.0\n",
        "    return masked_vector\n",
        "  \n",
        "  def vec2dic(self, d_vector, duals_vector):\n",
        "    d_v = torch.zeros((self.N_S,2), dtype=self.dtype).to(self.device)  \n",
        "    d_pi = {'1':{}, '2':{}}\n",
        "    duals = {}\n",
        "\n",
        "    # Store gradients related to v in the proper shape\n",
        "    for i in range(0,2):\n",
        "      d_v[:,i] = d_vector[i*self.N_S:(i+1)*self.N_S,:].view(-1)\n",
        "    \n",
        "    # Store gradients related to pi in dictionaries for each player and state\n",
        "    for player in self.players():\n",
        "      y0 = 2*self.N_S + self.get_player_id(player) * self.N_A_reduced['1']\n",
        "      yf = 2*self.N_S + self.N_A_reduced['1']  + self.get_player_id(player) * self.N_A_reduced['2'] \n",
        "      d_pi_vector = d_vector[y0:yf,:]\n",
        "      n = 0\n",
        "      for s in self.S:      \n",
        "        if self.more_than_one_action(player, s):\n",
        "          NA = self.A[player][s]\n",
        "          d_pi[player][s] = d_pi_vector[n:n+NA,:]\n",
        "          n = n + NA\n",
        "        else:\n",
        "          d_pi[player][s] = None      \n",
        "\n",
        "    # Separate duals for each player  \n",
        "    for player in self.players():\n",
        "      i = self.get_player_id(player)\n",
        "      n_restrictions_player = self.N_A_total[player] + self.N_A_reduced[player] + self.N_S_reduced[player]\n",
        "      duals[player] = torch.zeros((n_restrictions_player,1), dtype=self.dtype).to(self.device)\n",
        "      \n",
        "      y0 = self.get_player_id(player) * self.N_A_total['1']\n",
        "      yf = self.N_A_total['1']  + self.get_player_id(player) * self.N_A_total['2'] \n",
        "      duals[player][:self.N_A_total[player],:] = duals_vector[y0:yf,:]\n",
        "      \n",
        "      y0 = self.N_A_total['1'] + self.N_A_total['2'] + self.get_player_id(player) * self.N_A_reduced['1']\n",
        "      yf = self.N_A_total['1'] + self.N_A_total['2'] + self.N_A_reduced['1'] + self.get_player_id(player) * self.N_A_reduced['2'] \n",
        "      duals[player][self.N_A_total[player]:self.N_A_total[player]+self.N_A_reduced[player],:] = duals_vector[y0:yf,:]\n",
        "\n",
        "      y0 = (self.N_A_total['1'] + self.N_A_total['2'] + self.N_A_reduced['1'] + self.N_A_reduced['2'] \n",
        "            + self.get_player_id(player) * self.N_S_reduced['1'])\n",
        "      yf = (self.N_A_total['1'] + self.N_A_total['2'] + self.N_A_reduced['1'] + self.N_A_reduced['2'] \n",
        "            + self.N_S_reduced['1'] + self.get_player_id(player) * self.N_S_reduced['2']) \n",
        "      duals[player][-self.N_S_reduced[player]:,:] = duals_vector[y0:yf,:]\n",
        "\n",
        "    return d_v, d_pi, duals\n",
        "\n",
        "  def update_c_vector(self, c_vector, duals_0_vector):\n",
        "    new_c_vector = c_vector.clone()\n",
        "    entries_to_update = c_vector < -1.2*duals_0_vector\n",
        "    new_c_vector[entries_to_update] = -2*duals_0_vector[entries_to_update]\n",
        "    new_c_vector = self.mask_equality_restrictions(new_c_vector)\n",
        "    return new_c_vector\n",
        "\n",
        "  def copy_game(self):\n",
        "    # Ttuple = (self.transition_map, self.transition_type)\n",
        "    # game_copy = multi_player_game(self.N, self.S_no_string, self.A, self.R, Ttuple, self.beta, self.device).to(device)\n",
        "\n",
        "    game_copy = copy.deepcopy(self)\n",
        "    # with torch.no_grad():\n",
        "    #   for param_copy, param in zip(game_copy.parameters(), self.parameters()):\n",
        "    #     param_copy.copy_(param)\n",
        "    return game_copy\n",
        "  \n",
        "  def save(self):\n",
        "    torch.save(self.state_dict(), './'+self.name+'_gamesave_'+str(self.n_save)+'.pth')\n",
        "    print('Game '+str(self.n_save)+' saved succesfully')\n",
        "    self.n_save += 1\n",
        "  \n",
        "  #-----------------------------------------------------------------------------\n",
        "  # Methods related with the transition matrices\n",
        "\n",
        "  def transition_matrix(self): # TODO: consider other 2 cases\n",
        "    transition_matrix = torch.zeros((self.N_S,self.N_S), dtype=self.dtype).to(self.device)\n",
        "    for state in self.S_no_string:\n",
        "      strategy_1 = self.pi['1'][str(state)]\n",
        "      strategy_2 = self.pi['2'][str(state)]\n",
        "\n",
        "      det, dep = self.transition_type[str(state)]\n",
        "      N_A1 = self.A['1'][str(state)]\n",
        "      N_A2 = self.A['2'][str(state)]\n",
        "      id_s = self.get_state_index(state)\n",
        "\n",
        "      if det and dep:\n",
        "        for a1 in range(0,N_A1):\n",
        "          for a2 in range(0,N_A2):\n",
        "            _, next_state = self.transition_map(state, [a1,a2])\n",
        "            id_ns = self.get_state_index(next_state)\n",
        "            transition_prob = strategy_1[a1,0] * strategy_2[a2,0]\n",
        "            transition_matrix[id_s, id_ns] = transition_matrix[id_s, id_ns] + transition_prob\n",
        "      elif (not det) and (not dep):\n",
        "        _, transition_dic = self.transition_map(state, [])\n",
        "        for next_state, transition_prob in transition_dic:\n",
        "          transition_matrix[id_s, self.get_state_index(next_state)] = (\n",
        "              transition_prob * strategy_1.sum() * strategy_2.sum())\n",
        "    return transition_matrix\n",
        "\n",
        "  def partial_transition_matrices(self): # TODO: consider other 2 cases\n",
        "    # Create dictionary of transition matrices for each state given\n",
        "    # the strategy of the other player \n",
        "    transition_matrices = {}\n",
        "    for state in self.S_no_string:\n",
        "      s = str(state)\n",
        "      strategy_1 = self.pi['1'][s]\n",
        "      strategy_2 = self.pi['2'][s]\n",
        "      N_A1 = self.A['1'][s]\n",
        "      N_A2 = self.A['2'][s]\n",
        "      transition_matrices[s] = {\n",
        "          '1': torch.zeros((N_A1,self.N_S), dtype=self.dtype).to(self.device),\n",
        "          '2': torch.zeros((N_A2,self.N_S), dtype=self.dtype).to(self.device)\n",
        "      }\n",
        "\n",
        "      # Fill matrices with transition probabilities depending on the type\n",
        "      # of transition, i.e., if deterministic or random and independent or\n",
        "      # not on the actions\n",
        "      det, dep = self.transition_type[s]\n",
        "      if det and dep:\n",
        "        for a1 in range(0,N_A1):\n",
        "          for a2 in range(0,N_A2):\n",
        "            _, next_state = self.transition_map(state, [a1,a2])\n",
        "            id_ns = self.get_state_index(next_state)\n",
        "            transition_prob1 = strategy_2[a2,0]\n",
        "            transition_prob2 = strategy_1[a1,0]\n",
        "            transition_matrices[s]['1'][a1, id_ns] = (\n",
        "                transition_matrices[s]['1'][a1, id_ns] + transition_prob1)\n",
        "            transition_matrices[s]['2'][a2, id_ns] = (\n",
        "                transition_matrices[s]['2'][a2, id_ns] + transition_prob2)\n",
        "      elif (not det) and (not dep):\n",
        "        _, transition_dic = self.transition_map(state, [])\n",
        "        for next_state, transition_prob in transition_dic:\n",
        "          transition_matrices[s]['1'][:, self.get_state_index(next_state)] = (\n",
        "              transition_prob * strategy_2.sum())\n",
        "          transition_matrices[s]['2'][:, self.get_state_index(next_state)] = (\n",
        "              transition_prob * strategy_1.sum())\n",
        "    return transition_matrices\n",
        "\n",
        "  def transition_matrix_given_sai(self, player, state, ai): # TODO: consider other 2 cases\n",
        "    other_player = self.other_player(player)\n",
        "    N_Ami = self.A[other_player][str(state)]\n",
        "    transition_matrix = torch.zeros((self.N_S,N_Ami), dtype=self.dtype).to(self.device)\n",
        "    \n",
        "    det, dep = self.transition_type[str(state)]\n",
        "    \n",
        "    if det and dep:\n",
        "      for ami in range(0,N_Ami):\n",
        "          action = [0, 0]\n",
        "          action[self.get_player_id(player)] = ai\n",
        "          action[self.get_player_id(other_player)] = ami\n",
        "          _, next_state = self.transition_map(state, action)\n",
        "          id_ns = self.get_state_index(next_state)\n",
        "          transition_matrix[id_ns, ami] = 1.0\n",
        "    elif (not det) and (not dep):\n",
        "      _, transition_dic = self.transition_map(state, [])\n",
        "      for next_state, transition_prob in transition_dic:\n",
        "        transition_matrix[self.get_state_index(next_state), :] = transition_prob\n",
        "    return transition_matrix\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  # Methods related with the expected reward and value function calculation\n",
        "\n",
        "  # TODO: consider more than 2 players  \n",
        "  def expected_reward(self):\n",
        "    r_mean = torch.zeros((self.N_S,2), dtype=self.dtype).to(self.device)\n",
        "    for player_id in self.players_id():\n",
        "      player = str(player_id+1)\n",
        "      RM_i = self.R[player]\n",
        "      for s in self.S:\n",
        "        strategy_1 = self.pi['1'][s]\n",
        "        strategy_2 = self.pi['2'][s]\n",
        "        r_mean_1 = torch.einsum('ij,ik->jk', RM_i[s], strategy_1)\n",
        "        r_mean[self.get_state_index(s), player_id] = (r_mean_1 * strategy_2).sum()\n",
        "    return r_mean\n",
        "  \n",
        "  def partial_expected_reward(self):\n",
        "    # Create reward dictionary for each combination of players\n",
        "    r_mean = {}\n",
        "    for player in self.players():  \n",
        "      r_mean[player] = {'1':{}, '2':{}}\n",
        "\n",
        "    # Calculate expected reward for combination of players wrt the policy of one of the players\n",
        "    for s, player in self.state_player_pairs():\n",
        "      other_player = self.other_player(player) # Player used to calculate expected reward\n",
        "      for second_player in self.players():  \n",
        "        N_A = self.A[second_player][s]\n",
        "        RM_i = self.R[second_player] # Reward matrix for one of the players  \n",
        "        strategy = self.pi[other_player][s].view(-1)\n",
        "        formula = 'ij,'+self.player_dim(other_player)+'->'+self.player_dim(player)\n",
        "        r_mean[player][second_player][s] = torch.einsum(formula, RM_i[s], strategy).view(-1,1)\n",
        "    return r_mean\n",
        "  \n",
        "  def partial_expected_reward_other(self):\n",
        "    r_mean = {}\n",
        "    for player in self.players():\n",
        "      r_mean[player] = {}\n",
        "    for s, player in self.state_player_pairs():\n",
        "        RM_i = self.R[player]\n",
        "        other_player = self.other_player(player)\n",
        "        strategy = self.pi[other_player][s].view(-1)\n",
        "        formula = 'ij,'+self.player_dim(other_player)+'->'+self.player_dim(player)\n",
        "        r_mean[player][s] = torch.einsum(formula, RM_i[s], strategy).view(-1,1)\n",
        "    return r_mean\n",
        "  \n",
        "  # TODO: consider other 2 cases or transition matrices\n",
        "  # TODO: consider more than 2 players\n",
        "  def next_value_matrices(self, state):\n",
        "    det, dep = self.transition_type[str(state)]\n",
        "    N_A1 = self.A['1'][str(state)]\n",
        "    N_A2 = self.A['2'][str(state)]\n",
        "    vs = torch.zeros((N_A1,N_A2,2), dtype=self.dtype).to(self.device)\n",
        "    if det and dep: \n",
        "      for a1 in range(0,N_A1):\n",
        "        for a2 in range(0,N_A2):\n",
        "          _, next_state = self.transition_map(state, [a1,a2])\n",
        "          vs[a1,a2,:] = self.v[self.get_state_index(next_state),:]\n",
        "    elif (not det) and (not dep):\n",
        "      _, transition_dic = self.transition_map(state, [])\n",
        "      next_v = torch.zeros((1,2), dtype=self.dtype).to(self.device)\n",
        "      for next_state, transition_prob in transition_dic:\n",
        "        next_v = next_v + self.v[self.get_state_index(next_state),:].view(1,-1) * transition_prob      \n",
        "      for a1 in range(0,N_A1):\n",
        "        for a2 in range(0,N_A2):\n",
        "          vs[a1,a2,:] = next_v.view(-1)\n",
        "    return vs\n",
        "  \n",
        "  # TODO: consider more than 2 players\n",
        "  def partial_next_values(self):\n",
        "    # Create next-value dictionary for each player combination\n",
        "    next_v = {}\n",
        "    for player in self.players():\n",
        "      next_v[player] = {'1':{}, '2':{}}\n",
        "\n",
        "    # Fill dictionary \n",
        "    for state in self.S_no_string:\n",
        "      next_state_value_matrix = self.next_value_matrices(state)\n",
        "      strategy_1 = self.pi['1'][str(state)]\n",
        "      strategy_2 = self.pi['2'][str(state)]\n",
        "      \n",
        "      # Calculate mean next value when considering the strategy of one of the players. Output: array of size m^i(s)\n",
        "      for player_id in self.players_id():\n",
        "        next_v['1'][str(player_id+1)][str(state)] = torch.einsum('ij,jk->ik', next_state_value_matrix[:,:,player_id], strategy_2)\n",
        "        next_v['2'][str(player_id+1)][str(state)] = torch.einsum('ji,jk->ik', next_state_value_matrix[:,:,player_id], strategy_1)  \n",
        "    return next_v\n",
        "  \n",
        "  def next_value_dictionary(self):\n",
        "    next_v_dic = {}\n",
        "    for state in self.S_no_string:\n",
        "      next_v_dic[str(state)] = self.next_value_matrices(state)\n",
        "    return next_v_dic\n",
        "  \n",
        "  # TODO: consider more than 2 players\n",
        "  def bellman_projection(self):\n",
        "    r_mean = self.expected_reward()\n",
        "    next_v = torch.zeros_like(self.v)\n",
        "    for s in self.S_no_string:\n",
        "      next_state_value_matrix = self.next_value_matrices(s)\n",
        "      strategy_1 = self.pi['1'][str(s)].squeeze(1)\n",
        "      strategy_2 = self.pi['2'][str(s)].squeeze(1)\n",
        "      next_value_1 = torch.einsum('ijk,i->jk', next_state_value_matrix, strategy_1)\n",
        "      next_v[self.get_state_index(s),:] = torch.einsum('jk,j->k', next_value_1, strategy_2)\n",
        "    return r_mean + self.beta * next_v\n",
        "\n",
        "  # TODO: consider more than 2 players\n",
        "  def bellman_partial_projection(self):\n",
        "    r_mean = self.partial_expected_reward()\n",
        "    next_v = self.partial_next_values()\n",
        "\n",
        "    bellman_projection_dic = {'1':{}, '2':{}}\n",
        "    for player in self.players():\n",
        "      bellman_projection_dic[player] = {'1':{}, '2':{}}\n",
        "    for s, player in self.state_player_pairs():\n",
        "      for second_player in self.players():\n",
        "        bellman_projection_dic[player][second_player][s] = (\n",
        "            r_mean[player][second_player][s] + self.beta * next_v[player][second_player][s])\n",
        "    return bellman_projection_dic\n",
        "\n",
        "  # TODO: consider more than 2 players\n",
        "  def bellman_partial_projection_other(self):\n",
        "    r_mean = self.partial_expected_reward_other()\n",
        "    next_v = {'1':{}, '2':{}}\n",
        "    for state in self.S_no_string:\n",
        "      next_state_value_matrix = self.next_value_matrices(state)\n",
        "      strategy_1 = self.pi['1'][str(state)]\n",
        "      strategy_2 = self.pi['2'][str(state)]\n",
        "      # mean next value when considering the strategy of the other player. Output: array of size m^i(s)\n",
        "      next_v['1'][str(state)] = torch.einsum('ij,jk->ik', next_state_value_matrix[:,:,0], strategy_2)\n",
        "      next_v['2'][str(state)] = torch.einsum('ji,jk->ik', next_state_value_matrix[:,:,1], strategy_1)\n",
        "    bellman_projection_dic = {'1':{}, '2':{}}\n",
        "    for s, player in self.state_player_pairs():\n",
        "      bellman_projection_dic[player][s] = r_mean[player][s] + self.beta * next_v[player][s]\n",
        "    return bellman_projection_dic\n",
        "  \n",
        "  #-----------------------------------------------------------------------------\n",
        "  # Methods related with the linear optimization problem to find a feasible point (v given pi)\n",
        "\n",
        "  def reward_baselines(self):\n",
        "    r_mean = self.expected_reward()\n",
        "    r_baseline = r_mean.mean(0).view(-1,1).detach().cpu().numpy()\n",
        "    return r_baseline\n",
        "\n",
        "  def cost_vector_fixed_policies(self):\n",
        "    P = self.transition_matrix()\n",
        "    cost_vector = (1 - self.beta * P.sum(0)).view(-1,1).detach().cpu().numpy() / self.N_S\n",
        "    return cost_vector\n",
        "\n",
        "  def restriction_matrices_fixed_policies(self):\n",
        "    transition_matrices = self.partial_transition_matrices()\n",
        "    restriction_matrices = {'1':[], '2':[]}\n",
        "    for player in self.players():\n",
        "      for s in self.S:\n",
        "        temp_matrix = - self.beta * transition_matrices[s][player]\n",
        "        temp_matrix[:, self.get_state_index(s)] = temp_matrix[:, self.get_state_index(s)] + 1\n",
        "        restriction_matrices[player].append(temp_matrix.clone())\n",
        "      restriction_matrices[player] = -torch.cat(restriction_matrices[player], dim=0).detach().cpu().numpy()\n",
        "    return restriction_matrices\n",
        "\n",
        "  def restriction_vectors_fixed_policies(self, alpha):\n",
        "    r_mean = self.partial_expected_reward_other()\n",
        "    restriction_vectors = {'1':[], '2':[]}\n",
        "    for player in self.players():\n",
        "      for s in self.S:\n",
        "        restriction_vectors[player].append(r_mean[player][s].view(-1,1))\n",
        "      restriction_vectors[player] = -(torch.cat(restriction_vectors[player], dim=0)+alpha).detach().cpu().numpy()\n",
        "    return restriction_vectors\n",
        "\n",
        "  def parameters_fixed_policies(self, alpha):\n",
        "    cost = self.cost_vector_fixed_policies()\n",
        "    f0 = self.reward_baselines()\n",
        "    A_ub = self.restriction_matrices_fixed_policies()\n",
        "    b_ub = self.restriction_vectors_fixed_policies(alpha)\n",
        "    return cost, f0, A_ub, b_ub\n",
        "\n",
        "  def calculate_feasible_value(self, alpha=0.1):\n",
        "    v0 = np.zeros((self.N_S,2), dtype=np.float64)\n",
        "    cost, f0, A_ub, b_ub = self.parameters_fixed_policies(alpha)\n",
        "    for player_id in self.players_id():\n",
        "      temp_res = linprog(cost, A_ub=A_ub[str(player_id+1)], b_ub=b_ub[str(player_id+1)])\n",
        "      v0[:,player_id] = temp_res.x\n",
        "    return v0\n",
        "\n",
        "  def set_feasible_value(self, alpha=0.1):\n",
        "    v0 = self.calculate_feasible_value(alpha)\n",
        "    if self.dtype == torch.float64:\n",
        "      v0 = torch.DoubleTensor(v0).clone().to(self.device)\n",
        "    else:\n",
        "      v0 = torch.FloatTensor(v0).clone().to(self.device)\n",
        "    nn.init.zeros_(self.v)\n",
        "    with torch.no_grad():\n",
        "      self.v.data.add_(v0)  \n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  # Methods related with the associated non-linear optimization problem\n",
        "\n",
        "  # Calculation of original target function: Bellman approximation error\n",
        "  def calculate_bellman_error(self):     \n",
        "    v_estimated = self.bellman_projection()\n",
        "    f_bellman = (self.v - v_estimated).sum()\n",
        "    return f_bellman\n",
        "\n",
        "  def calculate_nash_restrictions(self, hard_constraints):\n",
        "    q_estimated = self.bellman_partial_projection_other() # Dic. with an array of 'q'-values for each agent \n",
        "    g_nash = {'1':{}, '2':{}}\n",
        "    coef = 1.0\n",
        "    for s, player in self.state_player_pairs():\n",
        "      if not hard_constraints:\n",
        "        coef = self.pi[player][s].sum()\n",
        "      g_nash[player][s] = coef * q_estimated[player][s] - self.v[self.get_state_index(s), self.get_player_id(player)].item()\n",
        "    return g_nash\n",
        "  \n",
        "  def calculate_restriction_vector(self, hard_constraints):\n",
        "    g_nash = self.calculate_nash_restrictions(hard_constraints)\n",
        "    pi_vector = self.pi2vec()\n",
        "    pi_sum_vector = self.pi_sum()\n",
        "    g_list = []\n",
        "    for player in self.players():\n",
        "      for s in self.S:\n",
        "        g_list.append(g_nash[player][s])\n",
        "    for player in self.players():\n",
        "      g_list.append(-pi_vector[player])\n",
        "    for player in self.players():\n",
        "      g_list.append(pi_sum_vector[player]-1)\n",
        "    g_vector = torch.cat(g_list, dim=0)\n",
        "    return g_vector\n",
        "  \n",
        "  # Methods to calculate gradients\n",
        "  def bellman_error_gradients(self):\n",
        "    P = self.transition_matrix()\n",
        "    bellman_error_grad_v = (torch.eye(self.N_S).to(self.device) - torch.t(P)).sum(1, keepdim=True)\n",
        "\n",
        "    q_individual = self.bellman_partial_projection()\n",
        "    bellman_error_grad_pi = {'1':{}, '2':{}}\n",
        "    for s, player in self.state_player_pairs():\n",
        "      bellman_error_grad_pi[player][s] = 0.0\n",
        "      for second_player in self.players():\n",
        "        bellman_error_grad_pi[player][s] = bellman_error_grad_pi[player][s] - q_individual[player][second_player][s]  \n",
        "    return bellman_error_grad_v, bellman_error_grad_pi\n",
        "\n",
        "  def nash_restriction_gradients(self, hard_constraints):\n",
        "    P_partial = self.partial_transition_matrices()\n",
        "    next_value_dic = self.next_value_dictionary()\n",
        "    consistent_R = self.player_consistent_reward_matrices()\n",
        "\n",
        "    nash_restriction_grad_v = {'1':{}, '2':{}}\n",
        "    nash_restriction_grad_pi = {'1':{}, '2':{}}\n",
        "\n",
        "    coef = 1.0\n",
        "    for s, player in self.state_player_pairs():\n",
        "      if not hard_constraints:\n",
        "        coef = self.pi[player][s].sum()\n",
        "      Delta = torch.zeros_like(P_partial[s][player])\n",
        "      Delta[:, self.get_state_index(s)] = 1.0\n",
        "      nash_restriction_grad_v[player][s] = coef * self.beta * P_partial[s][player] - Delta\n",
        "    \n",
        "      other_player = self.other_player(player)\n",
        "      if not hard_constraints:\n",
        "        coef = self.pi[other_player][s].sum()\n",
        "      next_value_matrix = next_value_dic[s][:,:,self.get_player_id(other_player)]\n",
        "      r_matrix = consistent_R[other_player][s] # the r_matrix and the next_value_matrix need to have as rows the actions of the other player\n",
        "      if player == '1':\n",
        "        next_value_matrix = torch.t(next_value_matrix)\n",
        "      nash_restriction_grad_pi[player][s] = coef * (r_matrix + self.beta * next_value_matrix)\n",
        "    return nash_restriction_grad_v, nash_restriction_grad_pi\n",
        "  \n",
        "  # TODO: consider more than 2 players\n",
        "  def bellman_error_gradient_vector(self):\n",
        "    grad_f_v, grad_f_pi = self.bellman_error_gradients() \n",
        "    grad_f_vector = torch.zeros((self.n_vars, 1), dtype=self.dtype).to(self.device)\n",
        "    \n",
        "    for i in range(0,2):\n",
        "      grad_f_vector[i*self.N_S:(i+1)*self.N_S,:] = grad_f_v.clone()\n",
        "    \n",
        "    for player in self.players():\n",
        "      grad_f_pi_list = []\n",
        "      for s in self.S:\n",
        "        if self.more_than_one_action(player, s):\n",
        "          grad_f_pi_list.append(grad_f_pi[player][s].clone())  \n",
        "      grad_f_pi_vector = torch.cat(grad_f_pi_list, dim=0)\n",
        "      y0 = 2*self.N_S + self.get_player_id(player) * self.N_A_reduced['1']\n",
        "      yf = 2*self.N_S + self.N_A_reduced['1'] + self.get_player_id(player) * self.N_A_reduced['2']\n",
        "      grad_f_vector[y0:yf,:] = grad_f_pi_vector\n",
        "\n",
        "    return grad_f_vector\n",
        "\n",
        "  def nash_restrictions_pi_mi_jacobian_matrix(self, player, grad_g_pi):\n",
        "    other_player = self.other_player(player)\n",
        "    grad_g_pi_list = []\n",
        "    s_not_added_list = []\n",
        "    for s in self.S:\n",
        "      if self.more_than_one_action(player, s):\n",
        "        grad = grad_g_pi[player][s].clone()\n",
        "        if len(s_not_added_list) == 0:\n",
        "          grad_g_pi_list.append(grad)\n",
        "        else:\n",
        "          n_null_rows = 0\n",
        "          for s_ in s_not_added_list:\n",
        "            n_null_rows += self.A[other_player][s_]\n",
        "          n_rows = n_null_rows + grad.shape[0]\n",
        "          n_cols = grad.shape[1]\n",
        "          null_rows_and_grad_g_pi = torch.zeros((n_rows, n_cols), dtype=self.dtype).to(self.device)\n",
        "          null_rows_and_grad_g_pi[-n_rows+n_null_rows:,:] = grad\n",
        "          grad_g_pi_list.append(null_rows_and_grad_g_pi)\n",
        "          s_not_added_list = []\n",
        "      else:\n",
        "        s_not_added_list.append(s)\n",
        "    if len(s_not_added_list) != 0:\n",
        "      n_null_rows = 0\n",
        "      for s_ in s_not_added_list:\n",
        "        n_null_rows += self.A[other_player][s_]\n",
        "      n_rows = n_null_rows + grad_g_pi_list[-1].shape[0]\n",
        "      n_cols = grad_g_pi_list[-1].shape[1]\n",
        "      null_rows_and_grad_g_pi = torch.zeros((n_rows, n_cols), dtype=self.dtype).to(self.device)\n",
        "      null_rows_and_grad_g_pi[:n_rows-n_null_rows,:] = grad_g_pi_list[-1].clone()\n",
        "      grad_g_pi_list[-1] = null_rows_and_grad_g_pi\n",
        "    \n",
        "    J_gmi_pi = torch.block_diag(*grad_g_pi_list)\n",
        "    return J_gmi_pi\n",
        "\n",
        "  def nash_restrictions_pi_i_jacobian_matrix(self, player, g_nash_pure):    \n",
        "    grad_g_pi_list = []\n",
        "    s_not_added_list = []\n",
        "    player_id = self.get_player_id(player)\n",
        "    for s in self.S:\n",
        "      if self.more_than_one_action(player, s):\n",
        "        NA = self.A[player][s]\n",
        "        ones = torch.ones((NA, NA), dtype=self.dtype).to(self.device)\n",
        "        s_id = self.get_state_index(s)\n",
        "        g = g_nash_pure[player][s].view(-1) + self.v[s_id, player_id].item() \n",
        "        grad = torch.einsum('ij,jk->ik', torch.diag(g), ones)\n",
        "        if len(s_not_added_list) == 0:\n",
        "          grad_g_pi_list.append(grad)\n",
        "        else:\n",
        "          n_null_rows = 0\n",
        "          for s_ in s_not_added_list:\n",
        "            n_null_rows += self.A[player][s_]\n",
        "          n_rows = n_null_rows + grad.shape[0]\n",
        "          n_cols = grad.shape[1]\n",
        "          null_rows_and_grad_g_pi = torch.zeros((n_rows, n_cols), dtype=self.dtype).to(self.device)\n",
        "          null_rows_and_grad_g_pi[-n_rows+n_null_rows:,:] = grad\n",
        "          grad_g_pi_list.append(null_rows_and_grad_g_pi)\n",
        "          s_not_added_list = []\n",
        "      else:\n",
        "        s_not_added_list.append(s)\n",
        "    if len(s_not_added_list) != 0:\n",
        "      n_null_rows = 0\n",
        "      for s_ in s_not_added_list:\n",
        "        n_null_rows += self.A[player][s_]\n",
        "      n_rows = n_null_rows + grad_g_pi_list[-1].shape[0]\n",
        "      n_cols = grad_g_pi_list[-1].shape[1]\n",
        "      null_rows_and_grad_g_pi = torch.zeros((n_rows, n_cols), dtype=self.dtype).to(self.device)\n",
        "      null_rows_and_grad_g_pi[:n_rows-n_null_rows,:] = grad_g_pi_list[-1].clone()\n",
        "      grad_g_pi_list[-1] = null_rows_and_grad_g_pi\n",
        "    \n",
        "    J_gi_pi = torch.block_diag(*grad_g_pi_list)\n",
        "    return J_gi_pi\n",
        "\n",
        "  def build_grad_tensors(self, hard_constraints):           \n",
        "    grad_f_vector = self.bellman_error_gradient_vector()\n",
        "    grad_g_v, grad_g_pi = self.nash_restriction_gradients(hard_constraints)\n",
        "    grad_g_matrix = torch.zeros((self.n_restrictions, self.n_vars), dtype=self.dtype).to(self.device)\n",
        "    \n",
        "    if not hard_constraints:\n",
        "      g_nash_pure = self.calculate_nash_restrictions(hard_constraints=True)\n",
        "\n",
        "    for player in self.players():\n",
        "      other_player = self.other_player(player)\n",
        "\n",
        "      # fill jacobian with restriction gradients for v\n",
        "      grad_g_v_list = [grad_g_v[player][s].clone() for s in self.S]\n",
        "      J_gi_vi = torch.cat(grad_g_v_list, dim=0)\n",
        "      y0 = self.get_player_id(player) * self.N_A_total['1']\n",
        "      yf = self.N_A_total['1'] + self.get_player_id(player) * self.N_A_total['2']\n",
        "      x0 = self.get_player_id(player) * self.N_S\n",
        "      xf = x0 + self.N_S\n",
        "      grad_g_matrix[y0:yf,x0:xf] = J_gi_vi\n",
        "\n",
        "      # fill jacobian with nash restriction gradients for pi \n",
        "      J_gmi_pi = self.nash_restrictions_pi_mi_jacobian_matrix(player, grad_g_pi)\n",
        "      y0 = self.get_player_id(other_player) * self.N_A_total['1']\n",
        "      yf = self.N_A_total['1'] + self.get_player_id(other_player) * self.N_A_total['2']\n",
        "      x0 = 2*self.N_S + self.get_player_id(player) * self.N_A_reduced['1']\n",
        "      xf = 2*self.N_S + self.N_A_reduced['1'] + self.get_player_id(player) * self.N_A_reduced['2']\n",
        "      grad_g_matrix[y0:yf,x0:xf] = J_gmi_pi\n",
        "\n",
        "      if not hard_constraints:\n",
        "        J_gi_pi = self.nash_restrictions_pi_i_jacobian_matrix(player, g_nash_pure)\n",
        "        y0 = self.get_player_id(player) * self.N_A_total['1']\n",
        "        yf = self.N_A_total['1'] + self.get_player_id(player) * self.N_A_total['2']\n",
        "        grad_g_matrix[y0:yf,x0:xf] = J_gi_pi\n",
        "\n",
        "      # fill jacobian with positivity restriction gradients for pi \n",
        "      J_gpi_plus = -torch.eye(self.N_A_reduced[player]).to(self.device)\n",
        "      y0 = self.N_A_total['1'] + self.N_A_total['2'] + self.get_player_id(player) * self.N_A_reduced['1']\n",
        "      yf = (self.N_A_total['1'] + self.N_A_total['2'] + self.N_A_reduced['1'] \n",
        "            + self.get_player_id(player) * self.N_A_reduced['2'])\n",
        "      grad_g_matrix[y0:yf,x0:xf] = J_gpi_plus\n",
        "\n",
        "      # fill jacobian with unitary sum restriction gradients for pi\n",
        "      grad_gpi_one_list = []\n",
        "      for s in self.S:\n",
        "        NA = self.A[player][s]\n",
        "        if self.more_than_one_action(player, s):\n",
        "          grad_gpi_one_list.append(torch.ones((1,NA), dtype=self.dtype).to(self.device))\n",
        "\n",
        "      J_gpi_one = torch.block_diag(*grad_gpi_one_list)\n",
        "      y0 = (self.N_A_total['1'] + self.N_A_total['2'] + self.N_A_reduced['1'] \n",
        "            + self.N_A_reduced['2'] + self.get_player_id(player) * self.N_S_reduced['1'])\n",
        "      yf = (self.N_A_total['1'] + self.N_A_total['2'] + self.N_A_reduced['1'] + self.N_A_reduced['2'] \n",
        "            + self.N_S_reduced['1'] + self.get_player_id(player) * self.N_S_reduced['2'])\n",
        "      grad_g_matrix[y0:yf,x0:xf] = J_gpi_one\n",
        "\n",
        "    return grad_f_vector, grad_g_matrix\n",
        "  \n",
        "  def calculate_descent_direction(self, g_vector, grad_f_vector, grad_g_matrix, r_value=1.0):\n",
        "    g_vector_ineq = self.mask_inequality_restrictions(g_vector)\n",
        "    g_vector_eq = self.mask_equality_restrictions(g_vector)\n",
        "    g_diag_matrix = torch.diag(r_value * g_vector_ineq.view(-1))\n",
        "                                            \n",
        "    A_matrix = g_diag_matrix - torch.einsum('ik,jk->ij', grad_g_matrix, grad_g_matrix) \n",
        "    b_vector = torch.einsum('ij,jk->ik', grad_g_matrix, grad_f_vector) - r_value * g_vector_eq \n",
        "    duals_0_vector = torch.solve(b_vector, A_matrix)[0]\n",
        "\n",
        "    d0_vector = - grad_f_vector - torch.einsum('ij,ik->jk', grad_g_matrix, duals_0_vector)\n",
        "    norm_2_d0 = d0_vector.pow(2).sum().item() \n",
        "    return d0_vector, norm_2_d0, duals_0_vector, A_matrix, b_vector\n",
        "\n",
        "  def calculate_feasible_direction(self, g_vector, c_vector, duals_0_vector, \n",
        "                                  norm_2_d0, A_matrix, b_vector, rho,\n",
        "                                  grad_f_vector, grad_g_matrix,\n",
        "                                  alpha=0.5, r_value=1.0):\n",
        "    mWe = torch.solve(torch.ones_like(b_vector), A_matrix)[0]\n",
        "    g_vector_eq = self.mask_equality_restrictions(g_vector)\n",
        "    dot = (r_value * g_vector_eq.view(-1) * mWe.view(-1)).sum()\n",
        "\n",
        "    new_rho = rho\n",
        "    div = (duals_0_vector.sum() + c_vector.sum() + dot).item()\n",
        "    if div > 0:\n",
        "        rho_1 = (1.0-alpha) / div\n",
        "        if rho_1 < rho:\n",
        "          new_rho = 0.5 * rho_1\n",
        "\n",
        "    duals_vector = torch.solve(b_vector - new_rho * norm_2_d0, A_matrix)[0]\n",
        "    d_vector = - grad_f_vector - torch.einsum('ij,ik->jk', grad_g_matrix, duals_vector)\n",
        "    return d_vector, duals_vector, new_rho, mWe\n",
        "\n",
        "  @staticmethod\n",
        "  def calculate_auxiliary_bellman_error(f, g_vector, c_vector):\n",
        "    return (f - (c_vector.view(-1) * g_vector.view(-1)).sum()).item()\n",
        "\n",
        "  def feasible_gradient_descent_v2(self, f, d_v, d_pi, hard_constraints, max_steps=1200,\n",
        "                                   verbose=False, on=True, alpha_0=1.0, eps=1e-6):\n",
        "    # Procedure to find feasible step size \n",
        "    found_feasible_step_size = False\n",
        "    step_size = alpha_0\n",
        "    n_step = 0\n",
        "    max_steps = max(1, max_steps)\n",
        "    step_size_hist = []\n",
        "    while (not found_feasible_step_size) and (n_step < max_steps):\n",
        "      step_size_hist.append(step_size)\n",
        "      game_temp = self.copy_game()\n",
        "      # Update parameters performing step in feasible descent direction \n",
        "      game_temp.v.data.add_(step_size * d_v)\n",
        "      for s, player in self.state_player_pairs():\n",
        "        if game_temp.more_than_one_action(player, s):\n",
        "          game_temp.pi[player][s].data.add_(step_size * d_pi[player][s])\n",
        "\n",
        "      f_temp = game_temp.calculate_bellman_error()\n",
        "      g_vector_temp = game_temp.calculate_restriction_vector(hard_constraints)\n",
        "      \n",
        "      theta_decreased = f_temp <= f - eps\n",
        "      NAt = self.N_A_total['1'] + self.N_A_total['2']\n",
        "      g_v_valid = torch.all(g_vector_temp[:NAt] <= 0.0).item()\n",
        "      g_pi_valid = torch.all(g_vector_temp[NAt:] <= 0.0).item()\n",
        "      g_valid = g_v_valid and g_pi_valid\n",
        "      \n",
        "      # Check if the current step size results in a feasible descent direction\n",
        "      if theta_decreased and g_valid:\n",
        "        found_feasible_step_size = True\n",
        "      else:        \n",
        "        step_size /= nu\n",
        "      n_step += 1\n",
        "      if verbose:        \n",
        "        print(\"Step: {}, Step size: {:.3e}, Found feasible: {}\".format(\n",
        "            n_step, step_size, found_feasible_step_size))\n",
        "        print(theta_decreased, g_v_valid, g_pi_valid)\n",
        "        print(\"Step: {}, f: {:.3e}, f new: {:.3e}, theta: {:.3e}, theta new: {:.3e}\".format(\n",
        "            n_step, f.item(), f_temp.item(), theta, theta_temp))\n",
        "      \n",
        "    if found_feasible_step_size and on:\n",
        "      self.v.data.add_(step_size * d_v)\n",
        "      for s, player in self.state_player_pairs():\n",
        "        if self.more_than_one_action(player, s):\n",
        "          self.pi[player][s].data.add_(step_size * d_pi[player][s])\n",
        "\n",
        "    return found_feasible_step_size, n_step, f_temp, step_size, step_size_hist\n",
        "\n",
        "  def feasible_gradient_descent(self, f, g_vector, c_vector, d_vector,\n",
        "                                grad_f_vector, grad_g_matrix, d_v, d_pi, \n",
        "                                duals_vector, hard_constraints, bound_step_size, max_steps=1200, \n",
        "                                eta=0.1, nu=1.1, gamma_0=0.5, verbose=False, on=True):\n",
        "    \n",
        "    # Calculate loss function\n",
        "    theta = self.calculate_auxiliary_bellman_error(f, g_vector, c_vector)\n",
        "    \n",
        "    # Calculate required decrement in the loss function\n",
        "    grad_theta_vector = grad_f_vector - torch.einsum('ij,ik->jk', grad_g_matrix, c_vector)\n",
        "    decrement = (d_vector.view(-1) * grad_theta_vector.view(-1)).sum().item()\n",
        "    \n",
        "    # Procedure to find feasible step size \n",
        "    found_feasible_step_size = False\n",
        "    step_size = 1.0\n",
        "    n_step = 0\n",
        "    max_steps = max(1, max_steps)\n",
        "    step_size_hist = []\n",
        "    while (not found_feasible_step_size) and (n_step < max_steps):\n",
        "      step_size_hist.append(step_size)\n",
        "      game_temp = self.copy_game()\n",
        "      # Update parameters performing step in feasible descent direction \n",
        "      game_temp.v.data.add_(step_size * d_v)\n",
        "      for s, player in self.state_player_pairs():\n",
        "        if game_temp.more_than_one_action(player, s):\n",
        "          game_temp.pi[player][s].data.add_(step_size * d_pi[player][s])\n",
        "\n",
        "      f_temp = game_temp.calculate_bellman_error()\n",
        "      g_vector_temp = game_temp.calculate_restriction_vector(hard_constraints)\n",
        "      theta_temp = game_temp.calculate_auxiliary_bellman_error(f_temp, g_vector_temp, c_vector)      \n",
        "      \n",
        "      gamma = gamma_0 * torch.ones_like(duals_vector)\n",
        "      gamma[duals_vector < 0] = 1.0\n",
        "      gamma[-self.N_S_reduced['1']-self.N_S_reduced['2']:,:] = 0.0\n",
        "\n",
        "      dtheta = theta_temp-theta\n",
        "      theta_decreased = ((dtheta / eta) <= (step_size * decrement))\n",
        "      NAt = self.N_A_total['1'] + self.N_A_total['2']\n",
        "      g_v_valid = torch.all(g_vector_temp[:NAt] <= (g_vector * gamma)[:NAt]).item()\n",
        "      g_pi_valid = torch.all(g_vector_temp[NAt:] <= (g_vector * gamma)[NAt:]).item()\n",
        "      g_valid = g_v_valid and g_pi_valid\n",
        "      \n",
        "      # Check if the current step size results in a feasible descent direction\n",
        "      if theta_decreased and g_valid:\n",
        "        found_feasible_step_size = True\n",
        "      else:        \n",
        "        step_size /= nu\n",
        "      n_step += 1\n",
        "      if verbose:        \n",
        "        print(\"Step: {}, Step size: {:.3e}, Found feasible: {}\".format(\n",
        "            n_step, step_size, found_feasible_step_size))\n",
        "        print(theta_decreased, g_v_valid, g_pi_valid)\n",
        "        print(\"Step: {}, f: {:.3e}, f new: {:.3e}, theta: {:.3e}, theta new: {:.3e}\".format(\n",
        "            n_step, f.item(), f_temp.item(), theta, theta_temp))\n",
        "      \n",
        "    if found_feasible_step_size and on:\n",
        "      self.v.data.add_(step_size * d_v)\n",
        "      for s, player in self.state_player_pairs():\n",
        "        if self.more_than_one_action(player, s):\n",
        "          self.pi[player][s].data.add_(step_size * d_pi[player][s])\n",
        "\n",
        "    return found_feasible_step_size, n_step, f_temp, step_size, step_size_hist\n",
        "\n",
        "  def optimize_game(self, hard_constraints=True, max_steps=1200, n_epochs=100, verbose=False, c=1.0, rho_0=1.0, on=True, eta_0=1e-3, nu=1.1, print_each=5, r_value=1.0):\n",
        "    f_0 = self.calculate_bellman_error()\n",
        "    eta = eta_0\n",
        "    rho = rho_0\n",
        "    c_vector = c*torch.ones((self.n_restrictions,1), dtype=self.dtype).to(self.device)\n",
        "    c_vector = self.mask_equality_restrictions(c_vector)\n",
        "    step_sizes_list = []\n",
        "    step_size_hists = []\n",
        "    step_size_bounds_list = []\n",
        "    dual_vectors_list = []\n",
        "    c_vectors_list = []\n",
        "    rhos_list = []\n",
        "    with torch.no_grad():\n",
        "      for epoch in range(0, n_epochs):\n",
        "        f = self.calculate_bellman_error()\n",
        "        g_vector = self.calculate_restriction_vector(hard_constraints)\n",
        "        grad_f_vector, grad_g_matrix = self.build_grad_tensors(hard_constraints)\n",
        "        \n",
        "        d0_vector, norm_2_d0, duals_0_vector, A_matrix, b_vector = self.calculate_descent_direction(g_vector, grad_f_vector, grad_g_matrix, r_value=r_value)\n",
        "        c_vector = self.update_c_vector(c_vector, duals_0_vector)\n",
        "        c_vectors_list.append(c_vector)\n",
        "        \n",
        "        d_vector, duals_vector, new_rho, mWe = self.calculate_feasible_direction(g_vector, c_vector, duals_0_vector, \n",
        "                                                                            norm_2_d0, A_matrix, b_vector, rho, \n",
        "                                                                            grad_f_vector, grad_g_matrix, r_value=r_value)\n",
        "        dual_vectors_list.append(duals_vector)\n",
        "        rhos_list.append(new_rho)\n",
        "        d_v, d_pi, duals = self.vec2dic(d_vector, duals_vector)\n",
        "\n",
        "        g_nash_satisfied, max_g_nash, prod_zero_satisfied, max_prod_zero = self.check_nash_KKT_conditions(duals, hard_constraints)\n",
        "        pi_KKT = self.check_pi_KKT_conditions(duals)\n",
        "        g_pi_plus_satisfied, max_g_pi_plus, prod_zero_plus_satisfied, max_prod_zero_plus = pi_KKT[:4] \n",
        "        g_pi_one_satisfied, max_g_pi_one, prod_zero_one_satisfied, max_prod_zero_one = pi_KKT[4:]\n",
        "\n",
        "        bound_step_size = self.calculate_bound_step_size(duals_vector, c_vector, new_rho, norm_2_d0, grad_g_matrix, mWe)\n",
        "        step_size_bounds_list.append(bound_step_size)\n",
        "\n",
        "        found_feasible_step_size, n_step, f_new, step_size, step_size_hist = self.feasible_gradient_descent(f, g_vector, c_vector, d_vector, \n",
        "                                                                                  grad_f_vector, grad_g_matrix, d_v, d_pi, \n",
        "                                                                                  duals_vector, hard_constraints, bound_step_size, verbose=verbose, \n",
        "                                                                                  max_steps=max_steps, on=on, eta=eta, nu=nu) # TODO: check if passing wrong grad_f\n",
        "        step_sizes_list.append(step_size)\n",
        "        step_size_hists.append(step_size_hist)\n",
        "        if found_feasible_step_size:\n",
        "          #eta /= 10.0\n",
        "          rho = new_rho\n",
        "          delta_f = (f_new - f_0) / f_0 * 100\n",
        "        else:\n",
        "          break\n",
        "        \n",
        "        if ((epoch + 1) % print_each == 0):\n",
        "          print('Epoch: {}, f: {:.5e}, delta f: {:.5e}%, nash satisfied: {}, max g: {:.3e}, dual nash satisfied: {}, max product: {:.3e}, rho: {:.3e}, norm2 d0:{:.3e}, ss: {:.3e}'.format(\n",
        "              epoch, f_new.item(), delta_f.item(), g_nash_satisfied, max_g_nash, prod_zero_satisfied, max_prod_zero, rho, norm_2_d0, step_size))\n",
        "          \n",
        "          print('Epoch: {}, >0 satisfied: {}, max g>0: {:.3e}, dual >0 satisfied: {}, max product >0: {:.3e}, =1 satisfied: {}, max g=1: {:.3e}, dual =1 satisfied: {}, max product =1: {:.3e}'.format(\n",
        "            epoch, g_pi_plus_satisfied, max_g_pi_plus, prod_zero_plus_satisfied, max_prod_zero_plus, g_pi_one_satisfied, max_g_pi_one, prod_zero_one_satisfied, max_prod_zero_one))\n",
        "                  \n",
        "    self.save()\n",
        "    if self.dtype == torch.float64:\n",
        "      step_sizes = torch.DoubleTensor(step_sizes_list).to(self.device)\n",
        "      step_size_bounds = torch.DoubleTensor(step_size_bounds_list).to(self.device)\n",
        "      rhos = torch.DoubleTensor(rhos_list).to(self.device)\n",
        "    else:\n",
        "      step_sizes = torch.FloatTensor(step_sizes_list).to(self.device)\n",
        "      step_size_bounds = torch.FloatTensor(step_size_bounds_list).to(self.device)\n",
        "      rhos = torch.FloatTensor(rhos_list).to(self.device)\n",
        "    return step_sizes, step_size_bounds, dual_vectors_list, rhos, c_vectors_list, step_size_hists\n",
        "  \n",
        "  def calculate_max_eigen_g_hessian(self):\n",
        "    mu_list = []\n",
        "    grad_g_v_dic, grad_g_pi_dic = self.nash_restriction_gradients(True)\n",
        "    dim = self.N_S + self.N_A_reduced['1'] + self.N_A_reduced['2']\n",
        "    NS = self.N_S\n",
        "    for player in self.players():\n",
        "      other_player = self.other_player(player)\n",
        "      NAi = self.N_A_reduced[player]\n",
        "      NAmi = self.N_A_reduced[other_player]\n",
        "      for state in self.S_no_string:\n",
        "        s = str(state)\n",
        "        pi_sum = self.pi[player][s].sum()\n",
        "        next_v_matrix = grad_g_pi_dic[other_player][s]\n",
        "        grad_g_v_matrix = grad_g_v_dic[player][s]\n",
        "        for ai in range(0, self.A[player][s]):\n",
        "          Tr = self.transition_matrix_given_sai(player, state, ai)\n",
        "          M14 = self.beta * pi_sum * Tr \n",
        "          # next_v = next_v_matrix[ai,:].view(-1)\n",
        "          # ones_1 = torch.ones(NAi,NAmi).to(self.device)\n",
        "          # M34 = torch.einsum('ij,jk->ik', ones_1, torch.diag(next_v))\n",
        "          Ri = self.R[player][s].clone()\n",
        "          if player == '2':\n",
        "            Ri = Ri.T\n",
        "          v_player = self.v[:,self.get_player_id(player)].view(-1,1)\n",
        "          next_v = Ri[ai,:].view(1,-1) + self.beta * torch.einsum('ji,jk->ki', Tr, v_player)\n",
        "          ones_1 = torch.ones((NAi,1), dtype=self.dtype).to(self.device)\n",
        "          M34 = torch.einsum('ij,jk->ik', ones_1, next_v)\n",
        "          \n",
        "          # p = grad_g_v_matrix[ai,:].view(-1)\n",
        "          # id_s = self.get_state_index(s)\n",
        "          # p[id_s] += 1\n",
        "          # ones_2 = torch.ones(NS,NAi).to(self.device)\n",
        "          # M13 = torch.einsum('ij,jk->ik', torch.diag(p), ones_2)\n",
        "          p = torch.einsum('ij,jk->ik', Tr, self.pi[other_player][s]) #grad_g_v_matrix[ai,:].view(-1)\n",
        "          ones_2 = torch.ones((NAi,1), dtype=self.dtype).to(self.device)\n",
        "          M13 = self.beta * torch.einsum('ij,kj->ik', p, ones_2)\n",
        "\n",
        "          # print(M13.shape, M14.shape, M34.shape)\n",
        "\n",
        "          M = torch.zeros((dim, dim), dtype=self.dtype).to(self.device)\n",
        "          M[:NS,NS:NS+NAi] = M13.clone()\n",
        "          M[:NS,NS+NAi:] = M14.clone()\n",
        "          M[NS:NS+NAi,:NS] = M13.T.clone()\n",
        "          M[NS:NS+NAi,NS+NAi:] = M34.clone()\n",
        "          M[NS+NAi:,:NS] = M14.T.clone()\n",
        "          M[NS+NAi:,NS:NS+NAi] = M34.T.clone()\n",
        "\n",
        "          M_eigval, M_eigvec = torch.eig(M)\n",
        "          mu_list.append(M_eigval.max())\n",
        "    mu_vector = torch.DoubleTensor(mu_list).view(-1,1).to(self.device)\n",
        "    return mu_vector\n",
        "\n",
        "  def calculate_bound_step_size(self, duals_vector, c_vector, rho, d0_2norm, \n",
        "                                grad_g_matrix, mWe, gamma_0=0.5, r_value=1.0):\n",
        "    beta_1_tau = 1 + rho * d0_2norm**0.5 * torch.einsum('ji,jk->ik', grad_g_matrix, mWe).pow(2).sum()**0.5\n",
        "    beta_tau = beta_1_tau**(-2)\n",
        "    if self.N_S == 1:\n",
        "      mu_vector = self.calculate_max_eigen_g_hessian()\n",
        "    else:\n",
        "      mu_vector = torch.ones_like(duals_vector)\n",
        "    tau_lambda = (1-gamma_0) / (r_value * (duals_vector + c_vector).max())\n",
        "    tau_mu = 2 * beta_tau * rho / mu_vector.max()\n",
        "    tau = np.infty\n",
        "    if duals_vector.max() > 0.0:\n",
        "      tau = tau_lambda.item()\n",
        "      if mu_vector.max() > 0.0:\n",
        "        tau = min(tau, tau_mu.item())\n",
        "    else:\n",
        "      if mu_vector.max() > 0.0:\n",
        "        tau = tau_mu.item()\n",
        "    return tau\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  # Methods related with the KKT conditions\n",
        "\n",
        "  def check_nash_KKT_conditions(self, lambda_nash, hard_constraints, tol=1e-8):\n",
        "    with torch.no_grad():\n",
        "      # Calculate restrictions\n",
        "      g_nash = self.calculate_nash_restrictions(hard_constraints)\n",
        "\n",
        "      g_nash_satisfied = True\n",
        "      product_zero_satisfied = True\n",
        "      \n",
        "      max_g_nash = -np.infty\n",
        "      max_product_zero = -np.infty\n",
        "      \n",
        "      for player in self.players():\n",
        "        remaining_duals = lambda_nash[player].clone()\n",
        "        for s in self.S:\n",
        "          if self.more_than_one_action(player, s):\n",
        "            NA = self.A[player][s]\n",
        "            g_nash_satisfied = g_nash_satisfied and torch.all(g_nash[player][s] <= 0)\n",
        "            max_g_nash = max(max_g_nash, g_nash[player][s].max().item())\n",
        "\n",
        "            lambda_g_nash_product = g_nash[player][s].view(-1) * remaining_duals[:NA,:].view(-1)\n",
        "            product_zero_satisfied = product_zero_satisfied and torch.all(lambda_g_nash_product.abs() <= tol)\n",
        "            max_product_zero = max(max_product_zero, lambda_g_nash_product.abs().max().item())\n",
        "            remaining_duals = remaining_duals[NA:,:]\n",
        "      return g_nash_satisfied, max_g_nash, product_zero_satisfied, max_product_zero\n",
        "\n",
        "  def check_pi_KKT_conditions(self, duals, tol=1e-8):\n",
        "    pi_vector = self.pi2vec()\n",
        "    pi_sum_vector = self.pi_sum()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      g_pi_plus_satisfied = True\n",
        "      g_pi_one_satisfied = True\n",
        "\n",
        "      product_zero_plus_satisfied = True\n",
        "      product_zero_one_satisfied = True\n",
        "\n",
        "      max_g_pi_plus = -np.infty\n",
        "      max_g_pi_one = -np.infty\n",
        "\n",
        "      max_product_zero_plus = -np.infty\n",
        "      max_product_zero_one = -np.infty\n",
        "\n",
        "      for player in self.players():\n",
        "        g_pi_plus_satisfied = g_pi_plus_satisfied and torch.all(pi_vector[player] >= 0)\n",
        "        g_pi_one_satisfied = g_pi_one_satisfied and torch.all(pi_sum_vector[player] <= 1)\n",
        "\n",
        "        max_g_pi_plus = max(max_g_pi_plus, -pi_vector[player].min().item())\n",
        "        max_g_pi_one = max(max_g_pi_one, (pi_sum_vector[player]-1).min().item())\n",
        "\n",
        "        NAt = self.N_A_total[player]\n",
        "        NAr = self.N_A_reduced[player]\n",
        "        lambda_g_pi_plus_product = -pi_vector[player].view(-1) * duals[player][NAt:NAt+NAr,:].view(-1) # TODO: fix for assymetric number of actions\n",
        "        product_zero_plus_satisfied = product_zero_plus_satisfied and torch.all(lambda_g_pi_plus_product.abs() <= tol)\n",
        "        max_product_zero_plus = max(max_product_zero_plus, lambda_g_pi_plus_product.abs().max().item())\n",
        "        lambda_g_pi_one_product = (pi_sum_vector[player].view(-1)-1) * duals[player][NAt+NAr:,:].view(-1)\n",
        "        product_zero_one_satisfied = product_zero_one_satisfied and torch.all(lambda_g_pi_one_product.abs() <= tol)\n",
        "        max_product_zero_one = max(max_product_zero_one, lambda_g_pi_one_product.abs().max().item())\n",
        "    \n",
        "      return (g_pi_plus_satisfied, max_g_pi_plus, product_zero_plus_satisfied, max_product_zero_plus, \n",
        "              g_pi_one_satisfied, max_g_pi_one, product_zero_one_satisfied, max_product_zero_one)   "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZNA9Fv1-1-h"
      },
      "source": [
        "# Prisoner's Dilemma With Incentives\n",
        "\n",
        "Now, we will create an instance of a stochastic game that corresponds to the prisoner's dilemma game. This game will include a modification that allows for mutual incentives between the prisoners. For this, we first need to specify the required player, state, and action sets $N, S, A$, and the reward and transition maps $R,T$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPVt4jdFpH13"
      },
      "source": [
        "# Define player set N\n",
        "N = 2\n",
        "\n",
        "# Define state set S\n",
        "M = 5\n",
        "G = [('G',)]\n",
        "O = [('O',i) for i in range(1,2+1)]\n",
        "E1 = [('E1',i,j) for i in range(0,2) for j in range(0,M+1)]\n",
        "E2 = [('E2',i,j) for i in range(0,2) for j in range(0,M+1)]\n",
        "R1 = [('R1',i) for i in range(0,2)]\n",
        "R2 = [('R2',i) for i in range(0,2)]\n",
        "S = list(itertools.chain(G.copy(), O.copy(), E1.copy(), E2.copy(), R1.copy(), R2.copy())) \n",
        "\n",
        "# Define action set A^i(s) per player and state\n",
        "A = {'1':{}, '2':{}}\n",
        "for player_id in range(0, N):\n",
        "  player = str(player_id+1)\n",
        "  other_player_id = 1-player_id\n",
        "  other_player = str(other_player_id+1)\n",
        "  A[player][str(('G',))] = 2\n",
        "  A[player][str(('O',player_id+1))] = 2*(M+1)\n",
        "  A[player][str(('O',other_player_id+1))] = 1\n",
        "  for i in range(0,2):\n",
        "    for j in range(0,M+1):\n",
        "      A[player][str(('E'+player,i,j))] = 2\n",
        "      A[player][str(('E'+other_player,i,j))] = 1\n",
        "    A[player][str(('R'+player,i))] = 2\n",
        "    A[player][str(('R'+other_player,i))] = 1\n",
        "\n",
        "# Define discount factor\n",
        "beta = 0.99\n",
        "\n",
        "# Define dtype\n",
        "dtype = torch.float32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3p_qDLQ0kl3"
      },
      "source": [
        "# Define payoff map R\n",
        "R1 = np.array([[3.,0.],[5.,1.]])\n",
        "R2 = np.array([[3.,5.],[0.,1.]])\n",
        "\n",
        "def offer_accepted(action):\n",
        "  if action == 0:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def prisoner_dilemma_rewards(state, actions):\n",
        "  if 'G' in state:\n",
        "    r1 = R1[actions[0], actions[1]]\n",
        "    r2 = R2[actions[0], actions[1]]\n",
        "  elif 'O' in state:\n",
        "    r1 = r2 = 0.0\n",
        "  elif 'E1' in state:\n",
        "    _, _, offeral = state\n",
        "    if offer_accepted(actions[0]):\n",
        "      r1 = offeral\n",
        "      r2 = -offeral\n",
        "    else:\n",
        "      r1 = r2 = 0\n",
        "  elif 'E2' in state:\n",
        "    _, _, offeral = state\n",
        "    if offer_accepted(actions[1]):\n",
        "      r1 = -offeral\n",
        "      r2 = offeral\n",
        "    else:\n",
        "      r1 = r2 = 0\n",
        "  elif 'R1' in state:\n",
        "    _, i = state\n",
        "    r1 = R1[actions[0], i]\n",
        "    r2 = R2[actions[0], i]\n",
        "  elif 'R2' in state:\n",
        "    _, i = state\n",
        "    r1 = R1[i, actions[1]]\n",
        "    r2 = R2[i, actions[1]]\n",
        "  else:\n",
        "    assert 0 == 1, 'Invalid state'\n",
        "  return r1, r2\n",
        "\n",
        "def prisoner_dilemma_reward_matrices(s):\n",
        "  if 'G' in s:\n",
        "    RM1 = R1.copy()\n",
        "    RM2 = R2.copy()\n",
        "  else:\n",
        "    N_A1 = A['1'][str(s)]\n",
        "    N_A2 = A['2'][str(s)]\n",
        "    if dtype == torch.float64:\n",
        "      RM1 = np.zeros((N_A1,N_A2), dtype=np.float64)\n",
        "      RM2 = np.zeros((N_A1,N_A2), dtype=np.float64)\n",
        "    else:\n",
        "      RM1 = np.zeros((N_A1,N_A2), dtype=np.float32)\n",
        "      RM2 = np.zeros((N_A1,N_A2), dtype=np.float32)\n",
        "    for a1 in range(0,N_A1):\n",
        "      for a2 in range(0,N_A2):\n",
        "        r1, r2 = prisoner_dilemma_rewards(s, [a1,a2])\n",
        "        RM1[a1,a2] = r1\n",
        "        RM2[a1,a2] = r2\n",
        "  return RM1, RM2  \n",
        "\n",
        "R = {'1':{}, '2':{}}\n",
        "for s in S:\n",
        "  RM1, RM2 = prisoner_dilemma_reward_matrices(s)\n",
        "  if dtype == torch.float64:\n",
        "    R['1'][str(s)] = torch.DoubleTensor(RM1).clone()\n",
        "    R['2'][str(s)] = torch.DoubleTensor(RM2).clone()\n",
        "  else:\n",
        "    \n",
        "    R['1'][str(s)] = torch.FloatTensor(RM1).clone()\n",
        "    R['2'][str(s)] = torch.FloatTensor(RM2).clone()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCEX15Bq4cyE"
      },
      "source": [
        "# Define transition map\n",
        "def prisoner_dilemma_transition_info(state, actions):\n",
        "  if 'G' in state or 'R1' in state or 'R2' in state:\n",
        "    T = [(('O',1), 0.5), (('O',2), 0.5)]\n",
        "    return ('R', T)\n",
        "  elif 'O' in state:\n",
        "    player_id = state[1]-1\n",
        "    other_player_id = 1 - player_id\n",
        "    other_player = str(other_player_id + 1)\n",
        "    offeral = actions[player_id] // 2\n",
        "    action_requested = actions[player_id] % 2\n",
        "    return ('D', ('E'+other_player, action_requested, offeral))\n",
        "  elif 'E1' in state:\n",
        "    _, action_requested, _ = state\n",
        "    if offer_accepted(actions[0]):\n",
        "      return ('D', ('R2', action_requested))\n",
        "    else:\n",
        "      return ('D', ('G',))\n",
        "  elif 'E2' in state:\n",
        "    _, action_requested, _ = state\n",
        "    if offer_accepted(actions[1]):\n",
        "      return ('D', ('R1', action_requested))\n",
        "    else:\n",
        "      return ('D', ('G',))   \n",
        "  else:\n",
        "    assert 0 == 1, 'Invalid state' \n",
        "\n",
        "prisoner_dilemma_transition_types = {}\n",
        "for state in S:\n",
        "  if 'G' in state or 'R1' in state or 'R2' in state:\n",
        "    prisoner_dilemma_transition_types[str(state)] = (0,0) \n",
        "  else:\n",
        "    prisoner_dilemma_transition_types[str(state)] = (1,1) # entries correspond to deterministic behaviour and dependence on actions\n",
        "\n",
        "T = (prisoner_dilemma_transition_info, prisoner_dilemma_transition_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BNAscRPo2x-"
      },
      "source": [
        "Now we initialize the game and optimize it with the Herskovits algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvdgNUPN510L"
      },
      "source": [
        "game = multi_player_game(N, S, A, R, T, beta, device, dtype=dtype).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLuixBYJl64d",
        "outputId": "de94d5c5-52a3-42e3-831d-0e259cf2b67d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "game.optimize_game(verbose=False, n_epochs=200, print_each=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19, f: 4.04823e+01, delta f: -5.86617e+01%, nash satisfied: True, max g: -2.075e-03, dual nash satisfied: False, max product: 1.292e+01, rho: 2.531e-04, norm2 d0:1.362e+01, ss: 1.509e-02\n",
            "Epoch: 19, >0 satisfied: True, max g>0: -1.080e-04, dual >0 satisfied: False, max product >0: 3.879e-01, =1 satisfied: True, max g=1: -1.321e-01, dual =1 satisfied: False, max product =1: 9.815e+00\n",
            "Epoch: 39, f: 3.29545e+01, delta f: -6.63486e+01%, nash satisfied: True, max g: -1.979e-04, dual nash satisfied: False, max product: 4.835e+01, rho: 1.259e-04, norm2 d0:3.298e+01, ss: 5.289e-03\n",
            "Epoch: 39, >0 satisfied: True, max g>0: -2.232e-05, dual >0 satisfied: False, max product >0: 7.239e-01, =1 satisfied: True, max g=1: -9.959e-02, dual =1 satisfied: False, max product =1: 2.087e+01\n",
            "Epoch: 59, f: 3.19475e+01, delta f: -6.73769e+01%, nash satisfied: True, max g: -9.966e-05, dual nash satisfied: False, max product: 9.523e+01, rho: 1.259e-04, norm2 d0:5.148e+01, ss: 1.458e-06\n",
            "Epoch: 59, >0 satisfied: True, max g>0: -2.386e-05, dual >0 satisfied: False, max product >0: 1.793e+00, =1 satisfied: True, max g=1: -9.312e-02, dual =1 satisfied: False, max product =1: 3.048e+01\n",
            "Epoch: 79, f: 3.17125e+01, delta f: -6.76169e+01%, nash satisfied: True, max g: -9.823e-05, dual nash satisfied: False, max product: 1.105e+02, rho: 1.259e-04, norm2 d0:6.008e+01, ss: 8.104e-06\n",
            "Epoch: 79, >0 satisfied: True, max g>0: -2.542e-05, dual >0 satisfied: False, max product >0: 2.157e+00, =1 satisfied: True, max g=1: -9.089e-02, dual =1 satisfied: False, max product =1: 3.467e+01\n",
            "Epoch: 99, f: 3.16259e+01, delta f: -6.77053e+01%, nash satisfied: True, max g: -6.771e-05, dual nash satisfied: False, max product: 1.174e+02, rho: 6.016e-05, norm2 d0:7.104e+01, ss: 1.556e-04\n",
            "Epoch: 99, >0 satisfied: True, max g>0: -1.308e-05, dual >0 satisfied: False, max product >0: 2.340e+00, =1 satisfied: True, max g=1: -8.995e-02, dual =1 satisfied: False, max product =1: 3.813e+01\n",
            "Epoch: 119, f: 3.16149e+01, delta f: -6.77166e+01%, nash satisfied: True, max g: -6.723e-05, dual nash satisfied: False, max product: 1.184e+02, rho: 6.016e-05, norm2 d0:7.157e+01, ss: 4.159e-06\n",
            "Epoch: 119, >0 satisfied: True, max g>0: -1.333e-05, dual >0 satisfied: False, max product >0: 2.347e+00, =1 satisfied: True, max g=1: -8.980e-02, dual =1 satisfied: False, max product =1: 3.822e+01\n",
            "Epoch: 139, f: 3.15713e+01, delta f: -6.77611e+01%, nash satisfied: True, max g: -5.341e-05, dual nash satisfied: False, max product: 1.212e+02, rho: 6.016e-05, norm2 d0:7.437e+01, ss: 2.312e-05\n",
            "Epoch: 139, >0 satisfied: True, max g>0: -1.356e-05, dual >0 satisfied: False, max product >0: 2.422e+00, =1 satisfied: True, max g=1: -8.923e-02, dual =1 satisfied: False, max product =1: 3.956e+01\n",
            "Epoch: 159, f: 3.15687e+01, delta f: -6.77637e+01%, nash satisfied: True, max g: -5.293e-05, dual nash satisfied: False, max product: 1.219e+02, rho: 6.016e-05, norm2 d0:7.480e+01, ss: 7.560e-14\n",
            "Epoch: 159, >0 satisfied: True, max g>0: -1.361e-05, dual >0 satisfied: False, max product >0: 2.423e+00, =1 satisfied: True, max g=1: -8.920e-02, dual =1 satisfied: False, max product =1: 3.969e+01\n",
            "Epoch: 179, f: 3.15687e+01, delta f: -6.77637e+01%, nash satisfied: True, max g: -5.293e-05, dual nash satisfied: False, max product: 1.219e+02, rho: 6.016e-05, norm2 d0:7.480e+01, ss: 7.560e-14\n",
            "Epoch: 179, >0 satisfied: True, max g>0: -1.361e-05, dual >0 satisfied: False, max product >0: 2.423e+00, =1 satisfied: True, max g=1: -8.920e-02, dual =1 satisfied: False, max product =1: 3.969e+01\n",
            "Epoch: 199, f: 3.15687e+01, delta f: -6.77637e+01%, nash satisfied: True, max g: -5.293e-05, dual nash satisfied: False, max product: 1.219e+02, rho: 6.016e-05, norm2 d0:7.480e+01, ss: 7.560e-14\n",
            "Epoch: 199, >0 satisfied: True, max g>0: -1.361e-05, dual >0 satisfied: False, max product >0: 2.423e+00, =1 satisfied: True, max g=1: -8.920e-02, dual =1 satisfied: False, max product =1: 3.969e+01\n",
            "Game 0 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J01u_GSogPj"
      },
      "source": [
        "We can see that the algorithm does not converge to the global optima, where $f(v^*,\\pi^*)$ becomes 0 and $v^*$ corresponds precisely to the value of the game when the policy is $\\pi^*$. It might be interesting to study why the algorithm does not converge. With this mind, we will consider a simpler case with only one state.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3cBY8Y3oQLv"
      },
      "source": [
        "# Iterated Prisoner's Dilemma\n",
        "\n",
        "Since the version with incentives has 7 states that correspond to more than 100 variables, we will focus now on the original iterated version with only one state.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_dRfGBEoQLx"
      },
      "source": [
        "# Define player set N\n",
        "N = 2\n",
        "\n",
        "# Define state set S\n",
        "G = [('G',)]\n",
        "S = list(itertools.chain(G.copy())) \n",
        "\n",
        "# Define action set A^i(s) per player and state\n",
        "A = {'1':{}, '2':{}}\n",
        "for player_id in range(0, N):\n",
        "  player = str(player_id+1)\n",
        "  A[player][str(('G',))] = 2\n",
        "  \n",
        "# Define discount factor\n",
        "beta = 0.99\n",
        "\n",
        "# Define dtype\n",
        "dtype = torch.float32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQKCVzaAoQL0"
      },
      "source": [
        "# Define payoff map R\n",
        "R1 = np.array([[3.,0.],[5.,1.]])\n",
        "R2 = np.array([[3.,5.],[0.,1.]])\n",
        "\n",
        "def iterated_prisoner_dilemma_rewards(state, actions):\n",
        "  if 'G' in state:\n",
        "    r1 = R1[actions[0], actions[1]]\n",
        "    r2 = R2[actions[0], actions[1]]\n",
        "  else:\n",
        "    assert 0 == 1, 'Invalid state'\n",
        "  return r1, r2\n",
        "\n",
        "def iterated_prisoner_dilemma_reward_matrices(s):\n",
        "  RM1 = R1.copy()\n",
        "  RM2 = R2.copy()\n",
        "  return RM1, RM2  \n",
        "\n",
        "R = {'1':{}, '2':{}}\n",
        "for s in S:\n",
        "  RM1, RM2 = iterated_prisoner_dilemma_reward_matrices(s)\n",
        "  if dtype == torch.float64:\n",
        "    R['1'][str(s)] = torch.DoubleTensor(RM1).clone()\n",
        "    R['2'][str(s)] = torch.DoubleTensor(RM2).clone()\n",
        "  else:\n",
        "    R['1'][str(s)] = torch.FloatTensor(RM1).clone()\n",
        "    R['2'][str(s)] = torch.FloatTensor(RM2).clone()\n",
        "\n",
        "# Define transition map\n",
        "def iterated_prisoner_dilemma_transition_map(state, actions):\n",
        "  return ('D', ('G',))\n",
        " \n",
        "iterated_prisoner_dilemma_transition_types = {str(('G',)): (1,1)}\n",
        "T = (iterated_prisoner_dilemma_transition_map, iterated_prisoner_dilemma_transition_types)\n",
        "\n",
        "name = 'PrisonersDilemmaIterated-v0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1oxLxQZoQL5"
      },
      "source": [
        "game_iterated = multi_player_game(N, S, A, R, T, beta, device, dtype=dtype, name=name).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70_DxEsDoQL7",
        "outputId": "8ad3b9a7-260f-42d1-a78d-b57ed38e55a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "game_iterated.optimize_game(verbose=False, n_epochs=300, print_each=50, eta_0=0.9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 49, f: 1.65299e+00, delta f: -6.42302e+01%, nash satisfied: True, max g: -1.173e-04, dual nash satisfied: False, max product: 5.270e-02, rho: 1.708e-04, norm2 d0:1.343e+02, ss: 2.673e-02\n",
            "Epoch: 49, >0 satisfied: True, max g>0: -8.131e-05, dual >0 satisfied: False, max product >0: 4.166e-02, =1 satisfied: True, max g=1: -8.607e-02, dual =1 satisfied: False, max product =1: 6.686e+01\n",
            "Epoch: 99, f: 1.62729e+00, delta f: -6.47862e+01%, nash satisfied: True, max g: -6.294e-05, dual nash satisfied: False, max product: 4.357e-02, rho: 5.440e-05, norm2 d0:2.643e+02, ss: 2.009e-02\n",
            "Epoch: 99, >0 satisfied: True, max g>0: -1.963e-05, dual >0 satisfied: False, max product >0: 2.935e-02, =1 satisfied: True, max g=1: -6.139e-02, dual =1 satisfied: False, max product =1: 1.194e+02\n",
            "Epoch: 149, f: 1.58406e+00, delta f: -6.57217e+01%, nash satisfied: True, max g: -4.959e-05, dual nash satisfied: False, max product: 2.594e-02, rho: 1.864e-05, norm2 d0:3.883e+02, ss: 1.134e-02\n",
            "Epoch: 149, >0 satisfied: True, max g>0: -5.607e-06, dual >0 satisfied: False, max product >0: 3.040e-02, =1 satisfied: True, max g=1: -4.722e-02, dual =1 satisfied: False, max product =1: 1.816e+02\n",
            "Epoch: 199, f: 1.45796e+00, delta f: -6.84504e+01%, nash satisfied: True, max g: -1.431e-04, dual nash satisfied: False, max product: 1.202e-01, rho: 1.864e-05, norm2 d0:3.982e+01, ss: 1.046e-03\n",
            "Epoch: 199, >0 satisfied: True, max g>0: -3.035e-04, dual >0 satisfied: False, max product >0: 1.640e-01, =1 satisfied: True, max g=1: -2.915e-02, dual =1 satisfied: False, max product =1: 8.403e+01\n",
            "Epoch: 249, f: 1.39067e+00, delta f: -6.99065e+01%, nash satisfied: True, max g: -4.578e-05, dual nash satisfied: False, max product: 2.251e-02, rho: 5.559e-06, norm2 d0:7.569e+02, ss: 1.158e-16\n",
            "Epoch: 249, >0 satisfied: True, max g>0: -5.065e-06, dual >0 satisfied: False, max product >0: 2.145e-02, =1 satisfied: True, max g=1: -2.418e-02, dual =1 satisfied: False, max product =1: 3.490e+02\n",
            "Epoch: 299, f: 1.39067e+00, delta f: -6.99065e+01%, nash satisfied: True, max g: -4.578e-05, dual nash satisfied: False, max product: 2.251e-02, rho: 5.559e-06, norm2 d0:7.569e+02, ss: 1.158e-16\n",
            "Epoch: 299, >0 satisfied: True, max g>0: -5.065e-06, dual >0 satisfied: False, max product >0: 2.145e-02, =1 satisfied: True, max g=1: -2.418e-02, dual =1 satisfied: False, max product =1: 3.490e+02\n",
            "Game 0 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9MwlBL3t2i2"
      },
      "source": [
        "\"Fortunately\", the algorithm also gets stucked in a local suboptima in the simpler case of only one state. Therefore we can investigate what is happening in this case and try to translate to the other one.\n",
        "\n",
        "First, we will see what is the policy discovered by the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHKhixv7uLYk",
        "outputId": "0681b88f-d8ca-4b08-c674-490fcfa246d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "for pname, p in game_iterated.named_parameters():\n",
        "  print(pname, p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v Parameter containing:\n",
            "tensor([[28.7552, 28.7552]], requires_grad=True)\n",
            "pi1.('G',) Parameter containing:\n",
            "tensor([[5.0651e-06],\n",
            "        [9.7582e-01]], requires_grad=True)\n",
            "pi2.('G',) Parameter containing:\n",
            "tensor([[5.0651e-06],\n",
            "        [9.7582e-01]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaH7ri7GwDnN"
      },
      "source": [
        "We can notice that the policy $\\pi^*$ corresponds to both prisoners **defecting**. Thus, the algorithm is actually finding the appropriate optimal policy. However, the associated $v^*$ vector seems off. We now that the value of the iterated game should be $v=\\frac{1}{1-\\beta}=100$, so not only the value is incorrect, but also smaller, much smaller. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHMo3bLKyTiw"
      },
      "source": [
        "While the policy is correctly selecting the action of **defecting**, we can see that it is yet far from being an appropriate distribution, since the sum of probabilities is around $0.976$. If we consider this disturbance in the value calculation we obtain a value of $\\tilde{v}\\approx\\frac{1}{1-\\beta \\pi^i(\\text{D})}\\approx 29.621$. This estimation is pretty close to $v^*$, so this \"non-unitarity\" of $\\pi$ is what causes the problem with $v^*$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RII_9GYK3DYY"
      },
      "source": [
        "Now, this is not the only problem associated with $\\pi^*$ not being unitary. The restrictions used in the optimization problem are $v^i(s)\\geq \\mathcal{pB}_{\\pi^{-i}}(v^i,s,a),\\forall\\hspace{2pt}i,s,a$, where $\\mathcal{B}_\\pi(\\cdotp)$ denotes the Bellman operator given the policy $\\pi$ and $\\mathcal{pB}_{\\pi^{-i}}(\\cdotp)$ the \"partial\" Bellman operator that uses only the information of the \"partial\" policy $\\pi^{-i}$. If we multiply each restriction by its corresponding probability $\\pi^i(a|s)$ and sum all of these restrictions, we will obtain: $v^i(s)\\geq\\frac{\\mathcal{B}_\\pi(v^i,s)}{\\sum_a\\pi^i(a|s)}$. This inequality implies that if the policy is not unitary, any feasible value vector $v$ has to be strictly larger than its Bellman projection $\\mathcal{B}_\\pi(v)$, and as a result $v$ cannot correspond to the value of the game."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQyDneiQ4EMM"
      },
      "source": [
        "Unfurtunately, this explanation does not clarify why the algorithm get's stucked in a local suboptima. Given that the policy is in general not unitary, the constraints are more restrictive and, as a result, we know that the loss function will be larger than 0 unless the global optima of the original problem is found. Thus, it is unlikely that modifying the constraints, multiplying the partial projections by $\\sum\\pi^i(a|s)$, will solve the current problem. It is also unclear if such a modification will result in any improvement. Nevertheless, we will attempt this change to evaluate the effects. For this, we need to add to the jacobian of $\\textbf{g}$ the gradients of the policy of a player with its own restrictions (which were previously $\\boldsymbol{0}$). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lqEqCnpJ1x0"
      },
      "source": [
        "game_iterated_2 = multi_player_game(N, S, A, R, T, beta, device, dtype=dtype, name=name).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofZQxhoX4J7i"
      },
      "source": [
        "After the modification, we can simply add the argument ```hard_constraints=False``` to the optimization method. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSv6gh7IJ1x8",
        "outputId": "b7679f9c-6009-4feb-faea-06d0fdccd96c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "xxx = game_iterated_2.optimize_game(hard_constraints=False, verbose=False, n_epochs=300, print_each=50, eta_0=0.9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 49, f: 3.52859e-04, delta f: -9.99924e+01%, nash satisfied: True, max g: -7.057e-05, dual nash satisfied: False, max product: 6.384e-02, rho: 1.003e-04, norm2 d0:1.350e+02, ss: 2.430e-02\n",
            "Epoch: 49, >0 satisfied: True, max g>0: -4.376e-05, dual >0 satisfied: False, max product >0: 1.744e-02, =1 satisfied: True, max g=1: -4.723e-02, dual =1 satisfied: False, max product =1: 5.662e+01\n",
            "Epoch: 99, f: 7.15256e-05, delta f: -9.99985e+01%, nash satisfied: True, max g: -2.098e-05, dual nash satisfied: False, max product: 5.444e-02, rho: 3.494e-05, norm2 d0:2.212e+02, ss: 8.649e-04\n",
            "Epoch: 99, >0 satisfied: True, max g>0: -1.646e-05, dual >0 satisfied: False, max product >0: 2.022e-02, =1 satisfied: True, max g=1: -3.532e-02, dual =1 satisfied: False, max product =1: 9.531e+01\n",
            "Epoch: 149, f: 1.86920e-04, delta f: -9.99960e+01%, nash satisfied: True, max g: -7.534e-05, dual nash satisfied: False, max product: 3.909e-02, rho: 1.236e-05, norm2 d0:2.975e+02, ss: 2.243e-03\n",
            "Epoch: 149, >0 satisfied: True, max g>0: -4.197e-06, dual >0 satisfied: False, max product >0: 2.181e-02, =1 satisfied: True, max g=1: -2.845e-02, dual =1 satisfied: False, max product =1: 1.400e+02\n",
            "Epoch: 199, f: 8.77380e-05, delta f: -9.99981e+01%, nash satisfied: True, max g: -2.480e-05, dual nash satisfied: False, max product: 1.754e-02, rho: 1.236e-05, norm2 d0:3.460e+02, ss: 8.649e-04\n",
            "Epoch: 199, >0 satisfied: True, max g>0: -4.762e-06, dual >0 satisfied: False, max product >0: 1.546e-02, =1 satisfied: True, max g=1: -2.469e-02, dual =1 satisfied: False, max product =1: 1.588e+02\n",
            "Epoch: 249, f: 1.28746e-03, delta f: -9.99721e+01%, nash satisfied: True, max g: -1.431e-04, dual nash satisfied: False, max product: 2.089e-01, rho: 1.236e-05, norm2 d0:2.888e+02, ss: 1.062e-04\n",
            "Epoch: 249, >0 satisfied: True, max g>0: -1.223e-05, dual >0 satisfied: False, max product >0: 3.393e-02, =1 satisfied: True, max g=1: -1.978e-02, dual =1 satisfied: False, max product =1: 1.642e+02\n",
            "Epoch: 299, f: 1.67847e-04, delta f: -9.99964e+01%, nash satisfied: True, max g: -6.485e-05, dual nash satisfied: False, max product: 7.639e-02, rho: 4.230e-06, norm2 d0:4.668e+02, ss: 1.053e-16\n",
            "Epoch: 299, >0 satisfied: True, max g>0: -1.326e-06, dual >0 satisfied: False, max product >0: 1.510e-02, =1 satisfied: True, max g=1: -1.919e-02, dual =1 satisfied: False, max product =1: 2.308e+02\n",
            "Game 0 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKPTYvun_yD3",
        "outputId": "05fcae0b-1766-40ee-8eef-1063d3132e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "for pname, p in game_iterated_2.named_parameters():\n",
        "  print(pname, p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v Parameter containing:\n",
            "tensor([[20.1433, 20.1441]], requires_grad=True)\n",
            "pi1.('G',) Parameter containing:\n",
            "tensor([[1.3262e-06],\n",
            "        [9.8081e-01]], requires_grad=True)\n",
            "pi2.('G',) Parameter containing:\n",
            "tensor([[1.6019e-06],\n",
            "        [9.8068e-01]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BH7C0FH4gAy"
      },
      "source": [
        "With the modification on the Nash constraints the solution found is now farther from the optimal point. Nonetheless, we can see that the loss is actually much lower. This is the case since $v^*$ is now allowed to get closer to the boundary and so it must be closer to the value of the game under $\\pi^*$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05QyrPXqAwpa"
      },
      "source": [
        "Since this change did not result in any real improvement (as expected), we'll move on to the next approximation. Let's try to check now the Lemmas of the algorithm. For this, we will replicate the optimization method of the game class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMj7gTpF7Y89"
      },
      "source": [
        "hard_constraints = False\n",
        "f_0 = game_iterated_2.calculate_bellman_error()\n",
        "rho = 1.0\n",
        "c_vector = 1.0*torch.ones((game_iterated_2.n_restrictions,1), dtype=torch.float32).to(game_iterated_2.device)\n",
        "c_vector = game_iterated_2.mask_equality_restrictions(c_vector)\n",
        "with torch.no_grad():\n",
        "  f = game_iterated_2.calculate_bellman_error()\n",
        "  g_vector = game_iterated_2.calculate_restriction_vector(hard_constraints)\n",
        "  grad_f_vector, grad_g_matrix = game_iterated_2.build_grad_tensors(hard_constraints)\n",
        "\n",
        "  d0_vector, norm_2_d0, duals_0_vector, A_matrix, b_vector = game_iterated_2.calculate_descent_direction(g_vector, grad_f_vector, grad_g_matrix)\n",
        "  new_c_vector = game_iterated_2.update_c_vector(c_vector, duals_0_vector)\n",
        "  d_vector, duals_vector, new_rho, mWe = game_iterated_2.calculate_feasible_direction(g_vector, new_c_vector, duals_0_vector, \n",
        "                                                                      norm_2_d0, A_matrix, b_vector, rho, \n",
        "                                                                      grad_f_vector, grad_g_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0giNN7ZCZqw"
      },
      "source": [
        "The Lemma 3.1 states that the matrix $W=(A^TA-RG)$, where $A=\\left(\\nabla \\textbf{g}\\right)^T$, is positive definite. So, let's calculate that matrix and its corresponding eigenvalues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3A-ENMw-x8X",
        "outputId": "92c0ae3d-399d-4aa9-83fd-f79f9381f67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "W = torch.einsum('ij,kj->ik',grad_g_matrix,grad_g_matrix) - torch.diag(g_vector.view(-1))\n",
        "W_eigenval, W_eigenvec = torch.eig(W)\n",
        "print(W_eigenval[:,0].view(-1,1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[7.0149e+03],\n",
            "        [2.6420e+01],\n",
            "        [2.5839e+00],\n",
            "        [1.8334e+00],\n",
            "        [6.4333e-01],\n",
            "        [6.0516e-01],\n",
            "        [3.6592e-01],\n",
            "        [2.0670e-01],\n",
            "        [1.9053e-02],\n",
            "        [1.5050e-04]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ooJ38PUDAt8"
      },
      "source": [
        "Indeed, all the eigenvalues are positive and so $W(x)$ is p.d. at the current solution. \n",
        "\n",
        "We can also notice that the value of $\\rho$ remains constant in each iteration, which indicates that the minimum vaule $\\rho^{\\text{min}}$ was reached with  (or is close after) only one iteration, in accordance to the Lemma 3.2 that states the existence of such bound.\n",
        "\n",
        "The Lemma 3.3 states that the matrix $Z=AW^{-1}A^T$ is positive semi-definite and that its eigenvalues are all less than or equal to 1. Let's calculate this matix and its eigenvalues. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfGa2V_kC_Sx",
        "outputId": "58f0e34c-661c-4b69-9d84-98c754e9766b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "Z = torch.einsum('ji,jk->ik',grad_g_matrix,torch.solve(grad_g_matrix, W)[0]) \n",
        "Z_eigenval, Z_eigenvec = torch.eig(Z)\n",
        "print(Z_eigenval[:,0].view(-1,1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[7.7009e-05],\n",
            "        [9.5731e-01],\n",
            "        [9.8147e-01],\n",
            "        [1.0000e+00],\n",
            "        [1.0000e+00],\n",
            "        [1.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UD9TkCoEkan"
      },
      "source": [
        "Again, the Lemma 3.3 holds. It might be relevant that all the eigenvalues are either close to 1 (most of them) or to 0 (only one).\n",
        "\n",
        "Now, let's calculate the dot product between the gradient $\\nabla f$ and the two descent directions $\\textbf{d}_0$ and $\\textbf{d}$, to verify that they are actually descent directions (Lemmas 3.4 and 3.5)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sysct-ZpEhrb",
        "outputId": "d9c6454d-b28a-4ee5-c75c-d1e548bc93a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "decrement_0 = torch.dot(d0_vector.view(-1), grad_f_vector.view(-1)) \n",
        "decrement = torch.dot(d_vector.view(-1), grad_f_vector.view(-1)) \n",
        "print(decrement_0.item(), decrement.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.6314853429794312 -0.3974042534828186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLpetTx5Gp7_"
      },
      "source": [
        "Once more, the Lemmas 3.4 and 3.5 are confirmed.\n",
        "\n",
        "The Lemma 3.6 states that there exists a finite step size $\\tau$ such that any other step size $0< t\\leq \\tau$ will result in a valid iteration that satisfies conditions (2.7) and (2.8). The condition (2.7) simply says that $\\theta_c$ (the auxilizary loss function) needs to decrease by a finite margin ($t\\eta \\textbf{d}^T\\nabla\\theta_c$); and the condition (2.8) that inequality restrictions $g_{\\text{ineq}}$ should only get closer to 0 by a fraction $\\gamma_0$ in the case of corresponding positive dual variables $\\lambda_i\\geq0$, and shouldn't get closer in the case of corresponding negative dual variables $\\lambda_i<0$. In the case of the equality restrictions $g_\\text{eq}$, it is only necessary to check that the restrictions are satisfied. \n",
        "\n",
        "Clearly, this Lemma seems to be off, since otherwise the algorithm should converge to the optimal solution. To evaluate this, we will add a new method to the game class that calculates the bound $\\tau$ and modify the optimization method to return both the steps sizes and $\\tau$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn0NLuOS5liS"
      },
      "source": [
        "game_iterated_3 = multi_player_game(N, S, A, R, T, beta, device, dtype=dtype, name=name).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7NzDuhlm7RU",
        "outputId": "8ca0c732-bc4d-455e-f69f-79bf5732a678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "step_sizes, step_size_bounds = game_iterated_3.optimize_game(hard_constraints=False, verbose=False, n_epochs=400, on=True, print_each=50, eta_0=0.9)[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 49, f: 3.52859e-04, delta f: -9.99924e+01%, nash satisfied: True, max g: -7.057e-05, dual nash satisfied: False, max product: 6.384e-02, rho: 1.003e-04, norm2 d0:1.350e+02, ss: 2.430e-02\n",
            "Epoch: 49, >0 satisfied: True, max g>0: -4.376e-05, dual >0 satisfied: False, max product >0: 1.744e-02, =1 satisfied: True, max g=1: -4.723e-02, dual =1 satisfied: False, max product =1: 5.662e+01\n",
            "Epoch: 99, f: 7.15256e-05, delta f: -9.99985e+01%, nash satisfied: True, max g: -2.098e-05, dual nash satisfied: False, max product: 5.444e-02, rho: 3.494e-05, norm2 d0:2.212e+02, ss: 8.649e-04\n",
            "Epoch: 99, >0 satisfied: True, max g>0: -1.646e-05, dual >0 satisfied: False, max product >0: 2.022e-02, =1 satisfied: True, max g=1: -3.532e-02, dual =1 satisfied: False, max product =1: 9.531e+01\n",
            "Epoch: 149, f: 1.86920e-04, delta f: -9.99960e+01%, nash satisfied: True, max g: -7.534e-05, dual nash satisfied: False, max product: 3.909e-02, rho: 1.236e-05, norm2 d0:2.975e+02, ss: 2.243e-03\n",
            "Epoch: 149, >0 satisfied: True, max g>0: -4.197e-06, dual >0 satisfied: False, max product >0: 2.181e-02, =1 satisfied: True, max g=1: -2.845e-02, dual =1 satisfied: False, max product =1: 1.400e+02\n",
            "Epoch: 199, f: 8.77380e-05, delta f: -9.99981e+01%, nash satisfied: True, max g: -2.480e-05, dual nash satisfied: False, max product: 1.754e-02, rho: 1.236e-05, norm2 d0:3.460e+02, ss: 8.649e-04\n",
            "Epoch: 199, >0 satisfied: True, max g>0: -4.762e-06, dual >0 satisfied: False, max product >0: 1.546e-02, =1 satisfied: True, max g=1: -2.469e-02, dual =1 satisfied: False, max product =1: 1.588e+02\n",
            "Epoch: 249, f: 1.28746e-03, delta f: -9.99721e+01%, nash satisfied: True, max g: -1.431e-04, dual nash satisfied: False, max product: 2.089e-01, rho: 1.236e-05, norm2 d0:2.888e+02, ss: 1.062e-04\n",
            "Epoch: 249, >0 satisfied: True, max g>0: -1.223e-05, dual >0 satisfied: False, max product >0: 3.393e-02, =1 satisfied: True, max g=1: -1.978e-02, dual =1 satisfied: False, max product =1: 1.642e+02\n",
            "Epoch: 299, f: 1.67847e-04, delta f: -9.99964e+01%, nash satisfied: True, max g: -6.485e-05, dual nash satisfied: False, max product: 7.639e-02, rho: 4.230e-06, norm2 d0:4.668e+02, ss: 1.053e-16\n",
            "Epoch: 299, >0 satisfied: True, max g>0: -1.326e-06, dual >0 satisfied: False, max product >0: 1.510e-02, =1 satisfied: True, max g=1: -1.919e-02, dual =1 satisfied: False, max product =1: 2.308e+02\n",
            "Epoch: 349, f: 1.67847e-04, delta f: -9.99964e+01%, nash satisfied: True, max g: -6.485e-05, dual nash satisfied: False, max product: 7.639e-02, rho: 4.230e-06, norm2 d0:4.668e+02, ss: 1.053e-16\n",
            "Epoch: 349, >0 satisfied: True, max g>0: -1.326e-06, dual >0 satisfied: False, max product >0: 1.510e-02, =1 satisfied: True, max g=1: -1.919e-02, dual =1 satisfied: False, max product =1: 2.308e+02\n",
            "Epoch: 399, f: 1.67847e-04, delta f: -9.99964e+01%, nash satisfied: True, max g: -6.485e-05, dual nash satisfied: False, max product: 7.639e-02, rho: 4.230e-06, norm2 d0:4.668e+02, ss: 1.053e-16\n",
            "Epoch: 399, >0 satisfied: True, max g>0: -1.326e-06, dual >0 satisfied: False, max product >0: 1.510e-02, =1 satisfied: True, max g=1: -1.919e-02, dual =1 satisfied: False, max product =1: 2.308e+02\n",
            "Game 0 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPktU_f1j5PS",
        "outputId": "567637f9-d05d-446f-b1bc-f15c7156270a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(16,6))\n",
        "plt.plot(torch.log10(step_sizes), label='Step size', linewidth=2.0)\n",
        "plt.plot(torch.log10(step_size_bounds), label='Bound', linewidth=2.0)\n",
        "plt.legend()\n",
        "plt.xlabel('# iterations')\n",
        "plt.ylabel('step size (log10)')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4yM7ZYfCgWk",
        "outputId": "b5319db6-13ef-4843-bbcd-5544b0811c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "for pname, p in game_iterated_3.named_parameters():\n",
        "  print(pname, p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v Parameter containing:\n",
            "tensor([[20.1433, 20.1441]], requires_grad=True)\n",
            "pi1.('G',) Parameter containing:\n",
            "tensor([[1.3262e-06],\n",
            "        [9.8081e-01]], requires_grad=True)\n",
            "pi2.('G',) Parameter containing:\n",
            "tensor([[1.6019e-06],\n",
            "        [9.8068e-01]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxf7PcHxO5Yb"
      },
      "source": [
        "The figure illustrates the step size in each iteration and the corresponding bound below which any step size should be accepted. The fact that there is a drastic jump around the iteration 300, when $t$ goes from $\\times10^{-4}$ to $\\times10^{-16}$, and decreasing several orders of magnitude below the bound indicates that there is a severe problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkPBqBiBQPL3"
      },
      "source": [
        "We will repeat one optimization step to assess why the restrictions are not satisfied if the step size is below the bound."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXow_ruY7ZCS"
      },
      "source": [
        "hard_constraints = False\n",
        "f_0 = game_iterated_3.calculate_bellman_error()\n",
        "rho = 1.0\n",
        "c_vector = 1.0*torch.ones((game_iterated_3.n_restrictions,1), dtype=dtype).to(game_iterated_3.device)\n",
        "c_vector = game_iterated_3.mask_equality_restrictions(c_vector)\n",
        "with torch.no_grad():\n",
        "  f = game_iterated_3.calculate_bellman_error()\n",
        "  g_vector = game_iterated_3.calculate_restriction_vector(hard_constraints)\n",
        "  grad_f_vector, grad_g_matrix = game_iterated_3.build_grad_tensors(hard_constraints)\n",
        "\n",
        "  d0_vector, d0_2norm, duals_0_vector, A_matrix, b_vector = game_iterated_3.calculate_descent_direction(g_vector, grad_f_vector, grad_g_matrix)\n",
        "  new_c_vector = game_iterated_3.update_c_vector(c_vector, duals_0_vector)\n",
        "  d_vector, duals_vector, new_rho, mWe = game_iterated_3.calculate_feasible_direction(g_vector, new_c_vector, duals_0_vector, \n",
        "                                                                      d0_2norm, A_matrix, b_vector, rho, \n",
        "                                                                      grad_f_vector, grad_g_matrix)\n",
        "  d_v, d_pi, duals = game_iterated_3.vec2dic(d_vector, duals_vector)\n",
        "  bound_step_size = game_iterated_3.calculate_bound_step_size(duals_vector, new_c_vector, new_rho, d0_2norm, grad_g_matrix, mWe)     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtHAlElARTUz",
        "outputId": "8b61f19a-8d82-4a28-e48a-aa844ca4ce2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "theta = game_iterated_3.calculate_auxiliary_bellman_error(f, g_vector, new_c_vector)\n",
        "grad_theta_vector = grad_f_vector - torch.einsum('ij,ik->jk', grad_g_matrix, new_c_vector)\n",
        "decrement = (d_vector.view(-1) * grad_theta_vector.view(-1)).sum().item()\n",
        "step_size = 1e-1*bound_step_size\n",
        "print(\"Bound: {:.3e}, step size: {:.3e}\".format(bound_step_size, step_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bound: 1.699e-07, step size: 1.699e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPgeh9cJS2yQ",
        "outputId": "e3260577-0690-4cde-f23b-5e56d45becc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "eta = 1e-3\n",
        "gamma_0 = 0.5\n",
        "game_temp = game_iterated_3.copy_game()\n",
        "with torch.no_grad():\n",
        "  game_temp.v.data.add_(step_size * d_v)\n",
        "  for s, player in game_iterated_3.state_player_pairs():\n",
        "    if game_temp.more_than_one_action(player, s):\n",
        "      game_temp.pi[player][s].data.add_(step_size * d_pi[player][s])\n",
        "\n",
        "pi_vector_temp = game_temp.pi2vec()\n",
        "pi_sum_vector_temp = game_temp.pi_sum()\n",
        "f_temp = game_temp.calculate_bellman_error()\n",
        "g_vector_temp = game_temp.calculate_restriction_vector(hard_constraints)\n",
        "theta_temp = game_temp.calculate_auxiliary_bellman_error(f_temp, g_vector_temp, new_c_vector)      \n",
        "\n",
        "gamma = gamma_0 * torch.ones_like(duals_vector)\n",
        "gamma[duals_vector < 0] = 1.0\n",
        "gamma[-game_iterated_3.N_S_reduced['1']-game_iterated_3.N_S_reduced['2']:,:] = 0.0\n",
        "\n",
        "theta_lim = theta + eta * step_size * decrement\n",
        "theta_decreased = theta_temp <= theta_lim\n",
        "NAt = game_iterated_3.N_A_total['1'] + game_iterated_3.N_A_total['2']\n",
        "g_v_valid = torch.all(g_vector_temp[:NAt] <= (g_vector * gamma)[:NAt]).item()\n",
        "g_pi_valid = torch.all(g_vector_temp[NAt:] <= (g_vector * gamma)[NAt:]).item()\n",
        "g_valid = g_v_valid and g_pi_valid\n",
        "\n",
        "print(\"Loss decreases: {}, Nash rest. closer to 0 by gamma rate: {}, policy rest. closer to 0 by gamma rate: {}\".format(\n",
        "    theta_decreased, g_v_valid, g_pi_valid))\n",
        "print(\"Original loss: {}, Relative max. new loss: {}(%), Relative new loss: {}(%)\".format(\n",
        "    theta, (theta_lim/theta - 1.0), (theta_temp/theta - 1.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss decreases: False, Nash rest. closer to 0 by gamma rate: True, policy rest. closer to 0 by gamma rate: True\n",
            "Original loss: 1011.418212890625, Relative max. new loss: -1.5466072866843206e-11(%), Relative new loss: 0.0(%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbklrVNySa0U"
      },
      "source": [
        "By printing the original loss function and the new loss function we can conclude that the parameters are not being updated, since the loss does not change. We will confirm this with the value function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLGe8BFxoOzl",
        "outputId": "73674077-2e8b-4f81-8396-a7a5d898c02d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"v: {}, new v: {}, delta v: {}\".format(\n",
        "    game_iterated_3.v.data.squeeze().tolist(), (game_temp.v.data.squeeze()).tolist(), (step_size * d_v).squeeze().tolist()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v: [20.143306732177734, 20.144145965576172], new v: [20.143306732177734, 20.144145965576172], delta v: [2.3482161282117886e-07, 2.3161749140854226e-07]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9WqQluFTfl2"
      },
      "source": [
        "We can see that although the change in the value function should be in the order of $10^{-7}$, the values actually don't change. This is an indication that there is some numeric problem caused by either Python, NumPy or PyTorch. After a literature revision it was found that using float numbers in Python (either `numpy.float32` or `torch.float32`) results in a maximum precision of 6 decimals ($2^{23}$), since the rest of the bits are reserved for the sign and the exponent. This clearly explains why a number with order $10^{-7}$ doesn't affect a number with order $10^{1}$. To check this explanation, we will change the type of all the tensors to double (``torch.float64`), which should provide a precision between 14 and 15 decimals ($2^{52}$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1_Faat_Te6P"
      },
      "source": [
        "dtype = torch.float64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoaH5Fq5Ybk4"
      },
      "source": [
        "# Define payoff map R\n",
        "R1 = np.array([[3.,0.],[5.,1.]])\n",
        "R2 = np.array([[3.,5.],[0.,1.]])\n",
        "\n",
        "def iterated_prisoner_dilemma_rewards(state, actions):\n",
        "  if 'G' in state:\n",
        "    r1 = R1[actions[0], actions[1]]\n",
        "    r2 = R2[actions[0], actions[1]]\n",
        "  else:\n",
        "    assert 0 == 1, 'Invalid state'\n",
        "  return r1, r2\n",
        "\n",
        "def iterated_prisoner_dilemma_reward_matrices(s):\n",
        "  RM1 = R1.copy()\n",
        "  RM2 = R2.copy()\n",
        "  return RM1, RM2  \n",
        "\n",
        "R = {'1':{}, '2':{}}\n",
        "for s in S:\n",
        "  RM1, RM2 = iterated_prisoner_dilemma_reward_matrices(s)\n",
        "  if dtype == torch.float64:\n",
        "    R['1'][str(s)] = torch.DoubleTensor(RM1).clone()\n",
        "    R['2'][str(s)] = torch.DoubleTensor(RM2).clone()\n",
        "  else:\n",
        "    R['1'][str(s)] = torch.FloatTensor(RM1).clone()\n",
        "    R['2'][str(s)] = torch.FloatTensor(RM2).clone()\n",
        "\n",
        "# Define transition map\n",
        "def iterated_prisoner_dilemma_transition_map(state, actions):\n",
        "  return ('D', ('G',))\n",
        " \n",
        "iterated_prisoner_dilemma_transition_types = {str(('G',)): (1,1)}\n",
        "T = (iterated_prisoner_dilemma_transition_map, iterated_prisoner_dilemma_transition_types)\n",
        "\n",
        "name = 'PrisonersDilemmaIterated-v0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZULlx63nYfk5"
      },
      "source": [
        "game_iterated_4 = multi_player_game(N, S, A, R, T, beta, device, dtype=dtype, name=name).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPvUzHIbX3ta",
        "outputId": "19d95ff8-6899-4ea0-db4b-dd1d47a455a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "step_sizes_2, step_size_bounds_2 = game_iterated_4.optimize_game(hard_constraints=False, verbose=False, n_epochs=4000, on=True, print_each=400, eta_0=0.9)[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 399, f: 1.24827e-05, delta f: -9.99997e+01%, nash satisfied: True, max g: -3.038e-06, dual nash satisfied: False, max product: 1.791e-02, rho: 4.376e-06, norm2 d0:6.705e+02, ss: 5.370e-04\n",
            "Epoch: 399, >0 satisfied: True, max g>0: -4.536e-06, dual >0 satisfied: False, max product >0: 1.273e-02, =1 satisfied: True, max g=1: -1.461e-02, dual =1 satisfied: False, max product =1: 2.877e+02\n",
            "Epoch: 799, f: 3.84074e-06, delta f: -9.99999e+01%, nash satisfied: True, max g: -9.778e-07, dual nash satisfied: False, max product: 1.198e-02, rho: 1.559e-06, norm2 d0:1.075e+03, ss: 6.498e-04\n",
            "Epoch: 799, >0 satisfied: True, max g>0: -8.095e-07, dual >0 satisfied: False, max product >0: 5.628e-03, =1 satisfied: True, max g=1: -8.371e-03, dual =1 satisfied: False, max product =1: 4.452e+02\n",
            "Epoch: 1199, f: 4.25676e-06, delta f: -9.99999e+01%, nash satisfied: True, max g: -1.177e-06, dual nash satisfied: False, max product: 6.589e-03, rho: 1.559e-06, norm2 d0:1.163e+03, ss: 2.277e-04\n",
            "Epoch: 1199, >0 satisfied: True, max g>0: -5.064e-07, dual >0 satisfied: False, max product >0: 5.445e-03, =1 satisfied: True, max g=1: -5.543e-03, dual =1 satisfied: False, max product =1: 4.178e+02\n",
            "Epoch: 1599, f: 1.74642e-06, delta f: -1.00000e+02%, nash satisfied: True, max g: -4.860e-07, dual nash satisfied: False, max product: 6.472e-03, rho: 5.593e-07, norm2 d0:1.227e+03, ss: 1.685e-03\n",
            "Epoch: 1599, >0 satisfied: True, max g>0: -8.664e-08, dual >0 satisfied: False, max product >0: 2.412e-03, =1 satisfied: True, max g=1: -4.072e-03, dual =1 satisfied: False, max product =1: 5.173e+02\n",
            "Epoch: 1999, f: 1.09578e-06, delta f: -1.00000e+02%, nash satisfied: True, max g: -3.816e-07, dual nash satisfied: False, max product: 4.402e-03, rho: 5.593e-07, norm2 d0:1.061e+03, ss: 1.711e-04\n",
            "Epoch: 1999, >0 satisfied: True, max g>0: -7.167e-08, dual >0 satisfied: False, max product >0: 2.711e-03, =1 satisfied: True, max g=1: -2.902e-03, dual =1 satisfied: False, max product =1: 4.322e+02\n",
            "Epoch: 2399, f: 9.43259e-07, delta f: -1.00000e+02%, nash satisfied: True, max g: -3.235e-07, dual nash satisfied: False, max product: 3.105e-03, rho: 5.593e-07, norm2 d0:8.835e+02, ss: 2.986e-03\n",
            "Epoch: 2399, >0 satisfied: True, max g>0: -7.932e-08, dual >0 satisfied: False, max product >0: 1.197e-03, =1 satisfied: True, max g=1: -2.171e-03, dual =1 satisfied: False, max product =1: 3.477e+02\n",
            "Epoch: 2799, f: 5.65463e-07, delta f: -1.00000e+02%, nash satisfied: True, max g: -3.164e-07, dual nash satisfied: False, max product: 2.112e-03, rho: 5.593e-07, norm2 d0:6.616e+02, ss: 2.468e-03\n",
            "Epoch: 2799, >0 satisfied: True, max g>0: -8.215e-08, dual >0 satisfied: False, max product >0: 8.565e-04, =1 satisfied: True, max g=1: -1.589e-03, dual =1 satisfied: False, max product =1: 2.586e+02\n",
            "Epoch: 3199, f: 6.56157e-07, delta f: -1.00000e+02%, nash satisfied: True, max g: -2.606e-07, dual nash satisfied: False, max product: 1.657e-03, rho: 5.593e-07, norm2 d0:4.786e+02, ss: 7.148e-04\n",
            "Epoch: 3199, >0 satisfied: True, max g>0: -5.217e-08, dual >0 satisfied: False, max product >0: 7.150e-04, =1 satisfied: True, max g=1: -1.194e-03, dual =1 satisfied: False, max product =1: 1.888e+02\n",
            "Epoch: 3599, f: 3.86526e-07, delta f: -1.00000e+02%, nash satisfied: True, max g: -1.050e-07, dual nash satisfied: False, max product: 1.405e-03, rho: 5.593e-07, norm2 d0:3.409e+02, ss: 4.035e-04\n",
            "Epoch: 3599, >0 satisfied: True, max g>0: -4.245e-08, dual >0 satisfied: False, max product >0: 6.320e-04, =1 satisfied: True, max g=1: -9.202e-04, dual =1 satisfied: False, max product =1: 1.371e+02\n",
            "Epoch: 3999, f: 3.57990e-07, delta f: -1.00000e+02%, nash satisfied: True, max g: -1.488e-07, dual nash satisfied: False, max product: 9.753e-04, rho: 5.593e-07, norm2 d0:1.996e+02, ss: 1.854e-03\n",
            "Epoch: 3999, >0 satisfied: True, max g>0: -2.624e-08, dual >0 satisfied: False, max product >0: 4.245e-04, =1 satisfied: True, max g=1: -6.373e-04, dual =1 satisfied: False, max product =1: 8.316e+01\n",
            "Game 0 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKmzOVIVf1ni",
        "outputId": "66004ea1-ba77-45f3-d9c6-89a944912465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "for pname, p in game_iterated_4.named_parameters():\n",
        "  print(pname, p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v Parameter containing:\n",
            "tensor([[88.7002, 88.7002]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('G',) Parameter containing:\n",
            "tensor([[9.0072e-08],\n",
            "        [9.9936e-01]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('G',) Parameter containing:\n",
            "tensor([[2.2157e-08],\n",
            "        [9.9936e-01]], dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTtLHxLlX3qv"
      },
      "source": [
        "game_iterated_5 = game_iterated_4.copy_game()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpwhx2VFX3oh",
        "outputId": "1a837e83-7307-480d-97a2-740e539f51d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "step_sizes_3, step_size_bounds_3 = game_iterated_5.optimize_game(hard_constraints=False, verbose=False, n_epochs=4000, on=True, print_each=400, eta_0=0.9)[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 399, f: 1.32112e-07, delta f: -6.30961e+01%, nash satisfied: True, max g: -4.763e-08, dual nash satisfied: False, max product: 6.822e-04, rho: 3.985e-07, norm2 d0:8.941e+01, ss: 1.046e-03\n",
            "Epoch: 399, >0 satisfied: True, max g>0: -1.455e-08, dual >0 satisfied: False, max product >0: 3.264e-04, =1 satisfied: True, max g=1: -3.890e-04, dual =1 satisfied: False, max product =1: 4.076e+01\n",
            "Epoch: 799, f: 4.59115e-08, delta f: -8.71752e+01%, nash satisfied: True, max g: -1.369e-08, dual nash satisfied: False, max product: 3.467e-04, rho: 3.985e-07, norm2 d0:2.365e+01, ss: 3.613e-03\n",
            "Epoch: 799, >0 satisfied: True, max g>0: -7.604e-09, dual >0 satisfied: False, max product >0: 1.673e-04, =1 satisfied: True, max g=1: -1.850e-04, dual =1 satisfied: False, max product =1: 1.122e+01\n",
            "Epoch: 1199, f: 3.56297e-09, delta f: -9.90047e+01%, nash satisfied: True, max g: -2.872e-10, dual nash satisfied: False, max product: 6.519e-05, rho: 3.985e-07, norm2 d0:8.432e-01, ss: 7.744e-03\n",
            "Epoch: 1199, >0 satisfied: True, max g>0: -9.769e-10, dual >0 satisfied: False, max product >0: 3.221e-05, =1 satisfied: True, max g=1: -3.290e-05, dual =1 satisfied: False, max product =1: 4.110e-01\n",
            "Epoch: 1599, f: 1.64519e-10, delta f: -9.99540e+01%, nash satisfied: True, max g: -4.974e-13, dual nash satisfied: False, max product: 2.773e-06, rho: 3.985e-07, norm2 d0:1.537e-03, ss: 7.744e-03\n",
            "Epoch: 1599, >0 satisfied: True, max g>0: -8.169e-11, dual >0 satisfied: False, max product >0: 1.386e-06, =1 satisfied: True, max g=1: -1.387e-06, dual =1 satisfied: False, max product =1: 4.912e-04\n",
            "Epoch: 1999, f: 1.98703e-09, delta f: -9.94449e+01%, nash satisfied: True, max g: -1.421e-14, dual nash satisfied: False, max product: 1.504e-07, rho: 3.985e-07, norm2 d0:4.390e-06, ss: 3.974e-03\n",
            "Epoch: 1999, >0 satisfied: True, max g>0: -9.840e-10, dual >0 satisfied: False, max product >0: 7.166e-08, =1 satisfied: True, max g=1: -7.403e-08, dual =1 satisfied: False, max product =1: 1.261e-05\n",
            "Epoch: 2399, f: 1.24117e-06, delta f: 2.46706e+02%, nash satisfied: True, max g: -2.430e-12, dual nash satisfied: False, max product: 1.694e-06, rho: 3.985e-07, norm2 d0:9.179e-07, ss: 1.069e-17\n",
            "Epoch: 2399, >0 satisfied: True, max g>0: -6.206e-07, dual >0 satisfied: False, max product >0: 1.694e-06, =1 satisfied: True, max g=1: -9.581e-14, dual =1 satisfied: True, max product =1: 2.824e-11\n",
            "Epoch: 2799, f: 1.24117e-06, delta f: 2.46706e+02%, nash satisfied: True, max g: -2.430e-12, dual nash satisfied: False, max product: 1.694e-06, rho: 3.985e-07, norm2 d0:9.179e-07, ss: 1.069e-17\n",
            "Epoch: 2799, >0 satisfied: True, max g>0: -6.206e-07, dual >0 satisfied: False, max product >0: 1.694e-06, =1 satisfied: True, max g=1: -9.581e-14, dual =1 satisfied: True, max product =1: 2.824e-11\n",
            "Epoch: 3199, f: 1.24117e-06, delta f: 2.46706e+02%, nash satisfied: True, max g: -2.430e-12, dual nash satisfied: False, max product: 1.694e-06, rho: 3.985e-07, norm2 d0:9.179e-07, ss: 1.069e-17\n",
            "Epoch: 3199, >0 satisfied: True, max g>0: -6.206e-07, dual >0 satisfied: False, max product >0: 1.694e-06, =1 satisfied: True, max g=1: -9.581e-14, dual =1 satisfied: True, max product =1: 2.824e-11\n",
            "Epoch: 3599, f: 1.24117e-06, delta f: 2.46706e+02%, nash satisfied: True, max g: -2.430e-12, dual nash satisfied: False, max product: 1.694e-06, rho: 3.985e-07, norm2 d0:9.179e-07, ss: 1.069e-17\n",
            "Epoch: 3599, >0 satisfied: True, max g>0: -6.206e-07, dual >0 satisfied: False, max product >0: 1.694e-06, =1 satisfied: True, max g=1: -9.581e-14, dual =1 satisfied: True, max product =1: 2.824e-11\n",
            "Epoch: 3999, f: 1.24117e-06, delta f: 2.46706e+02%, nash satisfied: True, max g: -2.430e-12, dual nash satisfied: False, max product: 1.694e-06, rho: 3.985e-07, norm2 d0:9.179e-07, ss: 1.069e-17\n",
            "Epoch: 3999, >0 satisfied: True, max g>0: -6.206e-07, dual >0 satisfied: False, max product >0: 1.694e-06, =1 satisfied: True, max g=1: -9.581e-14, dual =1 satisfied: True, max product =1: 2.824e-11\n",
            "Game 1 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4uFILARf4t5",
        "outputId": "61bac5c2-6f02-4ae0-cc61-427fa6ddef7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "for pname, p in game_iterated_5.named_parameters():\n",
        "  print(pname, p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v Parameter containing:\n",
            "tensor([[100.0002, 100.0002]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('G',) Parameter containing:\n",
            "tensor([[6.2059e-07],\n",
            "        [1.0000e+00]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('G',) Parameter containing:\n",
            "tensor([[6.2057e-07],\n",
            "        [1.0000e+00]], dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrjxMjd0ezqh"
      },
      "source": [
        "After using double variables the algorithm works adequately for something around 10 times more iterations than with floats. We can also see that the solution found $(v^*,\\pi^*)$ is extremely close to the optimal, which means that the game was solved successfully. Now, even if this is true, we can see that after certain point the algorithm reaches the limits of representation of the double variables and the previous problem appears again. This may happen only when the algorithm gets sufficiently close to the optimal, but there is no guarantee of this. We will now try again the Prisoner's Dilemma game with incentives to test this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIIPy6P3hK6_"
      },
      "source": [
        "# Prisoner's Dilemma With Incentives (2nd try)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjFUJ8GOhK7B"
      },
      "source": [
        "# Define player set N\n",
        "N = 2\n",
        "\n",
        "# Define state set S\n",
        "M = 5\n",
        "G = [('G',)]\n",
        "O = [('O',i) for i in range(1,2+1)]\n",
        "E1 = [('E1',i,j) for i in range(0,2) for j in range(0,M+1)]\n",
        "E2 = [('E2',i,j) for i in range(0,2) for j in range(0,M+1)]\n",
        "R1 = [('R1',i) for i in range(0,2)]\n",
        "R2 = [('R2',i) for i in range(0,2)]\n",
        "S = list(itertools.chain(G.copy(), O.copy(), E1.copy(), E2.copy(), R1.copy(), R2.copy())) \n",
        "\n",
        "# Define action set A^i(s) per player and state\n",
        "A = {'1':{}, '2':{}}\n",
        "for player_id in range(0, N):\n",
        "  player = str(player_id+1)\n",
        "  other_player_id = 1-player_id\n",
        "  other_player = str(other_player_id+1)\n",
        "  A[player][str(('G',))] = 2\n",
        "  A[player][str(('O',player_id+1))] = 2*(M+1)\n",
        "  A[player][str(('O',other_player_id+1))] = 1\n",
        "  for i in range(0,2):\n",
        "    for j in range(0,M+1):\n",
        "      A[player][str(('E'+player,i,j))] = 2\n",
        "      A[player][str(('E'+other_player,i,j))] = 1\n",
        "    A[player][str(('R'+player,i))] = 2\n",
        "    A[player][str(('R'+other_player,i))] = 1\n",
        "\n",
        "# Define discount factor\n",
        "beta = 0.99\n",
        "\n",
        "# Define dtype\n",
        "dtype = torch.float64"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIfJkhUKhK7F"
      },
      "source": [
        "# Define payoff map R\n",
        "R1 = np.array([[3.,0.],[5.,1.]])\n",
        "R2 = np.array([[3.,5.],[0.,1.]])\n",
        "\n",
        "def offer_accepted(action):\n",
        "  if action == 0:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def prisoner_dilemma_rewards(state, actions):\n",
        "  if 'G' in state:\n",
        "    r1 = R1[actions[0], actions[1]]\n",
        "    r2 = R2[actions[0], actions[1]]\n",
        "  elif 'O' in state:\n",
        "    r1 = r2 = 0.0\n",
        "  elif 'E1' in state:\n",
        "    _, _, offeral = state\n",
        "    if offer_accepted(actions[0]):\n",
        "      r1 = offeral\n",
        "      r2 = -offeral\n",
        "    else:\n",
        "      r1 = r2 = 0\n",
        "  elif 'E2' in state:\n",
        "    _, _, offeral = state\n",
        "    if offer_accepted(actions[1]):\n",
        "      r1 = -offeral\n",
        "      r2 = offeral\n",
        "    else:\n",
        "      r1 = r2 = 0\n",
        "  elif 'R1' in state:\n",
        "    _, i = state\n",
        "    r1 = R1[actions[0], i]\n",
        "    r2 = R2[actions[0], i]\n",
        "  elif 'R2' in state:\n",
        "    _, i = state\n",
        "    r1 = R1[i, actions[1]]\n",
        "    r2 = R2[i, actions[1]]\n",
        "  else:\n",
        "    assert 0 == 1, 'Invalid state'\n",
        "  return r1, r2\n",
        "\n",
        "def prisoner_dilemma_reward_matrices(s):\n",
        "  if 'G' in s:\n",
        "    RM1 = R1.copy()\n",
        "    RM2 = R2.copy()\n",
        "  else:\n",
        "    N_A1 = A['1'][str(s)]\n",
        "    N_A2 = A['2'][str(s)]\n",
        "    if dtype == torch.float64:\n",
        "      RM1 = np.zeros((N_A1,N_A2), dtype=np.float64)\n",
        "      RM2 = np.zeros((N_A1,N_A2), dtype=np.float64)\n",
        "    else:\n",
        "      RM1 = np.zeros((N_A1,N_A2), dtype=np.float32)\n",
        "      RM2 = np.zeros((N_A1,N_A2), dtype=np.float32)\n",
        "    for a1 in range(0,N_A1):\n",
        "      for a2 in range(0,N_A2):\n",
        "        r1, r2 = prisoner_dilemma_rewards(s, [a1,a2])\n",
        "        RM1[a1,a2] = r1\n",
        "        RM2[a1,a2] = r2\n",
        "  return RM1, RM2  \n",
        "\n",
        "R = {'1':{}, '2':{}}\n",
        "for s in S:\n",
        "  RM1, RM2 = prisoner_dilemma_reward_matrices(s)\n",
        "  if dtype == torch.float64:\n",
        "    R['1'][str(s)] = torch.DoubleTensor(RM1).clone()\n",
        "    R['2'][str(s)] = torch.DoubleTensor(RM2).clone()\n",
        "  else:\n",
        "    \n",
        "    R['1'][str(s)] = torch.FloatTensor(RM1).clone()\n",
        "    R['2'][str(s)] = torch.FloatTensor(RM2).clone()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5guTHdjhK7H"
      },
      "source": [
        "# Define transition map\n",
        "def prisoner_dilemma_transition_info(state, actions):\n",
        "  if 'G' in state or 'R1' in state or 'R2' in state:\n",
        "    T = [(('O',1), 0.5), (('O',2), 0.5)]\n",
        "    return ('R', T)\n",
        "  elif 'O' in state:\n",
        "    player_id = state[1]-1\n",
        "    other_player_id = 1 - player_id\n",
        "    other_player = str(other_player_id + 1)\n",
        "    offeral = actions[player_id] // 2\n",
        "    action_requested = actions[player_id] % 2\n",
        "    return ('D', ('E'+other_player, action_requested, offeral))\n",
        "  elif 'E1' in state:\n",
        "    _, action_requested, _ = state\n",
        "    if offer_accepted(actions[0]):\n",
        "      return ('D', ('R2', action_requested))\n",
        "    else:\n",
        "      return ('D', ('G',))\n",
        "  elif 'E2' in state:\n",
        "    _, action_requested, _ = state\n",
        "    if offer_accepted(actions[1]):\n",
        "      return ('D', ('R1', action_requested))\n",
        "    else:\n",
        "      return ('D', ('G',))   \n",
        "  else:\n",
        "    assert 0 == 1, 'Invalid state' \n",
        "\n",
        "prisoner_dilemma_transition_types = {}\n",
        "for state in S:\n",
        "  if 'G' in state or 'R1' in state or 'R2' in state:\n",
        "    prisoner_dilemma_transition_types[str(state)] = (0,0) \n",
        "  else:\n",
        "    prisoner_dilemma_transition_types[str(state)] = (1,1) # entries correspond to deterministic behaviour and dependence on actions\n",
        "\n",
        "T = (prisoner_dilemma_transition_info, prisoner_dilemma_transition_types)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEu_NEq8hK7J"
      },
      "source": [
        "game_2 = multi_player_game(N, S, A, R, T, beta, device, dtype=dtype).to(device)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhN2P5aMhK7L",
        "outputId": "fda15043-f5c6-4107-cb15-8e6382fc2009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "xxx = game_2.optimize_game(hard_constraints=False, verbose=False, n_epochs=2000, print_each=200, nu=1.6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 199, f: 9.84731e+00, delta f: -8.99445e+01%, nash satisfied: True, max g: -1.260e-05, dual nash satisfied: False, max product: 1.559e+03, rho: 5.903e-06, norm2 d0:1.117e+03, ss: 3.388e-04\n",
            "Epoch: 199, >0 satisfied: True, max g>0: -4.341e-06, dual >0 satisfied: False, max product >0: 5.805e-01, =1 satisfied: True, max g=1: -3.163e-02, dual =1 satisfied: False, max product =1: 1.844e+02\n",
            "Epoch: 399, f: 1.32528e+01, delta f: -8.64670e+01%, nash satisfied: True, max g: -3.199e-06, dual nash satisfied: False, max product: 1.506e+03, rho: 2.882e-06, norm2 d0:1.451e+03, ss: 5.421e-04\n",
            "Epoch: 399, >0 satisfied: True, max g>0: -1.373e-06, dual >0 satisfied: False, max product >0: 2.265e+00, =1 satisfied: True, max g=1: -2.449e-02, dual =1 satisfied: False, max product =1: 3.864e+02\n",
            "Epoch: 599, f: 1.39672e+01, delta f: -8.57375e+01%, nash satisfied: True, max g: -1.608e-06, dual nash satisfied: False, max product: 1.455e+03, rho: 1.440e-06, norm2 d0:2.098e+03, ss: 1.323e-04\n",
            "Epoch: 599, >0 satisfied: True, max g>0: -7.996e-07, dual >0 satisfied: False, max product >0: 8.740e-02, =1 satisfied: True, max g=1: -2.075e-02, dual =1 satisfied: False, max product =1: 5.381e+02\n",
            "Epoch: 799, f: 1.38582e+01, delta f: -8.58488e+01%, nash satisfied: True, max g: -2.041e-06, dual nash satisfied: False, max product: 7.096e+02, rho: 1.440e-06, norm2 d0:2.353e+03, ss: 5.421e-04\n",
            "Epoch: 799, >0 satisfied: True, max g>0: -5.166e-07, dual >0 satisfied: False, max product >0: 2.037e-02, =1 satisfied: True, max g=1: -1.860e-02, dual =1 satisfied: False, max product =1: 5.855e+02\n",
            "Epoch: 999, f: 1.38059e+01, delta f: -8.59022e+01%, nash satisfied: True, max g: -2.043e-06, dual nash satisfied: False, max product: 6.828e+02, rho: 1.440e-06, norm2 d0:2.445e+03, ss: 8.674e-04\n",
            "Epoch: 999, >0 satisfied: True, max g>0: -5.060e-07, dual >0 satisfied: False, max product >0: 1.559e-02, =1 satisfied: True, max g=1: -1.737e-02, dual =1 satisfied: False, max product =1: 6.048e+02\n",
            "Epoch: 1199, f: 1.37609e+01, delta f: -8.59481e+01%, nash satisfied: True, max g: -2.000e-06, dual nash satisfied: False, max product: 7.251e+02, rho: 1.440e-06, norm2 d0:2.517e+03, ss: 2.118e-04\n",
            "Epoch: 1199, >0 satisfied: True, max g>0: -3.895e-07, dual >0 satisfied: False, max product >0: 1.206e-02, =1 satisfied: True, max g=1: -1.619e-02, dual =1 satisfied: False, max product =1: 6.198e+02\n",
            "Epoch: 1399, f: 1.37114e+01, delta f: -8.59987e+01%, nash satisfied: True, max g: -1.930e-06, dual nash satisfied: False, max product: 7.716e+02, rho: 1.440e-06, norm2 d0:2.606e+03, ss: 1.323e-04\n",
            "Epoch: 1399, >0 satisfied: True, max g>0: -3.590e-07, dual >0 satisfied: False, max product >0: 9.243e-03, =1 satisfied: True, max g=1: -1.483e-02, dual =1 satisfied: False, max product =1: 6.346e+02\n",
            "Epoch: 1599, f: 1.36503e+01, delta f: -8.60611e+01%, nash satisfied: True, max g: -9.940e-07, dual nash satisfied: False, max product: 9.639e+02, rho: 6.105e-07, norm2 d0:3.147e+03, ss: 8.272e-05\n",
            "Epoch: 1599, >0 satisfied: True, max g>0: -3.328e-07, dual >0 satisfied: False, max product >0: 1.216e-02, =1 satisfied: True, max g=1: -1.342e-02, dual =1 satisfied: False, max product =1: 7.665e+02\n",
            "Epoch: 1799, f: 1.36023e+01, delta f: -8.61101e+01%, nash satisfied: True, max g: -7.612e-07, dual nash satisfied: False, max product: 1.023e+03, rho: 6.105e-07, norm2 d0:3.288e+03, ss: 8.272e-05\n",
            "Epoch: 1799, >0 satisfied: True, max g>0: -1.726e-07, dual >0 satisfied: False, max product >0: 1.030e-02, =1 satisfied: True, max g=1: -1.238e-02, dual =1 satisfied: False, max product =1: 7.885e+02\n",
            "Epoch: 1999, f: 1.35727e+01, delta f: -8.61403e+01%, nash satisfied: True, max g: -7.509e-07, dual nash satisfied: False, max product: 1.070e+03, rho: 6.105e-07, norm2 d0:3.375e+03, ss: 3.388e-04\n",
            "Epoch: 1999, >0 satisfied: True, max g>0: -1.938e-07, dual >0 satisfied: False, max product >0: 8.470e-03, =1 satisfied: True, max g=1: -1.176e-02, dual =1 satisfied: False, max product =1: 8.000e+02\n",
            "Game 0 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6haIxI6kw0h",
        "outputId": "81da1879-20c0-4ad3-fcd3-d4679c307de5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "xxx = game_2.optimize_game(hard_constraints=False, verbose=False, n_epochs=2000, print_each=200, nu=1.6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 199, f: 1.35403e+01, delta f: -2.39147e-01%, nash satisfied: True, max g: -4.994e-07, dual nash satisfied: False, max product: 1.185e+03, rho: 4.009e-07, norm2 d0:3.632e+03, ss: 3.388e-04\n",
            "Epoch: 199, >0 satisfied: True, max g>0: -1.023e-07, dual >0 satisfied: False, max product >0: 9.283e-03, =1 satisfied: True, max g=1: -1.115e-02, dual =1 satisfied: False, max product =1: 8.635e+02\n",
            "Epoch: 399, f: 1.35023e+01, delta f: -5.19066e-01%, nash satisfied: True, max g: -4.650e-07, dual nash satisfied: False, max product: 1.245e+03, rho: 4.009e-07, norm2 d0:3.681e+03, ss: 8.272e-05\n",
            "Epoch: 399, >0 satisfied: True, max g>0: -8.387e-08, dual >0 satisfied: False, max product >0: 8.332e-03, =1 satisfied: True, max g=1: -1.044e-02, dual =1 satisfied: False, max product =1: 8.717e+02\n",
            "Epoch: 599, f: 1.34534e+01, delta f: -8.79407e-01%, nash satisfied: True, max g: -5.214e-07, dual nash satisfied: False, max product: 1.306e+03, rho: 4.009e-07, norm2 d0:3.759e+03, ss: 8.674e-04\n",
            "Epoch: 599, >0 satisfied: True, max g>0: -1.229e-07, dual >0 satisfied: False, max product >0: 6.870e-03, =1 satisfied: True, max g=1: -9.602e-03, dual =1 satisfied: False, max product =1: 8.796e+02\n",
            "Epoch: 799, f: 1.34107e+01, delta f: -1.19335e+00%, nash satisfied: True, max g: -4.478e-07, dual nash satisfied: False, max product: 1.355e+03, rho: 4.009e-07, norm2 d0:3.765e+03, ss: 2.118e-04\n",
            "Epoch: 799, >0 satisfied: True, max g>0: -1.469e-07, dual >0 satisfied: False, max product >0: 6.235e-03, =1 satisfied: True, max g=1: -8.918e-03, dual =1 satisfied: False, max product =1: 8.772e+02\n",
            "Epoch: 999, f: 1.33723e+01, delta f: -1.47687e+00%, nash satisfied: True, max g: -3.658e-07, dual nash satisfied: False, max product: 1.386e+03, rho: 4.009e-07, norm2 d0:3.679e+03, ss: 5.170e-05\n",
            "Epoch: 999, >0 satisfied: True, max g>0: -1.952e-07, dual >0 satisfied: False, max product >0: 7.047e-03, =1 satisfied: True, max g=1: -8.347e-03, dual =1 satisfied: False, max product =1: 8.644e+02\n",
            "Epoch: 1199, f: 1.33315e+01, delta f: -1.77730e+00%, nash satisfied: True, max g: -2.872e-07, dual nash satisfied: False, max product: 1.427e+03, rho: 4.009e-07, norm2 d0:3.671e+03, ss: 8.272e-05\n",
            "Epoch: 1199, >0 satisfied: True, max g>0: -1.995e-07, dual >0 satisfied: False, max product >0: 6.652e-03, =1 satisfied: True, max g=1: -7.788e-03, dual =1 satisfied: False, max product =1: 8.555e+02\n",
            "Epoch: 1399, f: 1.32913e+01, delta f: -2.07341e+00%, nash satisfied: True, max g: -4.381e-07, dual nash satisfied: False, max product: 1.481e+03, rho: 4.009e-07, norm2 d0:3.782e+03, ss: 1.388e-03\n",
            "Epoch: 1399, >0 satisfied: True, max g>0: -8.058e-08, dual >0 satisfied: False, max product >0: 4.258e-03, =1 satisfied: True, max g=1: -7.283e-03, dual =1 satisfied: False, max product =1: 8.533e+02\n",
            "Epoch: 1599, f: 1.32583e+01, delta f: -2.31654e+00%, nash satisfied: True, max g: -4.738e-07, dual nash satisfied: False, max product: 1.491e+03, rho: 4.009e-07, norm2 d0:3.627e+03, ss: 5.170e-05\n",
            "Epoch: 1599, >0 satisfied: True, max g>0: -1.778e-07, dual >0 satisfied: False, max product >0: 5.438e-03, =1 satisfied: True, max g=1: -6.881e-03, dual =1 satisfied: False, max product =1: 8.304e+02\n",
            "Epoch: 1799, f: 1.32274e+01, delta f: -2.54419e+00%, nash satisfied: True, max g: -3.095e-07, dual nash satisfied: False, max product: 1.510e+03, rho: 4.009e-07, norm2 d0:3.565e+03, ss: 8.272e-05\n",
            "Epoch: 1799, >0 satisfied: True, max g>0: -1.670e-07, dual >0 satisfied: False, max product >0: 5.600e-03, =1 satisfied: True, max g=1: -6.531e-03, dual =1 satisfied: False, max product =1: 8.143e+02\n",
            "Epoch: 1999, f: 1.31940e+01, delta f: -2.79053e+00%, nash satisfied: True, max g: -4.834e-07, dual nash satisfied: False, max product: 1.519e+03, rho: 4.009e-07, norm2 d0:3.430e+03, ss: 5.170e-05\n",
            "Epoch: 1999, >0 satisfied: True, max g>0: -1.757e-07, dual >0 satisfied: False, max product >0: 6.246e-03, =1 satisfied: True, max g=1: -6.173e-03, dual =1 satisfied: False, max product =1: 7.908e+02\n",
            "Game 1 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqI7hcETo-bO",
        "outputId": "d89fac8a-0599-4632-c762-a6391d29f78a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "xxx = game_2.optimize_game(hard_constraints=False, verbose=False, n_epochs=4000, print_each=400, nu=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 399, f: 1.31688e+01, delta f: -1.90356e-01%, nash satisfied: True, max g: -1.172e-07, dual nash satisfied: False, max product: 1.781e+03, rho: 1.974e-07, norm2 d0:3.877e+03, ss: 1.000e-05\n",
            "Epoch: 399, >0 satisfied: True, max g>0: -7.548e-08, dual >0 satisfied: False, max product >0: 5.026e-03, =1 satisfied: True, max g=1: -5.938e-03, dual =1 satisfied: False, max product =1: 9.047e+02\n",
            "Epoch: 799, f: 1.31472e+01, delta f: -3.54120e-01%, nash satisfied: True, max g: -1.524e-07, dual nash satisfied: False, max product: 1.808e+03, rho: 1.974e-07, norm2 d0:3.892e+03, ss: 1.000e-03\n",
            "Epoch: 799, >0 satisfied: True, max g>0: -3.620e-08, dual >0 satisfied: False, max product >0: 4.662e-03, =1 satisfied: True, max g=1: -5.740e-03, dual =1 satisfied: False, max product =1: 8.985e+02\n",
            "Epoch: 1199, f: 1.31267e+01, delta f: -5.09924e-01%, nash satisfied: True, max g: -1.514e-07, dual nash satisfied: False, max product: 1.824e+03, rho: 1.974e-07, norm2 d0:3.852e+03, ss: 1.000e-03\n",
            "Epoch: 1199, >0 satisfied: True, max g>0: -3.462e-08, dual >0 satisfied: False, max product >0: 4.373e-03, =1 satisfied: True, max g=1: -5.549e-03, dual =1 satisfied: False, max product =1: 8.868e+02\n",
            "Epoch: 1599, f: 1.31070e+01, delta f: -6.58933e-01%, nash satisfied: True, max g: -1.205e-07, dual nash satisfied: False, max product: 1.827e+03, rho: 1.974e-07, norm2 d0:3.747e+03, ss: 1.000e-05\n",
            "Epoch: 1599, >0 satisfied: True, max g>0: -7.194e-08, dual >0 satisfied: False, max product >0: 4.479e-03, =1 satisfied: True, max g=1: -5.365e-03, dual =1 satisfied: False, max product =1: 8.689e+02\n",
            "Epoch: 1999, f: 1.30877e+01, delta f: -8.05619e-01%, nash satisfied: True, max g: -1.966e-07, dual nash satisfied: False, max product: 1.843e+03, rho: 1.974e-07, norm2 d0:3.717e+03, ss: 1.000e-04\n",
            "Epoch: 1999, >0 satisfied: True, max g>0: -6.238e-08, dual >0 satisfied: False, max product >0: 4.016e-03, =1 satisfied: True, max g=1: -5.194e-03, dual =1 satisfied: False, max product =1: 8.577e+02\n",
            "Epoch: 2399, f: 1.30681e+01, delta f: -9.54004e-01%, nash satisfied: True, max g: -1.458e-07, dual nash satisfied: False, max product: 1.863e+03, rho: 1.974e-07, norm2 d0:3.710e+03, ss: 1.000e-03\n",
            "Epoch: 2399, >0 satisfied: True, max g>0: -3.287e-08, dual >0 satisfied: False, max product >0: 3.718e-03, =1 satisfied: True, max g=1: -5.027e-03, dual =1 satisfied: False, max product =1: 8.481e+02\n",
            "Epoch: 2799, f: 1.30500e+01, delta f: -1.09147e+00%, nash satisfied: True, max g: -1.918e-07, dual nash satisfied: False, max product: 1.858e+03, rho: 1.974e-07, norm2 d0:3.581e+03, ss: 1.000e-05\n",
            "Epoch: 2799, >0 satisfied: True, max g>0: -6.862e-08, dual >0 satisfied: False, max product >0: 4.168e-03, =1 satisfied: True, max g=1: -4.869e-03, dual =1 satisfied: False, max product =1: 8.276e+02\n",
            "Epoch: 3199, f: 1.30323e+01, delta f: -1.22552e+00%, nash satisfied: True, max g: -1.938e-07, dual nash satisfied: False, max product: 1.867e+03, rho: 1.974e-07, norm2 d0:3.532e+03, ss: 1.000e-05\n",
            "Epoch: 3199, >0 satisfied: True, max g>0: -6.748e-08, dual >0 satisfied: False, max product >0: 4.009e-03, =1 satisfied: True, max g=1: -4.723e-03, dual =1 satisfied: False, max product =1: 8.143e+02\n",
            "Epoch: 3599, f: 1.30148e+01, delta f: -1.35756e+00%, nash satisfied: True, max g: -1.909e-07, dual nash satisfied: False, max product: 1.866e+03, rho: 1.974e-07, norm2 d0:3.437e+03, ss: 1.000e-05\n",
            "Epoch: 3599, >0 satisfied: True, max g>0: -6.725e-08, dual >0 satisfied: False, max product >0: 4.402e-03, =1 satisfied: True, max g=1: -4.582e-03, dual =1 satisfied: False, max product =1: 7.969e+02\n",
            "Epoch: 3999, f: 1.29977e+01, delta f: -1.48765e+00%, nash satisfied: True, max g: -1.401e-07, dual nash satisfied: False, max product: 1.896e+03, rho: 1.974e-07, norm2 d0:3.500e+03, ss: 1.000e-03\n",
            "Epoch: 3999, >0 satisfied: True, max g>0: -3.031e-08, dual >0 satisfied: False, max product >0: 3.135e-03, =1 satisfied: True, max g=1: -4.450e-03, dual =1 satisfied: False, max product =1: 7.932e+02\n",
            "Game 2 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX2OuR3tst0C",
        "outputId": "3f8a243f-c88e-438a-d27b-ae363f8754a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "xxx = game_2.optimize_game(hard_constraints=False, verbose=False, n_epochs=10000, print_each=1000, nu=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 999, f: 1.29532e+01, delta f: -3.42575e-01%, nash satisfied: True, max g: -1.386e-07, dual nash satisfied: False, max product: 1.958e+03, rho: 1.585e-07, norm2 d0:3.338e+03, ss: 1.000e-05\n",
            "Epoch: 999, >0 satisfied: True, max g>0: -4.933e-08, dual >0 satisfied: False, max product >0: 3.678e-03, =1 satisfied: True, max g=1: -4.112e-03, dual =1 satisfied: False, max product =1: 7.745e+02\n",
            "Epoch: 1999, f: 1.29111e+01, delta f: -6.66264e-01%, nash satisfied: True, max g: -1.340e-07, dual nash satisfied: False, max product: 1.948e+03, rho: 1.585e-07, norm2 d0:3.112e+03, ss: 1.000e-05\n",
            "Epoch: 1999, >0 satisfied: True, max g>0: -4.821e-08, dual >0 satisfied: False, max product >0: 4.251e-03, =1 satisfied: True, max g=1: -3.812e-03, dual =1 satisfied: False, max product =1: 7.293e+02\n",
            "Epoch: 2999, f: 1.28711e+01, delta f: -9.73518e-01%, nash satisfied: True, max g: -8.000e-08, dual nash satisfied: False, max product: 1.970e+03, rho: 1.585e-07, norm2 d0:3.040e+03, ss: 1.000e-05\n",
            "Epoch: 2999, >0 satisfied: True, max g>0: -4.486e-08, dual >0 satisfied: False, max product >0: 2.967e-03, =1 satisfied: True, max g=1: -3.540e-03, dual =1 satisfied: False, max product =1: 6.982e+02\n",
            "Epoch: 3999, f: 1.28320e+01, delta f: -1.27504e+00%, nash satisfied: True, max g: -6.862e-08, dual nash satisfied: False, max product: 1.951e+03, rho: 1.585e-07, norm2 d0:2.824e+03, ss: 1.000e-05\n",
            "Epoch: 3999, >0 satisfied: True, max g>0: -4.358e-08, dual >0 satisfied: False, max product >0: 3.375e-03, =1 satisfied: True, max g=1: -3.286e-03, dual =1 satisfied: False, max product =1: 6.536e+02\n",
            "Epoch: 4999, f: 1.27940e+01, delta f: -1.56690e+00%, nash satisfied: True, max g: -6.690e-08, dual nash satisfied: False, max product: 1.940e+03, rho: 1.585e-07, norm2 d0:2.660e+03, ss: 1.000e-05\n",
            "Epoch: 4999, >0 satisfied: True, max g>0: -4.146e-08, dual >0 satisfied: False, max product >0: 3.114e-03, =1 satisfied: True, max g=1: -3.051e-03, dual =1 satisfied: False, max product =1: 6.140e+02\n",
            "Epoch: 5999, f: 1.27572e+01, delta f: -1.84991e+00%, nash satisfied: True, max g: -7.203e-08, dual nash satisfied: False, max product: 1.940e+03, rho: 1.585e-07, norm2 d0:2.552e+03, ss: 1.000e-04\n",
            "Epoch: 5999, >0 satisfied: True, max g>0: -3.304e-08, dual >0 satisfied: False, max product >0: 2.169e-03, =1 satisfied: True, max g=1: -2.833e-03, dual =1 satisfied: False, max product =1: 5.794e+02\n",
            "Epoch: 6999, f: 1.27207e+01, delta f: -2.13103e+00%, nash satisfied: True, max g: -6.820e-08, dual nash satisfied: False, max product: 1.915e+03, rho: 1.585e-07, norm2 d0:2.372e+03, ss: 1.000e-05\n",
            "Epoch: 6999, >0 satisfied: True, max g>0: -3.590e-08, dual >0 satisfied: False, max product >0: 2.085e-03, =1 satisfied: True, max g=1: -2.625e-03, dual =1 satisfied: False, max product =1: 5.384e+02\n",
            "Epoch: 7999, f: 1.26850e+01, delta f: -2.40538e+00%, nash satisfied: True, max g: -1.025e-07, dual nash satisfied: False, max product: 1.883e+03, rho: 1.585e-07, norm2 d0:2.189e+03, ss: 1.000e-05\n",
            "Epoch: 7999, >0 satisfied: True, max g>0: -3.465e-08, dual >0 satisfied: False, max product >0: 2.022e-03, =1 satisfied: True, max g=1: -2.431e-03, dual =1 satisfied: False, max product =1: 4.978e+02\n",
            "Epoch: 8999, f: 1.26491e+01, delta f: -2.68181e+00%, nash satisfied: True, max g: -9.739e-08, dual nash satisfied: False, max product: 1.844e+03, rho: 1.585e-07, norm2 d0:1.999e+03, ss: 1.000e-05\n",
            "Epoch: 8999, >0 satisfied: True, max g>0: -3.289e-08, dual >0 satisfied: False, max product >0: 2.062e-03, =1 satisfied: True, max g=1: -2.244e-03, dual =1 satisfied: False, max product =1: 4.563e+02\n",
            "Epoch: 9999, f: 1.26127e+01, delta f: -2.96209e+00%, nash satisfied: True, max g: -9.505e-08, dual nash satisfied: False, max product: 1.803e+03, rho: 1.585e-07, norm2 d0:1.824e+03, ss: 1.000e-05\n",
            "Epoch: 9999, >0 satisfied: True, max g>0: -3.077e-08, dual >0 satisfied: False, max product >0: 1.877e-03, =1 satisfied: True, max g=1: -2.061e-03, dual =1 satisfied: False, max product =1: 4.158e+02\n",
            "Game 3 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCMfPRvsOe1u",
        "outputId": "b9412424-c7fb-4be1-c34b-0b8d9899faba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "game_2.load_state_dict(torch.load('StochasticGame-v0_gamesave_3-3.pth'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zvAzztWP8GG",
        "outputId": "765b5840-183d-4d95-a5bc-4ec9ef5d5d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "xxx = game_2.optimize_game(hard_constraints=False, verbose=False, n_epochs=10000, print_each=1000, nu=10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 999, f: 1.25730e+01, delta f: -3.14342e-01%, nash satisfied: True, max g: -4.018e-08, dual nash satisfied: False, max product: 1.796e+03, rho: 1.357e-07, norm2 d0:1.667e+03, ss: 1.000e-05\n",
            "Epoch: 999, >0 satisfied: True, max g>0: -2.386e-08, dual >0 satisfied: False, max product >0: 1.561e-03, =1 satisfied: True, max g=1: -1.872e-03, dual =1 satisfied: False, max product =1: 3.821e+02\n",
            "Epoch: 1999, f: 1.25315e+01, delta f: -6.43504e-01%, nash satisfied: True, max g: -6.936e-08, dual nash satisfied: False, max product: 1.730e+03, rho: 1.357e-07, norm2 d0:1.464e+03, ss: 1.000e-04\n",
            "Epoch: 1999, >0 satisfied: True, max g>0: -2.067e-08, dual >0 satisfied: False, max product >0: 1.386e-03, =1 satisfied: True, max g=1: -1.682e-03, dual =1 satisfied: False, max product =1: 3.359e+02\n",
            "Epoch: 2999, f: 1.24661e+01, delta f: -1.16249e+00%, nash satisfied: True, max g: -8.542e-08, dual nash satisfied: False, max product: 1.607e+03, rho: 1.357e-07, norm2 d0:1.161e+03, ss: 1.000e-04\n",
            "Epoch: 2999, >0 satisfied: True, max g>0: -1.172e-08, dual >0 satisfied: False, max product >0: 2.505e-03, =1 satisfied: True, max g=1: -1.404e-03, dual =1 satisfied: False, max product =1: 2.666e+02\n",
            "Epoch: 3999, f: 1.23605e+01, delta f: -1.99967e+00%, nash satisfied: True, max g: -4.616e-08, dual nash satisfied: False, max product: 1.364e+03, rho: 1.357e-07, norm2 d0:7.313e+02, ss: 1.000e-04\n",
            "Epoch: 3999, >0 satisfied: True, max g>0: -8.853e-09, dual >0 satisfied: False, max product >0: 7.531e-03, =1 satisfied: True, max g=1: -1.015e-03, dual =1 satisfied: False, max product =1: 1.691e+02\n",
            "Epoch: 4999, f: 1.22472e+01, delta f: -2.89752e+00%, nash satisfied: True, max g: -2.694e-08, dual nash satisfied: False, max product: 1.095e+03, rho: 1.357e-07, norm2 d0:4.185e+02, ss: 1.000e-04\n",
            "Epoch: 4999, >0 satisfied: True, max g>0: -6.362e-09, dual >0 satisfied: False, max product >0: 2.324e-02, =1 satisfied: True, max g=1: -7.126e-04, dual =1 satisfied: False, max product =1: 9.790e+01\n",
            "Epoch: 5999, f: 1.20884e+01, delta f: -4.15672e+00%, nash satisfied: True, max g: -1.754e-08, dual nash satisfied: False, max product: 8.479e+02, rho: 1.357e-07, norm2 d0:2.281e+02, ss: 1.000e-04\n",
            "Epoch: 5999, >0 satisfied: True, max g>0: -4.509e-09, dual >0 satisfied: False, max product >0: 6.704e-02, =1 satisfied: True, max g=1: -4.969e-04, dual =1 satisfied: False, max product =1: 5.385e+01\n",
            "Epoch: 6999, f: 1.17815e+01, delta f: -6.59038e+00%, nash satisfied: True, max g: -1.199e-08, dual nash satisfied: False, max product: 6.337e+02, rho: 1.357e-07, norm2 d0:1.187e+02, ss: 1.000e-04\n",
            "Epoch: 6999, >0 satisfied: True, max g>0: -3.159e-09, dual >0 satisfied: False, max product >0: 1.662e-01, =1 satisfied: True, max g=1: -3.437e-04, dual =1 satisfied: False, max product =1: 2.821e+01\n",
            "Epoch: 7999, f: 1.11832e+01, delta f: -1.13340e+01%, nash satisfied: True, max g: -8.445e-09, dual nash satisfied: False, max product: 4.600e+02, rho: 1.357e-07, norm2 d0:5.972e+01, ss: 1.000e-04\n",
            "Epoch: 7999, >0 satisfied: True, max g>0: -2.590e-09, dual >0 satisfied: False, max product >0: 3.168e-01, =1 satisfied: True, max g=1: -2.360e-04, dual =1 satisfied: False, max product =1: 1.418e+01\n",
            "Epoch: 8999, f: 1.02055e+01, delta f: -1.90856e+01%, nash satisfied: True, max g: -5.846e-09, dual nash satisfied: False, max product: 3.221e+02, rho: 1.357e-07, norm2 d0:2.893e+01, ss: 1.000e-04\n",
            "Epoch: 8999, >0 satisfied: True, max g>0: -1.871e-09, dual >0 satisfied: False, max product >0: 4.521e-01, =1 satisfied: True, max g=1: -1.591e-04, dual =1 satisfied: False, max product =1: 6.729e+00\n",
            "Epoch: 9999, f: 7.83709e+00, delta f: -3.78634e+01%, nash satisfied: True, max g: -2.961e-09, dual nash satisfied: False, max product: 1.506e+02, rho: 1.357e-07, norm2 d0:6.795e+00, ss: 1.000e-03\n",
            "Epoch: 9999, >0 satisfied: True, max g>0: -7.771e-10, dual >0 satisfied: False, max product >0: 4.387e-01, =1 satisfied: True, max g=1: -7.191e-05, dual =1 satisfied: False, max product =1: 1.423e+00\n",
            "Game 0 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSGbjdgzXVRj",
        "outputId": "bf4fde44-51aa-4381-8f00-a007ac66108f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "xxx = game_2.optimize_game(hard_constraints=False, verbose=False, n_epochs=10000, print_each=1000, nu=10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 999, f: 5.97801e+00, delta f: -2.37215e+01%, nash satisfied: True, max g: -6.378e-09, dual nash satisfied: False, max product: 5.544e+00, rho: 1.515e-06, norm2 d0:1.073e-02, ss: 1.000e-02\n",
            "Epoch: 999, >0 satisfied: True, max g>0: -1.281e-09, dual >0 satisfied: False, max product >0: 1.925e-03, =1 satisfied: True, max g=1: -1.608e-08, dual =1 satisfied: False, max product =1: 1.755e-06\n",
            "Epoch: 1999, f: 5.95675e+00, delta f: -2.39928e+01%, nash satisfied: True, max g: -6.376e-09, dual nash satisfied: False, max product: 5.628e+00, rho: 1.515e-06, norm2 d0:1.104e-02, ss: 1.000e-03\n",
            "Epoch: 1999, >0 satisfied: True, max g>0: -1.279e-09, dual >0 satisfied: False, max product >0: 3.236e-03, =1 satisfied: True, max g=1: -1.654e-08, dual =1 satisfied: False, max product =1: 1.814e-06\n",
            "Epoch: 2999, f: 5.94496e+00, delta f: -2.41432e+01%, nash satisfied: True, max g: -6.365e-09, dual nash satisfied: False, max product: 5.699e+00, rho: 1.515e-06, norm2 d0:1.129e-02, ss: 1.000e-03\n",
            "Epoch: 2999, >0 satisfied: True, max g>0: -1.276e-09, dual >0 satisfied: False, max product >0: 3.679e-03, =1 satisfied: True, max g=1: -1.683e-08, dual =1 satisfied: False, max product =1: 1.925e-06\n",
            "Epoch: 3999, f: 5.93320e+00, delta f: -2.42934e+01%, nash satisfied: True, max g: -6.315e-09, dual nash satisfied: False, max product: 5.821e+00, rho: 1.515e-06, norm2 d0:1.169e-02, ss: 1.000e-03\n",
            "Epoch: 3999, >0 satisfied: True, max g>0: -1.263e-09, dual >0 satisfied: False, max product >0: 3.543e-03, =1 satisfied: True, max g=1: -1.727e-08, dual =1 satisfied: False, max product =1: 2.119e-06\n",
            "Epoch: 4999, f: 5.83319e+00, delta f: -2.55694e+01%, nash satisfied: True, max g: -6.091e-09, dual nash satisfied: False, max product: 6.268e+00, rho: 1.515e-06, norm2 d0:1.302e-02, ss: 1.000e-02\n",
            "Epoch: 4999, >0 satisfied: True, max g>0: -1.523e-09, dual >0 satisfied: False, max product >0: 9.140e-04, =1 satisfied: True, max g=1: -1.972e-08, dual =1 satisfied: False, max product =1: 3.012e-06\n",
            "Epoch: 5999, f: 5.47939e+00, delta f: -3.00839e+01%, nash satisfied: True, max g: -6.069e-09, dual nash satisfied: False, max product: 6.458e+00, rho: 1.515e-06, norm2 d0:1.316e-02, ss: 1.000e-02\n",
            "Epoch: 5999, >0 satisfied: True, max g>0: -1.512e-09, dual >0 satisfied: False, max product >0: 9.190e-04, =1 satisfied: True, max g=1: -1.993e-08, dual =1 satisfied: False, max product =1: 3.212e-06\n",
            "Epoch: 6999, f: 5.12914e+00, delta f: -3.45530e+01%, nash satisfied: True, max g: -6.073e-09, dual nash satisfied: False, max product: 6.620e+00, rho: 1.515e-06, norm2 d0:1.320e-02, ss: 1.000e-02\n",
            "Epoch: 6999, >0 satisfied: True, max g>0: -1.503e-09, dual >0 satisfied: False, max product >0: 9.203e-04, =1 satisfied: True, max g=1: -1.999e-08, dual =1 satisfied: False, max product =1: 3.349e-06\n",
            "Epoch: 7999, f: 4.77857e+00, delta f: -3.90262e+01%, nash satisfied: True, max g: -6.068e-09, dual nash satisfied: False, max product: 6.777e+00, rho: 1.515e-06, norm2 d0:1.321e-02, ss: 1.000e-02\n",
            "Epoch: 7999, >0 satisfied: True, max g>0: -1.494e-09, dual >0 satisfied: False, max product >0: 9.210e-04, =1 satisfied: True, max g=1: -2.001e-08, dual =1 satisfied: False, max product =1: 3.475e-06\n",
            "Epoch: 8999, f: 4.42633e+00, delta f: -4.35208e+01%, nash satisfied: True, max g: -6.064e-09, dual nash satisfied: False, max product: 6.934e+00, rho: 1.515e-06, norm2 d0:1.322e-02, ss: 1.000e-02\n",
            "Epoch: 8999, >0 satisfied: True, max g>0: -1.486e-09, dual >0 satisfied: False, max product >0: 9.214e-04, =1 satisfied: True, max g=1: -2.003e-08, dual =1 satisfied: False, max product =1: 3.597e-06\n",
            "Epoch: 9999, f: 4.07810e+00, delta f: -4.79641e+01%, nash satisfied: True, max g: -6.073e-09, dual nash satisfied: False, max product: 7.087e+00, rho: 1.515e-06, norm2 d0:1.323e-02, ss: 1.000e-01\n",
            "Epoch: 9999, >0 satisfied: True, max g>0: -1.478e-09, dual >0 satisfied: False, max product >0: 9.214e-04, =1 satisfied: True, max g=1: -2.004e-08, dual =1 satisfied: False, max product =1: 3.715e-06\n",
            "Game 1 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N6DgbMDn7N7",
        "outputId": "2e15213c-dad5-4585-d653-ef3c4bb9129f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "game_2.load_state_dict(torch.load('StochasticGame-v0_gamesave_5-5.pth'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8--8ZWEcgq4"
      },
      "source": [
        "xxx = game_2.optimize_game(hard_constraints=False, verbose=False, n_epochs=12000, print_each=2000, nu=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO5J-KceyCJw",
        "outputId": "b73e71f3-cac6-40d5-f9cb-dc05543bbe33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "game_2.load_state_dict(torch.load('StochasticGame-v0_gamesave_4.pth'))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKZJsyHt0oH2",
        "outputId": "850e60c2-78f2-4332-aeb5-1f80252d0608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for pname, p in game_2.named_parameters():\n",
        "  print(pname, p)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v Parameter containing:\n",
            "tensor([[94.2532, 94.2532],\n",
            "        [94.5858, 93.5683],\n",
            "        [93.5683, 94.5858],\n",
            "        [93.4355, 95.5568],\n",
            "        [93.2809, 93.2865],\n",
            "        [94.2082, 95.2042],\n",
            "        [95.2072, 94.1842],\n",
            "        [96.2069, 93.1842],\n",
            "        [97.2077, 92.1855],\n",
            "        [93.2768, 93.2794],\n",
            "        [94.1538, 92.1390],\n",
            "        [95.1522, 91.1391],\n",
            "        [96.1514, 90.1393],\n",
            "        [97.1509, 89.1396],\n",
            "        [98.1504, 88.1400],\n",
            "        [95.5568, 93.4355],\n",
            "        [93.2865, 93.2809],\n",
            "        [95.2042, 94.2082],\n",
            "        [94.1842, 95.2072],\n",
            "        [93.1842, 96.2069],\n",
            "        [92.1855, 97.2077],\n",
            "        [93.2794, 93.2768],\n",
            "        [92.1390, 94.1538],\n",
            "        [91.1391, 95.1522],\n",
            "        [90.1393, 96.1514],\n",
            "        [89.1396, 97.1509],\n",
            "        [88.1400, 98.1504],\n",
            "        [98.1962, 93.1707],\n",
            "        [94.1099, 94.1254],\n",
            "        [93.1707, 98.1961],\n",
            "        [94.1254, 94.1099]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('G',) Parameter containing:\n",
            "tensor([[0.0413],\n",
            "        [0.9582]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('O', 1) Parameter containing:\n",
            "tensor([[7.4024e-01],\n",
            "        [1.8017e-04],\n",
            "        [1.8123e-04],\n",
            "        [1.6745e-04],\n",
            "        [1.0442e-02],\n",
            "        [1.7978e-04],\n",
            "        [2.3702e-02],\n",
            "        [2.0807e-04],\n",
            "        [6.0987e-02],\n",
            "        [2.7859e-04],\n",
            "        [1.6252e-01],\n",
            "        [4.6322e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('O', 2) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 0, 0) Parameter containing:\n",
            "tensor([[0.5811],\n",
            "        [0.4185]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 0, 1) Parameter containing:\n",
            "tensor([[0.0024],\n",
            "        [0.9972]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 0, 2) Parameter containing:\n",
            "tensor([[9.9924e-01],\n",
            "        [3.1297e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 0, 3) Parameter containing:\n",
            "tensor([[9.9932e-01],\n",
            "        [2.3587e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 0, 4) Parameter containing:\n",
            "tensor([[9.9941e-01],\n",
            "        [1.5034e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 0, 5) Parameter containing:\n",
            "tensor([[9.9944e-01],\n",
            "        [1.1262e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 1, 0) Parameter containing:\n",
            "tensor([[0.0018],\n",
            "        [0.9977]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 1, 1) Parameter containing:\n",
            "tensor([[9.9894e-01],\n",
            "        [6.1623e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 1, 2) Parameter containing:\n",
            "tensor([[9.9930e-01],\n",
            "        [2.5828e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 1, 3) Parameter containing:\n",
            "tensor([[9.9940e-01],\n",
            "        [1.5427e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 1, 4) Parameter containing:\n",
            "tensor([[9.9945e-01],\n",
            "        [1.0899e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 1, 5) Parameter containing:\n",
            "tensor([[9.9947e-01],\n",
            "        [8.4231e-05]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 0, 0) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 0, 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 0, 2) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 0, 3) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 0, 4) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 0, 5) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 1, 0) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 1, 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 1, 2) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 1, 3) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 1, 4) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 1, 5) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('R1', 0) Parameter containing:\n",
            "tensor([[0.0043],\n",
            "        [0.9952]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('R1', 1) Parameter containing:\n",
            "tensor([[0.0028],\n",
            "        [0.9967]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('R2', 0) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('R2', 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('G',) Parameter containing:\n",
            "tensor([[0.0413],\n",
            "        [0.9582]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('O', 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('O', 2) Parameter containing:\n",
            "tensor([[7.4024e-01],\n",
            "        [1.8017e-04],\n",
            "        [1.8123e-04],\n",
            "        [1.6745e-04],\n",
            "        [1.0442e-02],\n",
            "        [1.7978e-04],\n",
            "        [2.3702e-02],\n",
            "        [2.0807e-04],\n",
            "        [6.0987e-02],\n",
            "        [2.7859e-04],\n",
            "        [1.6252e-01],\n",
            "        [4.6322e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 0, 0) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 0, 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 0, 2) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 0, 3) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 0, 4) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 0, 5) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 1, 0) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 1, 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 1, 2) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 1, 3) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 1, 4) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 1, 5) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 0, 0) Parameter containing:\n",
            "tensor([[0.5811],\n",
            "        [0.4185]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 0, 1) Parameter containing:\n",
            "tensor([[0.0024],\n",
            "        [0.9972]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 0, 2) Parameter containing:\n",
            "tensor([[9.9924e-01],\n",
            "        [3.1297e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 0, 3) Parameter containing:\n",
            "tensor([[9.9932e-01],\n",
            "        [2.3587e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 0, 4) Parameter containing:\n",
            "tensor([[9.9941e-01],\n",
            "        [1.5034e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 0, 5) Parameter containing:\n",
            "tensor([[9.9944e-01],\n",
            "        [1.1262e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 1, 0) Parameter containing:\n",
            "tensor([[0.0018],\n",
            "        [0.9977]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 1, 1) Parameter containing:\n",
            "tensor([[9.9894e-01],\n",
            "        [6.1623e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 1, 2) Parameter containing:\n",
            "tensor([[9.9930e-01],\n",
            "        [2.5828e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 1, 3) Parameter containing:\n",
            "tensor([[9.9940e-01],\n",
            "        [1.5427e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 1, 4) Parameter containing:\n",
            "tensor([[9.9945e-01],\n",
            "        [1.0899e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 1, 5) Parameter containing:\n",
            "tensor([[9.9947e-01],\n",
            "        [8.4231e-05]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('R1', 0) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('R1', 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('R2', 0) Parameter containing:\n",
            "tensor([[0.0043],\n",
            "        [0.9952]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('R2', 1) Parameter containing:\n",
            "tensor([[0.0028],\n",
            "        [0.9967]], dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UC860jawkbo",
        "outputId": "c7af081f-c7e9-43dc-e651-613484034602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# game_2.save()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Game 4 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vulWwps-u47n"
      },
      "source": [
        "game_2.perturb_pi(hard_constraints=False, alpha=0.1)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpvYKFLFzNKr",
        "outputId": "0ef0f476-5c97-4c9b-c0e2-6c0927807700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "xxx = game_2.optimize_game(hard_constraints=False, verbose=False, n_epochs=1000, print_each=100, nu=10, eta_0=1e-3, r_value=1e-2)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 99, f: 4.29997e+00, delta f: -6.28966e+00%, nash satisfied: True, max g: -7.310e-04, dual nash satisfied: False, max product: 4.898e+00, rho: 1.926e-04, norm2 d0:4.286e-03, ss: 1.000e+00\n",
            "Epoch: 99, >0 satisfied: True, max g>0: -1.724e-05, dual >0 satisfied: False, max product >0: 1.526e-02, =1 satisfied: True, max g=1: -1.754e-04, dual =1 satisfied: False, max product =1: 3.145e-02\n",
            "Epoch: 199, f: 4.20374e+00, delta f: -8.38681e+00%, nash satisfied: True, max g: -3.151e-04, dual nash satisfied: False, max product: 4.895e+00, rho: 1.926e-04, norm2 d0:4.268e-03, ss: 1.000e+00\n",
            "Epoch: 199, >0 satisfied: True, max g>0: -1.691e-05, dual >0 satisfied: False, max product >0: 1.612e-02, =1 satisfied: True, max g=1: -1.164e-04, dual =1 satisfied: False, max product =1: 2.138e-02\n",
            "Epoch: 299, f: 4.18234e+00, delta f: -8.85307e+00%, nash satisfied: True, max g: -1.637e-04, dual nash satisfied: False, max product: 4.891e+00, rho: 1.926e-04, norm2 d0:4.251e-03, ss: 1.000e+00\n",
            "Epoch: 299, >0 satisfied: True, max g>0: -1.686e-05, dual >0 satisfied: False, max product >0: 1.678e-02, =1 satisfied: True, max g=1: -9.461e-05, dual =1 satisfied: False, max product =1: 1.771e-02\n",
            "Epoch: 399, f: 4.18229e+00, delta f: -8.85417e+00%, nash satisfied: True, max g: -1.578e-04, dual nash satisfied: False, max product: 4.890e+00, rho: 1.926e-04, norm2 d0:4.250e-03, ss: 9.881e-323\n",
            "Epoch: 399, >0 satisfied: True, max g>0: -1.686e-05, dual >0 satisfied: False, max product >0: 1.683e-02, =1 satisfied: True, max g=1: -9.375e-05, dual =1 satisfied: False, max product =1: 1.757e-02\n",
            "Epoch: 499, f: 4.18229e+00, delta f: -8.85417e+00%, nash satisfied: True, max g: -1.578e-04, dual nash satisfied: False, max product: 4.890e+00, rho: 1.926e-04, norm2 d0:4.250e-03, ss: 9.881e-323\n",
            "Epoch: 499, >0 satisfied: True, max g>0: -1.686e-05, dual >0 satisfied: False, max product >0: 1.683e-02, =1 satisfied: True, max g=1: -9.375e-05, dual =1 satisfied: False, max product =1: 1.757e-02\n",
            "Epoch: 599, f: 4.18229e+00, delta f: -8.85417e+00%, nash satisfied: True, max g: -1.578e-04, dual nash satisfied: False, max product: 4.890e+00, rho: 1.926e-04, norm2 d0:4.250e-03, ss: 9.881e-323\n",
            "Epoch: 599, >0 satisfied: True, max g>0: -1.686e-05, dual >0 satisfied: False, max product >0: 1.683e-02, =1 satisfied: True, max g=1: -9.375e-05, dual =1 satisfied: False, max product =1: 1.757e-02\n",
            "Epoch: 699, f: 4.18229e+00, delta f: -8.85417e+00%, nash satisfied: True, max g: -1.578e-04, dual nash satisfied: False, max product: 4.890e+00, rho: 1.926e-04, norm2 d0:4.250e-03, ss: 9.881e-323\n",
            "Epoch: 699, >0 satisfied: True, max g>0: -1.686e-05, dual >0 satisfied: False, max product >0: 1.683e-02, =1 satisfied: True, max g=1: -9.375e-05, dual =1 satisfied: False, max product =1: 1.757e-02\n",
            "Epoch: 799, f: 4.18229e+00, delta f: -8.85417e+00%, nash satisfied: True, max g: -1.578e-04, dual nash satisfied: False, max product: 4.890e+00, rho: 1.926e-04, norm2 d0:4.250e-03, ss: 9.881e-323\n",
            "Epoch: 799, >0 satisfied: True, max g>0: -1.686e-05, dual >0 satisfied: False, max product >0: 1.683e-02, =1 satisfied: True, max g=1: -9.375e-05, dual =1 satisfied: False, max product =1: 1.757e-02\n",
            "Epoch: 899, f: 4.18229e+00, delta f: -8.85417e+00%, nash satisfied: True, max g: -1.578e-04, dual nash satisfied: False, max product: 4.890e+00, rho: 1.926e-04, norm2 d0:4.250e-03, ss: 9.881e-323\n",
            "Epoch: 899, >0 satisfied: True, max g>0: -1.686e-05, dual >0 satisfied: False, max product >0: 1.683e-02, =1 satisfied: True, max g=1: -9.375e-05, dual =1 satisfied: False, max product =1: 1.757e-02\n",
            "Epoch: 999, f: 4.18229e+00, delta f: -8.85417e+00%, nash satisfied: True, max g: -1.578e-04, dual nash satisfied: False, max product: 4.890e+00, rho: 1.926e-04, norm2 d0:4.250e-03, ss: 9.881e-323\n",
            "Epoch: 999, >0 satisfied: True, max g>0: -1.686e-05, dual >0 satisfied: False, max product >0: 1.683e-02, =1 satisfied: True, max g=1: -9.375e-05, dual =1 satisfied: False, max product =1: 1.757e-02\n",
            "Game 7 saved succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcljr2s04v3l",
        "outputId": "76fb7c54-891c-4cfb-8531-8238e1991bf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "xxx = game_2.optimize_game(hard_constraints=False, verbose=False, n_epochs=1000, print_each=100, nu=10, eta_0=1e-2, r_value=10.0)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 99, f: 9.92534e-01, delta f: -1.86131e-11%, nash satisfied: True, max g: -6.024e-08, dual nash satisfied: False, max product: 5.040e+00, rho: 5.818e-04, norm2 d0:6.313e-03, ss: 1.000e-18\n",
            "Epoch: 99, >0 satisfied: True, max g>0: -9.911e-09, dual >0 satisfied: False, max product >0: 7.620e-05, =1 satisfied: True, max g=1: -3.238e-06, dual =1 satisfied: False, max product =1: 1.250e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-4fe522b84709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhard_constraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_each\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-c5ca3125dee4>\u001b[0m in \u001b[0;36moptimize_game\u001b[0;34m(self, hard_constraints, max_steps, n_epochs, verbose, c, rho_0, on, eta_0, nu, print_each, r_value)\u001b[0m\n\u001b[1;32m    956\u001b[0m                                                                                   \u001b[0mgrad_f_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_g_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_pi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m                                                                                   \u001b[0mduals_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard_constraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound_step_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m                                                                                   max_steps=max_steps, on=on, eta=eta, nu=nu) # TODO: check if passing wrong grad_f\n\u001b[0m\u001b[1;32m    959\u001b[0m         \u001b[0mstep_sizes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mstep_size_hists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_size_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-c5ca3125dee4>\u001b[0m in \u001b[0;36mfeasible_gradient_descent\u001b[0;34m(self, f, g_vector, c_vector, d_vector, grad_f_vector, grad_g_matrix, d_v, d_pi, duals_vector, hard_constraints, bound_step_size, max_steps, eta, nu, gamma_0, verbose, on)\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mfound_feasible_step_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_step\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0mstep_size_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m       \u001b[0mgame_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m       \u001b[0;31m# Update parameters performing step in feasible descent direction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m       \u001b[0mgame_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-c5ca3125dee4>\u001b[0m in \u001b[0;36mcopy_game\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;31m# game_copy = multi_player_game(self.N, self.S_no_string, self.A, self.R, Ttuple, self.beta, self.device).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mgame_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;31m# with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;31m#   for param_copy, param in zip(game_copy.parameters(), self.parameters()):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/parameter.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/parameter.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, requires_grad)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_subclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__deepcopy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqRJtNl6XKgS",
        "outputId": "56ccddf2-11c4-49ef-cf53-68343875ac57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for pname, p in game_2.named_parameters():\n",
        "  print(pname, p)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v Parameter containing:\n",
            "tensor([[91.8401, 91.8401],\n",
            "        [92.1923, 91.0833],\n",
            "        [91.0833, 92.1922],\n",
            "        [91.0671, 93.1334],\n",
            "        [90.8975, 90.9024],\n",
            "        [91.8289, 92.8416],\n",
            "        [92.8273, 91.8120],\n",
            "        [93.8269, 90.8114],\n",
            "        [94.8274, 89.8124],\n",
            "        [90.8916, 90.8959],\n",
            "        [91.7817, 89.7622],\n",
            "        [92.7794, 88.7622],\n",
            "        [93.7784, 87.7624],\n",
            "        [94.7777, 86.7627],\n",
            "        [95.7772, 85.7631],\n",
            "        [93.1334, 91.0671],\n",
            "        [90.9024, 90.8975],\n",
            "        [92.8416, 91.8289],\n",
            "        [91.8120, 92.8273],\n",
            "        [90.8114, 93.8269],\n",
            "        [89.8124, 94.8274],\n",
            "        [90.8959, 90.8916],\n",
            "        [89.7622, 91.7817],\n",
            "        [88.7622, 92.7794],\n",
            "        [87.7624, 93.7784],\n",
            "        [86.7627, 94.7777],\n",
            "        [85.7631, 95.7771],\n",
            "        [95.7939, 90.7614],\n",
            "        [91.7033, 91.7231],\n",
            "        [90.7614, 95.7939],\n",
            "        [91.7231, 91.7033]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('G',) Parameter containing:\n",
            "tensor([[0.0386],\n",
            "        [0.9609]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('O', 1) Parameter containing:\n",
            "tensor([[7.8314e-01],\n",
            "        [2.5511e-04],\n",
            "        [2.5662e-04],\n",
            "        [2.6620e-04],\n",
            "        [8.3009e-03],\n",
            "        [3.3039e-04],\n",
            "        [1.9404e-02],\n",
            "        [4.7639e-04],\n",
            "        [5.0277e-02],\n",
            "        [8.3968e-04],\n",
            "        [1.3419e-01],\n",
            "        [1.7901e-03]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('O', 2) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 0, 0) Parameter containing:\n",
            "tensor([[0.5688],\n",
            "        [0.4307]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 0, 1) Parameter containing:\n",
            "tensor([[0.0022],\n",
            "        [0.9974]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 0, 2) Parameter containing:\n",
            "tensor([[9.9917e-01],\n",
            "        [3.5258e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 0, 3) Parameter containing:\n",
            "tensor([[9.9920e-01],\n",
            "        [3.1979e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 0, 4) Parameter containing:\n",
            "tensor([[9.9930e-01],\n",
            "        [2.2065e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 0, 5) Parameter containing:\n",
            "tensor([[9.9935e-01],\n",
            "        [1.7151e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 1, 0) Parameter containing:\n",
            "tensor([[0.0017],\n",
            "        [0.9978]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 1, 1) Parameter containing:\n",
            "tensor([[9.9880e-01],\n",
            "        [7.2368e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 1, 2) Parameter containing:\n",
            "tensor([[9.9917e-01],\n",
            "        [3.5185e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 1, 3) Parameter containing:\n",
            "tensor([[9.9929e-01],\n",
            "        [2.2724e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 1, 4) Parameter containing:\n",
            "tensor([[9.9935e-01],\n",
            "        [1.6939e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E1', 1, 5) Parameter containing:\n",
            "tensor([[9.9938e-01],\n",
            "        [1.3561e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 0, 0) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 0, 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 0, 2) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 0, 3) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 0, 4) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 0, 5) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 1, 0) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 1, 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 1, 2) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 1, 3) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 1, 4) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('E2', 1, 5) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('R1', 0) Parameter containing:\n",
            "tensor([[0.0036],\n",
            "        [0.9959]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('R1', 1) Parameter containing:\n",
            "tensor([[0.0034],\n",
            "        [0.9961]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('R2', 0) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi1.('R2', 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('G',) Parameter containing:\n",
            "tensor([[0.0386],\n",
            "        [0.9609]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('O', 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('O', 2) Parameter containing:\n",
            "tensor([[7.8314e-01],\n",
            "        [2.5511e-04],\n",
            "        [2.5662e-04],\n",
            "        [2.6620e-04],\n",
            "        [8.3009e-03],\n",
            "        [3.3039e-04],\n",
            "        [1.9404e-02],\n",
            "        [4.7639e-04],\n",
            "        [5.0277e-02],\n",
            "        [8.3968e-04],\n",
            "        [1.3419e-01],\n",
            "        [1.7901e-03]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 0, 0) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 0, 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 0, 2) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 0, 3) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 0, 4) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 0, 5) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 1, 0) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 1, 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 1, 2) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 1, 3) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 1, 4) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E1', 1, 5) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 0, 0) Parameter containing:\n",
            "tensor([[0.5688],\n",
            "        [0.4307]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 0, 1) Parameter containing:\n",
            "tensor([[0.0022],\n",
            "        [0.9974]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 0, 2) Parameter containing:\n",
            "tensor([[9.9917e-01],\n",
            "        [3.5258e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 0, 3) Parameter containing:\n",
            "tensor([[9.9920e-01],\n",
            "        [3.1979e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 0, 4) Parameter containing:\n",
            "tensor([[9.9930e-01],\n",
            "        [2.2065e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 0, 5) Parameter containing:\n",
            "tensor([[9.9935e-01],\n",
            "        [1.7151e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 1, 0) Parameter containing:\n",
            "tensor([[0.0017],\n",
            "        [0.9978]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 1, 1) Parameter containing:\n",
            "tensor([[9.9880e-01],\n",
            "        [7.2368e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 1, 2) Parameter containing:\n",
            "tensor([[9.9917e-01],\n",
            "        [3.5185e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 1, 3) Parameter containing:\n",
            "tensor([[9.9929e-01],\n",
            "        [2.2724e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 1, 4) Parameter containing:\n",
            "tensor([[9.9935e-01],\n",
            "        [1.6939e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('E2', 1, 5) Parameter containing:\n",
            "tensor([[9.9938e-01],\n",
            "        [1.3561e-04]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('R1', 0) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('R1', 1) Parameter containing:\n",
            "tensor([[1.]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('R2', 0) Parameter containing:\n",
            "tensor([[0.0036],\n",
            "        [0.9959]], dtype=torch.float64, requires_grad=True)\n",
            "pi2.('R2', 1) Parameter containing:\n",
            "tensor([[0.0034],\n",
            "        [0.9961]], dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJlzCP3Tg6Sl"
      },
      "source": [
        "We may conclude then that although the algorithm is itself  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATqb0MUfo1ZW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcpyWtCzbmnA",
        "outputId": "44689577-7ec8-48b0-e5a9-c6ea0ffa2c07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "norm_2_d = d_vector.pow(2).sum()\n",
        "print(norm_2_d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.3048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrZXI52heOLj"
      },
      "source": [
        "mu_vector = game_iterated_3.calculate_max_eigen_g_hessian()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7BgS4GJeTUi",
        "outputId": "fff8448e-8f8d-40ee-e44f-6cdfb11a8675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "mu_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[15.6184],\n",
              "        [18.7268],\n",
              "        [15.6185],\n",
              "        [18.7268]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZFO26i5g-mB",
        "outputId": "e7179211-e90c-4fa7-ad41-a0d6f77dad14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "g_vector[:NAt,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9.2485e-01],\n",
              "        [-5.2452e-06],\n",
              "        [-9.2485e-01],\n",
              "        [-2.8610e-06]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1gEFhhQefZu",
        "outputId": "dc5bfeaa-0833-4546-8c32-3825e348b00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "g_vector[:NAt,:] + step_size * torch.einsum('ij,jk->ik', grad_g_matrix[:NAt,:], d_vector) + 0.5*mu_vector*(step_size**2)*norm_2_d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9.2450e-01],\n",
              "        [-6.2809e-06],\n",
              "        [-9.2450e-01],\n",
              "        [-3.8971e-06]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZJmRukOfaqe",
        "outputId": "143859d6-212b-49a5-efce-502b85ea2085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "g_vector_temp[:NAt,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9.2451e-01],\n",
              "        [ 3.4952e-04],\n",
              "        [-9.2450e-01],\n",
              "        [ 3.5191e-04]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeTMJa4PgU2Y"
      },
      "source": [
        "beta_1_tau = 1 + new_rho * d0_2norm**0.5 * torch.einsum('ji,jk->ik', grad_g_matrix, mWe).pow(2).sum()**0.5\n",
        "beta_tau = beta_1_tau**(-2)\n",
        "tau_lambda = (1-gamma_0) / (1.0 * (duals_vector + new_c_vector).max())\n",
        "tau_mu = 2 * beta_tau * new_rho / mu_vector.max()\n",
        "tau = np.infty\n",
        "if duals_vector.max() > 0.0:\n",
        "  tau = tau_lambda.item()\n",
        "  if mu_vector.max() > 0.0:\n",
        "    tau = min(tau, tau_mu.item())\n",
        "else:\n",
        "  if mu_vector.max() > 0.0:\n",
        "    tau = tau_mu.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsA8iT7MhKC8",
        "outputId": "73e975d5-5fa0-4bbc-da9f-1d70b26ee229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "d0_2norm - beta_tau * norm_2_d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0350)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTaH7ItWhbNj",
        "outputId": "1bcc0873-b4f8-4f52-9a5d-f5255c6ab641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(tau_mu, tau_lambda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0011) tensor(0.3201)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYWxw4dZhgXw",
        "outputId": "c51e8200-7c3e-495e-9e6e-95f9dbebedcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "step_size*2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0010919219348579645"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkcgRFZnj_VD"
      },
      "source": [
        "mu_list = []\n",
        "hessians = []\n",
        "Tr_list = []\n",
        "grad_g_v_dic, grad_g_pi_dic = game_iterated_3.nash_restriction_gradients(True)\n",
        "dim = game_iterated_3.N_S + game_iterated_3.N_A_reduced['1'] + game_iterated_3.N_A_reduced['2']\n",
        "NS = game_iterated_3.N_S\n",
        "for player in game_iterated_3.players():\n",
        "  other_player = game_iterated_3.other_player(player)\n",
        "  NAi = game_iterated_3.N_A_reduced[player]\n",
        "  NAmi = game_iterated_3.N_A_reduced[other_player]\n",
        "  for state in game_iterated_3.S_no_string:\n",
        "    s = str(state)\n",
        "    pi_sum = game_iterated_3.pi[player][s].sum()\n",
        "    next_v_matrix = grad_g_pi_dic[other_player][s]\n",
        "    grad_g_v_matrix = grad_g_v_dic[player][s]\n",
        "    for ai in range(0, game_iterated_3.A[player][s]):\n",
        "      Tr = game_iterated_3.transition_matrix_given_sai(player, state, ai)\n",
        "      M14 = game_iterated_3.beta * pi_sum * Tr \n",
        "      # next_v = next_v_matrix[ai,:].view(-1)\n",
        "      Ri = game_iterated_3.R[player][s].clone()\n",
        "      if player == '2':\n",
        "        Ri = Ri.T\n",
        "      v_player = game_iterated_3.v[:,game_iterated_3.get_player_id(player)].view(-1,1)\n",
        "      next_v = Ri[ai,:].view(1,-1) + game_iterated_3.beta * torch.einsum('ji,jk->ki', Tr, v_player)\n",
        "      #ones_1 = torch.ones(NAi,NAmi).to(game_iterated_3.device)\n",
        "      ones_1 = torch.ones((NAi,1), dtype=torch.float64).to(game_iterated_3.device)\n",
        "      M34 = torch.einsum('ij,jk->ik', ones_1, next_v) #torch.einsum('ij,jk->ik', ones_1, torch.diag(next_v))\n",
        "      p = torch.einsum('ij,jk->ik', Tr, game_iterated_3.pi[other_player][s]) #grad_g_v_matrix[ai,:].view(-1)\n",
        "      # id_s = game_iterated_3.get_state_index(s)\n",
        "      # p[id_s] += 1\n",
        "      #ones_2 = torch.ones(NS,NAi).to(game_iterated_3.device)\n",
        "      ones_2 = torch.ones((NAi,1), dtype=torch.float64).to(game_iterated_3.device)\n",
        "      M13 = game_iterated_3.beta * torch.einsum('ij,kj->ik', p, ones_2) #torch.einsum('ij,jk->ik', torch.diag(p), ones_2)\n",
        "      \n",
        "      M = torch.zeros((dim, dim), dtype=torch.float64).to(game_iterated_3.device)\n",
        "      M[:NS,NS:NS+NAi] = M13.clone()\n",
        "      M[:NS,NS+NAi:] = M14.clone()\n",
        "      M[NS:NS+NAi,:NS] = M13.T.clone()\n",
        "      M[NS:NS+NAi,NS+NAi:] = M34.clone()\n",
        "      M[NS+NAi:,:NS] = M14.T.clone()\n",
        "      M[NS+NAi:,NS:NS+NAi] = M34.T.clone()\n",
        "\n",
        "      M_eigval, M_eigvec = torch.eig(M)\n",
        "      mu_list.append(M_eigval.max())\n",
        "      hessians.append(M.clone())\n",
        "      Tr_list.append(Tr.clone())\n",
        "mu_vector = torch.DoubleTensor(mu_list).view(-1,1).to(game_iterated_3.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3kHs7bXGnx0",
        "outputId": "a1058e90-1186-4e29-8fb1-b298951c64a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "mu_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[15.6184],\n",
              "        [18.7268],\n",
              "        [15.6185],\n",
              "        [18.7268]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaUKyhhXkfyb",
        "outputId": "de23d173-27cb-4dc7-a708-61289ee64bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        }
      },
      "source": [
        "dg2_list = []\n",
        "for i in range(0, NAt):\n",
        "  d_reduced = torch.zeros((hessians[i].shape[0],1), dtype=torch.float64)\n",
        "  if i < game_iterated_3.N_A_total['1']:\n",
        "    d_reduced[:game_iterated_3.N_S,:] = d_vector[:game_iterated_3.N_S,:]\n",
        "    d_reduced[game_iterated_3.N_S:,:] = d_vector[2*game_iterated_3.N_S:,:]\n",
        "  else:\n",
        "    d_reduced[:game_iterated_3.N_S,:] = d_vector[game_iterated_3.N_S:2*game_iterated_3.N_S,:]\n",
        "    d_reduced[game_iterated_3.N_S:game_iterated_3.N_S+game_iterated_3.N_A_reduced['2'],:] = d_vector[2*game_iterated_3.N_S+game_iterated_3.N_A_reduced['1']:,:]\n",
        "    d_reduced[game_iterated_3.N_S+game_iterated_3.N_A_reduced['2']:,:] = d_vector[2*game_iterated_3.N_S:2*game_iterated_3.N_S+game_iterated_3.N_A_reduced['1'],:]\n",
        "  Hd = torch.einsum('ij,jk->ik', hessians[i], d_reduced)\n",
        "  dg2_list.append((d_reduced.view(-1) * Hd.view(-1)).sum())\n",
        "  print(i, hessians[i], d_reduced, (d_reduced * Hd).sum())\n",
        "dg2_vector = torch.DoubleTensor(dg2_list).to(game_iterated_3.device).view(-1,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor([[0.0000, 0.8809, 0.8809, 0.8809, 0.8809],\n",
            "        [0.8809, 0.0000, 0.0000, 9.0644, 6.0644],\n",
            "        [0.8809, 0.0000, 0.0000, 9.0644, 6.0644],\n",
            "        [0.8809, 9.0644, 9.0644, 0.0000, 0.0000],\n",
            "        [0.8809, 6.0644, 6.0644, 0.0000, 0.0000]], grad_fn=<CloneBackward>) tensor([[ 0.1140],\n",
            "        [-0.2052],\n",
            "        [ 0.3119],\n",
            "        [-0.2052],\n",
            "        [ 0.3119]]) tensor(0.0496, grad_fn=<SumBackward0>)\n",
            "1 tensor([[ 0.0000,  0.8809,  0.8809,  0.8809,  0.8809],\n",
            "        [ 0.8809,  0.0000,  0.0000, 11.0644,  7.0644],\n",
            "        [ 0.8809,  0.0000,  0.0000, 11.0644,  7.0644],\n",
            "        [ 0.8809, 11.0644, 11.0644,  0.0000,  0.0000],\n",
            "        [ 0.8809,  7.0644,  7.0644,  0.0000,  0.0000]],\n",
            "       grad_fn=<CloneBackward>) tensor([[ 0.1140],\n",
            "        [-0.2052],\n",
            "        [ 0.3119],\n",
            "        [-0.2052],\n",
            "        [ 0.3119]]) tensor(0.0285, grad_fn=<SumBackward0>)\n",
            "2 tensor([[0.0000, 0.8809, 0.8809, 0.8809, 0.8809],\n",
            "        [0.8809, 0.0000, 0.0000, 9.0644, 6.0644],\n",
            "        [0.8809, 0.0000, 0.0000, 9.0644, 6.0644],\n",
            "        [0.8809, 9.0644, 9.0644, 0.0000, 0.0000],\n",
            "        [0.8809, 6.0644, 6.0644, 0.0000, 0.0000]], grad_fn=<CloneBackward>) tensor([[ 0.1140],\n",
            "        [-0.2052],\n",
            "        [ 0.3119],\n",
            "        [-0.2052],\n",
            "        [ 0.3119]]) tensor(0.0496, grad_fn=<SumBackward0>)\n",
            "3 tensor([[ 0.0000,  0.8809,  0.8809,  0.8809,  0.8809],\n",
            "        [ 0.8809,  0.0000,  0.0000, 11.0644,  7.0644],\n",
            "        [ 0.8809,  0.0000,  0.0000, 11.0644,  7.0644],\n",
            "        [ 0.8809, 11.0644, 11.0644,  0.0000,  0.0000],\n",
            "        [ 0.8809,  7.0644,  7.0644,  0.0000,  0.0000]],\n",
            "       grad_fn=<CloneBackward>) tensor([[ 0.1140],\n",
            "        [-0.2052],\n",
            "        [ 0.3119],\n",
            "        [-0.2052],\n",
            "        [ 0.3119]]) tensor(0.0285, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE6hVDDJkw4E",
        "outputId": "aa7786c2-5a0c-4910-e584-ddc621ad4102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "mu_vector*norm_2_d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.7608],\n",
              "        [5.7083],\n",
              "        [4.7608],\n",
              "        [5.7083]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy7YuSnvpc73",
        "outputId": "f2cb63dc-9f95-4890-b540-d31485aa2c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "step_size * d_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.2246e-05],\n",
              "        [ 6.2243e-05],\n",
              "        [-1.1204e-04],\n",
              "        [ 1.7029e-04],\n",
              "        [-1.1205e-04],\n",
              "        [ 1.7030e-04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfVYRpphzIcK"
      },
      "source": [
        "dg3_list = []\n",
        "i = 0\n",
        "for player in game_iterated_3.players():\n",
        "  other_player = game_iterated_3.other_player(player)\n",
        "  d_v_i = d_v[:,game_iterated_3.get_player_id(player)].view(-1,1)\n",
        "  for state in game_iterated_3.S_no_string:\n",
        "    s = str(state)\n",
        "    d_pi_mi = d_pi[other_player][s]\n",
        "    d_pi_i_sum = d_pi[player][s].sum()\n",
        "    for ai in range(0, game_iterated_3.A[player][s]):\n",
        "      Tr = Tr_list[i]\n",
        "      d_P = torch.einsum('ij,jk->ik', Tr, d_pi_mi)\n",
        "      dPdv = (d_P.view(-1) * d_v_i.view(-1)).sum()\n",
        "      dg3_list.append(game_iterated_3.beta * d_pi_i_sum * dPdv)\n",
        "      i += 1\n",
        "dg3_vector = torch.DoubleTensor(dg3_list).to(game_iterated_3.device).view(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_FQfuW-RUih"
      },
      "source": [
        "dg1_vector = torch.einsum('ij,jk->ik', grad_g_matrix[:NAt,:], d_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f42YxpHRZoS",
        "outputId": "b1868b75-c028-48a8-ab8e-cd331a6e8f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "step_size**1 * dg1_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.4226e-04],\n",
              "        [-1.8864e-06],\n",
              "        [ 3.4227e-04],\n",
              "        [-1.8869e-06]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8kHAyYWRHwC",
        "outputId": "89a4621f-42b2-4fc2-f3c0-740e23c425c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "0.5*step_size**2 * dg2_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7.3865e-09],\n",
              "        [4.2530e-09],\n",
              "        [7.3860e-09],\n",
              "        [4.2525e-09]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvXdxPdeQXdh",
        "outputId": "5af11220-80c7-4fbe-8b27-b12f87b352e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "step_size**3 * dg3_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.0911e-13],\n",
              "        [2.0911e-13],\n",
              "        [2.0910e-13],\n",
              "        [2.0910e-13]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCQTv9WLRrH1"
      },
      "source": [
        "g_vector_temp_estimated = g_vector[:NAt,:] + step_size**1 * dg1_vector + 0.5*step_size**2 * dg2_vector + step_size**3 * dg3_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "domHhHrNR4DY",
        "outputId": "3c15e95d-da84-4983-e94b-cc6f92ab8175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "g_vector_temp_estimated"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9.2451e-01],\n",
              "        [-7.1274e-06],\n",
              "        [-9.2450e-01],\n",
              "        [-4.7436e-06]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JucADVpRjQr",
        "outputId": "2aa83205-a531-4b7c-de13-aee67305aec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "g_vector_temp[:NAt,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9.2451e-01],\n",
              "        [ 3.4952e-04],\n",
              "        [-9.2450e-01],\n",
              "        [ 3.5191e-04]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQbVOnVcYcZf"
      },
      "source": [
        "q_estimated_temp = game_temp.bellman_partial_projection_other() # Dic. with an array of 'q'-values for each agent \n",
        "g_nash_temp = {'1':{}, '2':{}}\n",
        "coef = 1.0\n",
        "for s, player in game_temp.state_player_pairs():\n",
        "  if not hard_constraints:\n",
        "    coef = game_temp.pi[player][s].sum()\n",
        "  g_nash_temp[player][s] = coef * q_estimated_temp[player][s] - game_temp.v[game_temp.get_state_index(s), game_temp.get_player_id(player)].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV8pT69OZklu",
        "outputId": "8573c71c-e395-44db-f8b2-53bbbb0739b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "g_nash_temp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': {\"('G',)\": tensor([[-9.2451e-01],\n",
              "          [ 3.4952e-04]], grad_fn=<SubBackward0>)},\n",
              " '2': {\"('G',)\": tensor([[-9.2450e-01],\n",
              "          [ 3.5191e-04]], grad_fn=<SubBackward0>)}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsU1ttQzaN4R"
      },
      "source": [
        "q_estimated_3 = game_temp.bellman_partial_projection_other() # Dic. with an array of 'q'-values for each agent \n",
        "g_nash_3 = {'1':{}, '2':{}}\n",
        "coef = 1.0\n",
        "for s, player in game_iterated_3.state_player_pairs():\n",
        "  if not hard_constraints: \n",
        "    coef = (game_iterated_3.pi[player][s] + step_size * d_pi[player][s]).sum()\n",
        "  g_nash_3[player][s] = coef * q_estimated_3[player][s] - (game_iterated_3.v + step_size * d_v)[game_iterated_3.get_state_index(s), game_iterated_3.get_player_id(player)].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7xikxx8cZ5c",
        "outputId": "e820ff0f-d211-423f-e58d-4baae147da4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "g_nash_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': {\"('G',)\": tensor([[-9.2451e-01],\n",
              "          [ 3.4952e-04]], grad_fn=<SubBackward0>)},\n",
              " '2': {\"('G',)\": tensor([[-9.2450e-01],\n",
              "          [ 3.5191e-04]], grad_fn=<SubBackward0>)}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etk8tTJebDMV",
        "outputId": "8bf82c4b-1983-4ce5-d11a-53ca7d060ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "(game_temp.v.data - game_iterated_3.v.data)/step_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1144, 0.1144]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdZf5wABbQQk",
        "outputId": "78dbd463-fdf7-499d-80d8-e83acb2fb7f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "(game_temp.pi2vec()['1'] - game_iterated_3.pi2vec()['1'])/step_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2052],\n",
              "        [ 0.3119]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MrMxYKVdewj"
      },
      "source": [
        "r_mean_3 = {}\n",
        "for player in game_iterated_3.players():\n",
        "  r_mean_3[player] = {}\n",
        "for s in game_iterated_3.S:\n",
        "  RM1 = game_iterated_3.R['1'][s]\n",
        "  RM2 = game_iterated_3.R['2'][s]\n",
        "  strategy1 = game_iterated_3.pi['1'][s] + step_size * d_pi['1'][s]\n",
        "  strategy2 = game_iterated_3.pi['2'][s] + step_size * d_pi['2'][s]\n",
        "  r_mean_3['1'][s] = torch.einsum('ij,jk->ik', RM1, strategy2)\n",
        "  r_mean_3['2'][s] = torch.einsum('ji,jk->ik', RM2, strategy1)\n",
        "\n",
        "next_v_3 = {'1':{}, '2':{}}\n",
        "for state in game_iterated_3.S_no_string:\n",
        "  s = str(state)\n",
        "\n",
        "  det, dep = game_iterated_3.transition_type[str(state)]\n",
        "  N_A1 = game_iterated_3.A['1'][str(state)]\n",
        "  N_A2 = game_iterated_3.A['2'][str(state)]\n",
        "  vs = torch.zeros((N_A1,N_A2,2), dtype=torch.float64).to(game_iterated_3.device)\n",
        "  if det and dep: \n",
        "    for a1 in range(0,N_A1):\n",
        "      for a2 in range(0,N_A2):\n",
        "        _, next_state = game_iterated_3.transition_map(state, [a1,a2])\n",
        "        vs[a1,a2,:] = (game_iterated_3.v + step_size * d_v)[game_iterated_3.get_state_index(next_state),:]\n",
        "  elif (not det) and (not dep):\n",
        "    _, transition_dic = game_iterated_3.transition_map(state, [])\n",
        "    next_v = torch.zeros((1,2), dtype=torch.float64).to(game_iterated_3.device)\n",
        "    for next_state, transition_prob in transition_dic:\n",
        "      next_v = next_v + (game_iterated_3.v + step_size * d_v)[game_iterated_3.get_state_index(next_state),:].view(1,-1) * transition_prob      \n",
        "    for a1 in range(0,N_A1):\n",
        "      for a2 in range(0,N_A2):\n",
        "        vs[a1,a2,:] = next_v.view(-1)\n",
        "\n",
        "  next_state_value_matrix_3 = vs.clone()\n",
        "  strategy_1 = (game_iterated_3.pi['1'][s] + step_size * d_pi['1'][s])\n",
        "  strategy_2 = (game_iterated_3.pi['2'][s] + step_size * d_pi['2'][s])\n",
        "  # mean next value when considering the strategy of the other player. Output: array of size m^i(s)\n",
        "  next_v_3['1'][s] = torch.einsum('ij,jk->ik', next_state_value_matrix_3[:,:,0], strategy_2)\n",
        "  next_v_3['2'][s] = torch.einsum('ji,jk->ik', next_state_value_matrix_3[:,:,1], strategy_1)\n",
        "q_estimated_3 = {'1':{}, '2':{}}\n",
        "for s, player in game_iterated_3.state_player_pairs():\n",
        "  q_estimated_3[player][s] = r_mean_3[player][s] + game_iterated_3.beta * next_v_3[player][s]\n",
        "\n",
        "g_nash_3 = {'1':{}, '2':{}}\n",
        "coef = 1.0\n",
        "for s, player in game_iterated_3.state_player_pairs():\n",
        "  if not hard_constraints: \n",
        "    coef = (game_iterated_3.pi[player][s] + step_size * d_pi[player][s]).sum()\n",
        "  g_nash_3[player][s] = coef * q_estimated_3[player][s] - (game_iterated_3.v + step_size * d_v)[game_iterated_3.get_state_index(s), game_iterated_3.get_player_id(player)].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz8M-rR4edoy",
        "outputId": "135f1faa-67c5-4142-be28-05ce919992a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "g_nash_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': {\"('G',)\": tensor([[-9.2451e-01],\n",
              "          [ 3.4952e-04]], grad_fn=<SubBackward0>)},\n",
              " '2': {\"('G',)\": tensor([[-9.2450e-01],\n",
              "          [ 3.5191e-04]], grad_fn=<SubBackward0>)}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePXVrJC0oJEp"
      },
      "source": [
        "i = 0\n",
        "dg1_list = []\n",
        "grad_g_v_dic_list = {'1':[], '2':[]}\n",
        "grad_g_pi_dic_list = {'1':[], '2':[]}\n",
        "beta = game_iterated_3.beta\n",
        "for player in game_iterated_3.players():\n",
        "  other_player = game_iterated_3.other_player(player)\n",
        "  player_id = game_iterated_3.get_player_id(player)\n",
        "  v_i = game_iterated_3.v[:,player_id].view(-1,1) \n",
        "  dv_i = d_v[:,player_id].view(-1,1)\n",
        "  for state in game_iterated_3.S_no_string:\n",
        "    s = str(state)\n",
        "    s_id = game_iterated_3.get_state_index(s)\n",
        "    pi_i = game_iterated_3.pi[player][s]\n",
        "    pi_mi = game_iterated_3.pi[other_player][s]\n",
        "    dpi_i = d_pi[player][s]\n",
        "    dpi_mi = d_pi[other_player][s]    \n",
        "\n",
        "    Ri_s = game_iterated_3.R[player][s].clone()\n",
        "    if player == '2':\n",
        "      Ri_s = Ri_s.T\n",
        "\n",
        "    sum_pi = game_iterated_3.pi[player][s].sum()\n",
        "    sum_dpi = d_pi[player][s].sum()\n",
        "\n",
        "    for ai in range(0, game_iterated_3.A[player][s]):\n",
        "      Tr = Tr_list[i]\n",
        "      Ri_s_ai = Ri_s[ai,:].view(-1,1)\n",
        "\n",
        "      P_pi_mi = torch.einsum('ij,jk->ik', Tr, pi_mi)\n",
        "      P_dpi_mi = torch.einsum('ij,jk->ik', Tr, dpi_mi)\n",
        "      R_pi_mi = torch.dot(Ri_s_ai.view(-1), pi_mi.view(-1))\n",
        "      R_dpi_mi = torch.dot(Ri_s_ai.view(-1), dpi_mi.view(-1))\n",
        "      P_pi_mi_dv_i = torch.dot(P_pi_mi.view(-1), dv_i.view(-1))\n",
        "      P_dpi_mi_v_i = torch.dot(P_dpi_mi.view(-1), v_i.view(-1))\n",
        "      P_pi_mi_v_i = torch.dot(P_pi_mi.view(-1), v_i.view(-1))\n",
        "\n",
        "      dg1_s_ai = sum_pi * (beta * P_pi_mi_dv_i + R_dpi_mi + beta * P_dpi_mi_v_i)\n",
        "      dg1_s_ai = dg1_s_ai + sum_dpi * (R_pi_mi + beta * P_pi_mi_v_i)\n",
        "      dg1_s_ai = dg1_s_ai - dv_i.view(-1)[s_id]\n",
        "      dg1_list.append(dg1_s_ai)\n",
        "\n",
        "      grad_g_v_i = sum_pi * beta * P_pi_mi\n",
        "      grad_g_v_i[s_id,0] = grad_g_v_i[s_id,0] - 1\n",
        "      grad_g_v_dic_list[player].append(grad_g_v_i.view(1,-1))\n",
        "      grad_g_v_dic_list[other_player].append(torch.zeros_like(grad_g_v_i).view(1,-1))\n",
        "\n",
        "      mean_v_i = torch.einsum('ji,jk->ik', Tr, v_i)\n",
        "      grad_g_pi_mi = sum_pi * (Ri_s_ai + beta * mean_v_i)\n",
        "      grad_g_pi_dic_list[other_player].append(grad_g_pi_mi.view(1,-1))\n",
        "\n",
        "      grad_g_pi_i = (R_pi_mi + beta * P_pi_mi_v_i) * torch.ones_like(pi_i)\n",
        "      grad_g_pi_dic_list[player].append(grad_g_pi_i.view(1,-1))\n",
        "\n",
        "      i = i + 1\n",
        "dg1_vector_direct = torch.DoubleTensor(dg1_list).to(game_iterated_3.device).view(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NVKFcitpIcd",
        "outputId": "6add4c58-eab0-40c9-d23a-18a1923016cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "dg1_vector_direct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6269],\n",
              "        [0.6501],\n",
              "        [0.6269],\n",
              "        [0.6501]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6sJ6FzZuaOB",
        "outputId": "7fe91e85-a7b8-4dfe-d230-3f09f4e5b066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "dg1_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6269],\n",
              "        [-0.0035],\n",
              "        [ 0.6269],\n",
              "        [-0.0035]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91V7rDaEulSH",
        "outputId": "bb8ac0de-fbbf-47b4-805a-24fb8824de17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "grad_g_matrix[:NAt,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2162,  0.0000,  5.8449,  5.8449,  8.0656,  5.3962],\n",
              "        [-0.2162,  0.0000,  0.7586,  0.7586,  9.8453,  6.2860],\n",
              "        [ 0.0000, -0.2162,  8.0656,  5.3962,  5.8449,  5.8449],\n",
              "        [ 0.0000, -0.2162,  9.8453,  6.2860,  0.7586,  0.7586]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpFxbMsmvkeb",
        "outputId": "9cb2dc63-e4f0-4d9c-bede-71d60a2c221f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "grad_g_matrix[:NAt,:] @ d_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6269],\n",
              "        [-0.0035],\n",
              "        [ 0.6269],\n",
              "        [-0.0035]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYLOrGvNvkx6"
      },
      "source": [
        "g_vector_temp_estimated_direct = g_vector[:NAt,:] + step_size**1 * dg1_vector_direct + 0.5*step_size**2 * dg2_vector + step_size**3 * dg3_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f25FX1Cav1NN",
        "outputId": "4036c4fa-5369-4bb0-bf56-5ac1145b576a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "g_vector_temp_estimated_direct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9.2451e-01],\n",
              "        [ 3.4970e-04],\n",
              "        [-9.2450e-01],\n",
              "        [ 3.5210e-04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLs9cRrkv5FZ",
        "outputId": "cf965ecc-6c02-47c2-ab00-31736fba780e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "g_vector_temp[:NAt,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9.2451e-01],\n",
              "        [ 3.4952e-04],\n",
              "        [-9.2450e-01],\n",
              "        [ 3.5191e-04]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2khvr_c0WOw"
      },
      "source": [
        "for player in game_iterated_3.players():\n",
        "  grad_g_v_dic_list[player] = torch.cat(grad_g_v_dic_list[player], dim = 0)\n",
        "  grad_g_pi_dic_list[player] = torch.cat(grad_g_pi_dic_list[player], dim = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2ZmPpht0t4-",
        "outputId": "76442e59-dee1-4347-8d75-b59828d98ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "grad_g_v_dic_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': tensor([[-0.2162],\n",
              "         [-0.2162],\n",
              "         [ 0.0000],\n",
              "         [ 0.0000]], grad_fn=<CatBackward>), '2': tensor([[ 0.0000],\n",
              "         [ 0.0000],\n",
              "         [-0.2162],\n",
              "         [-0.2162]], grad_fn=<CatBackward>)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQdSw2t51BjY",
        "outputId": "88ba1c2d-c9f5-4695-bd5b-b5e365e6b0f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "grad_g_pi_dic_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': tensor([[5.8449, 5.8449],\n",
              "         [6.8842, 6.8842],\n",
              "         [8.0656, 5.3962],\n",
              "         [9.8453, 6.2860]], grad_fn=<CatBackward>),\n",
              " '2': tensor([[8.0656, 5.3962],\n",
              "         [9.8453, 6.2860],\n",
              "         [5.8449, 5.8449],\n",
              "         [6.8842, 6.8842]], grad_fn=<CatBackward>)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    }
  ]
}